<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url('https://themes.googleusercontent.com/fonts/css?kit=4mNYFHt_IKFsPe52toizH4jB0lxTqxuZ9MrNDVFkHCs');.lst-kix_ne2kodfi1kix-8>li:before{content:"\0025a0  "}.lst-kix_um8gcdc8t9m9-2>li:before{content:"-  "}.lst-kix_um8gcdc8t9m9-3>li:before{content:"-  "}.lst-kix_um8gcdc8t9m9-4>li:before{content:"-  "}.lst-kix_um8gcdc8t9m9-6>li:before{content:"-  "}ul.lst-kix_8d6owvwxykff-3{list-style-type:none}ul.lst-kix_8d6owvwxykff-2{list-style-type:none}.lst-kix_um8gcdc8t9m9-5>li:before{content:"-  "}.lst-kix_um8gcdc8t9m9-7>li:before{content:"-  "}ul.lst-kix_8d6owvwxykff-5{list-style-type:none}ul.lst-kix_8d6owvwxykff-4{list-style-type:none}ul.lst-kix_8d6owvwxykff-7{list-style-type:none}.lst-kix_dnm4ke3nhj1e-8>li:before{content:"\0025a0  "}ul.lst-kix_8d6owvwxykff-6{list-style-type:none}ul.lst-kix_8d6owvwxykff-8{list-style-type:none}.lst-kix_um8gcdc8t9m9-8>li:before{content:"-  "}ul.lst-kix_8d6owvwxykff-1{list-style-type:none}ul.lst-kix_8d6owvwxykff-0{list-style-type:none}ul.lst-kix_dnm4ke3nhj1e-5{list-style-type:none}ul.lst-kix_dnm4ke3nhj1e-6{list-style-type:none}ul.lst-kix_dnm4ke3nhj1e-7{list-style-type:none}ul.lst-kix_dnm4ke3nhj1e-8{list-style-type:none}ul.lst-kix_dnm4ke3nhj1e-0{list-style-type:none}ul.lst-kix_dnm4ke3nhj1e-1{list-style-type:none}ul.lst-kix_dnm4ke3nhj1e-2{list-style-type:none}ul.lst-kix_dnm4ke3nhj1e-3{list-style-type:none}ul.lst-kix_dnm4ke3nhj1e-4{list-style-type:none}ol.lst-kix_8dw3ycrgt362-3.start{counter-reset:lst-ctn-kix_8dw3ycrgt362-3 0}ul.lst-kix_p3wa2k83s8cn-1{list-style-type:none}ul.lst-kix_p3wa2k83s8cn-0{list-style-type:none}ul.lst-kix_p3wa2k83s8cn-3{list-style-type:none}.lst-kix_3z0hr7pzpec4-3>li:before{content:"\0025cf  "}.lst-kix_3z0hr7pzpec4-5>li:before{content:"\0025a0  "}ul.lst-kix_p3wa2k83s8cn-2{list-style-type:none}ul.lst-kix_p3wa2k83s8cn-5{list-style-type:none}ul.lst-kix_p3wa2k83s8cn-4{list-style-type:none}ul.lst-kix_p3wa2k83s8cn-7{list-style-type:none}ul.lst-kix_p3wa2k83s8cn-6{list-style-type:none}.lst-kix_ao97xhpq4hr9-7>li:before{content:"\0025cb  "}ul.lst-kix_p3wa2k83s8cn-8{list-style-type:none}.lst-kix_ao97xhpq4hr9-5>li:before{content:"\0025a0  "}ul.lst-kix_hm0ybxxbxp2l-5{list-style-type:none}ul.lst-kix_hm0ybxxbxp2l-6{list-style-type:none}ul.lst-kix_hm0ybxxbxp2l-7{list-style-type:none}ul.lst-kix_hm0ybxxbxp2l-8{list-style-type:none}ul.lst-kix_hm0ybxxbxp2l-1{list-style-type:none}ul.lst-kix_hm0ybxxbxp2l-2{list-style-type:none}ul.lst-kix_hm0ybxxbxp2l-3{list-style-type:none}ul.lst-kix_hm0ybxxbxp2l-4{list-style-type:none}.lst-kix_3z0hr7pzpec4-7>li:before{content:"\0025cb  "}.lst-kix_mfwegjdddisb-3>li:before{content:"\0025cf  "}.lst-kix_mfwegjdddisb-5>li:before{content:"\0025a0  "}.lst-kix_7n1btf6e2iyv-7>li:before{content:"\0025cb  "}.lst-kix_mfwegjdddisb-1>li:before{content:"\0025cb  "}.lst-kix_mfwegjdddisb-7>li:before{content:"\0025cb  "}ul.lst-kix_hm0ybxxbxp2l-0{list-style-type:none}.lst-kix_7n1btf6e2iyv-1>li:before{content:"\0025cb  "}.lst-kix_ao97xhpq4hr9-3>li:before{content:"\0025cf  "}.lst-kix_7n1btf6e2iyv-3>li:before{content:"\0025cf  "}ol.lst-kix_8dw3ycrgt362-8.start{counter-reset:lst-ctn-kix_8dw3ycrgt362-8 0}.lst-kix_ao97xhpq4hr9-1>li:before{content:"\0025cb  "}.lst-kix_7n1btf6e2iyv-5>li:before{content:"\0025a0  "}.lst-kix_7pcs9kbg0qhi-4>li{counter-increment:lst-ctn-kix_7pcs9kbg0qhi-4}.lst-kix_8dw3ycrgt362-0>li{counter-increment:lst-ctn-kix_8dw3ycrgt362-0}.lst-kix_dnm4ke3nhj1e-1>li:before{content:"\0025cb  "}.lst-kix_dnm4ke3nhj1e-5>li:before{content:"\0025a0  "}ol.lst-kix_7pcs9kbg0qhi-2.start{counter-reset:lst-ctn-kix_7pcs9kbg0qhi-2 0}.lst-kix_dnm4ke3nhj1e-7>li:before{content:"\0025cb  "}.lst-kix_7pcs9kbg0qhi-5>li{counter-increment:lst-ctn-kix_7pcs9kbg0qhi-5}.lst-kix_um8gcdc8t9m9-1>li:before{content:"-  "}.lst-kix_8dw3ycrgt362-7>li:before{content:"" counter(lst-ctn-kix_8dw3ycrgt362-7,lower-latin) ". "}.lst-kix_dnm4ke3nhj1e-3>li:before{content:"\0025cf  "}ul.lst-kix_3z0hr7pzpec4-5{list-style-type:none}ul.lst-kix_3z0hr7pzpec4-6{list-style-type:none}ul.lst-kix_3z0hr7pzpec4-7{list-style-type:none}.lst-kix_8dw3ycrgt362-1>li:before{content:"" counter(lst-ctn-kix_8dw3ycrgt362-1,lower-latin) ". "}.lst-kix_8dw3ycrgt362-3>li:before{content:"" counter(lst-ctn-kix_8dw3ycrgt362-3,decimal) ". "}ul.lst-kix_3z0hr7pzpec4-8{list-style-type:none}.lst-kix_5we8o0btcr67-7>li:before{content:"\0025cb  "}.lst-kix_8dw3ycrgt362-5>li:before{content:"" counter(lst-ctn-kix_8dw3ycrgt362-5,lower-roman) ". "}ul.lst-kix_3z0hr7pzpec4-0{list-style-type:none}ul.lst-kix_3z0hr7pzpec4-1{list-style-type:none}ul.lst-kix_3z0hr7pzpec4-2{list-style-type:none}ul.lst-kix_3z0hr7pzpec4-3{list-style-type:none}.lst-kix_ne2kodfi1kix-1>li:before{content:"\0025cb  "}ul.lst-kix_3z0hr7pzpec4-4{list-style-type:none}.lst-kix_5s83gilt2o7g-1>li:before{content:"\0025cb  "}.lst-kix_ne2kodfi1kix-3>li:before{content:"\0025cf  "}.lst-kix_ne2kodfi1kix-7>li:before{content:"\0025cb  "}.lst-kix_5s83gilt2o7g-3>li:before{content:"\0025cf  "}.lst-kix_5s83gilt2o7g-5>li:before{content:"\0025a0  "}.lst-kix_3z0hr7pzpec4-1>li:before{content:"\0025cb  "}.lst-kix_ne2kodfi1kix-5>li:before{content:"\0025a0  "}ul.lst-kix_5iyzxwlmxp1f-6{list-style-type:none}ul.lst-kix_5iyzxwlmxp1f-5{list-style-type:none}ul.lst-kix_5iyzxwlmxp1f-4{list-style-type:none}ul.lst-kix_5iyzxwlmxp1f-3{list-style-type:none}.lst-kix_5s83gilt2o7g-6>li:before{content:"\0025cf  "}ul.lst-kix_5iyzxwlmxp1f-2{list-style-type:none}ul.lst-kix_5iyzxwlmxp1f-1{list-style-type:none}ul.lst-kix_5iyzxwlmxp1f-0{list-style-type:none}ul.lst-kix_5iyzxwlmxp1f-8{list-style-type:none}ul.lst-kix_5iyzxwlmxp1f-7{list-style-type:none}ol.lst-kix_8dw3ycrgt362-7.start{counter-reset:lst-ctn-kix_8dw3ycrgt362-7 0}.lst-kix_5we8o0btcr67-3>li:before{content:"\0025cf  "}.lst-kix_hm0ybxxbxp2l-7>li:before{content:"\0025cb  "}.lst-kix_hm0ybxxbxp2l-6>li:before{content:"\0025cf  "}.lst-kix_8d6owvwxykff-0>li:before{content:"\0025cf  "}.lst-kix_5we8o0btcr67-2>li:before{content:"\0025a0  "}ul.lst-kix_msukp0gxz1c7-6{list-style-type:none}ol.lst-kix_7pcs9kbg0qhi-6.start{counter-reset:lst-ctn-kix_7pcs9kbg0qhi-6 0}ul.lst-kix_msukp0gxz1c7-5{list-style-type:none}ul.lst-kix_msukp0gxz1c7-8{list-style-type:none}.lst-kix_mvnr2hoa94kd-2>li:before{content:"\0025a0  "}ul.lst-kix_msukp0gxz1c7-7{list-style-type:none}ul.lst-kix_msukp0gxz1c7-2{list-style-type:none}.lst-kix_hm0ybxxbxp2l-2>li:before{content:"\0025a0  "}ul.lst-kix_msukp0gxz1c7-1{list-style-type:none}ul.lst-kix_msukp0gxz1c7-4{list-style-type:none}ul.lst-kix_msukp0gxz1c7-3{list-style-type:none}.lst-kix_9uzslqp6q29w-3>li:before{content:"\0025cf  "}ul.lst-kix_msukp0gxz1c7-0{list-style-type:none}.lst-kix_hm0ybxxbxp2l-3>li:before{content:"\0025cf  "}.lst-kix_9uzslqp6q29w-4>li:before{content:"\0025cb  "}.lst-kix_mvnr2hoa94kd-1>li:before{content:"\0025cb  "}.lst-kix_9uzslqp6q29w-0>li:before{content:"\0025cf  "}ul.lst-kix_hait203o5dqo-1{list-style-type:none}ul.lst-kix_hait203o5dqo-0{list-style-type:none}ul.lst-kix_hait203o5dqo-3{list-style-type:none}ul.lst-kix_hait203o5dqo-2{list-style-type:none}ul.lst-kix_hait203o5dqo-5{list-style-type:none}ul.lst-kix_hait203o5dqo-4{list-style-type:none}ul.lst-kix_hait203o5dqo-7{list-style-type:none}.lst-kix_8dw3ycrgt362-1>li{counter-increment:lst-ctn-kix_8dw3ycrgt362-1}ul.lst-kix_hait203o5dqo-6{list-style-type:none}ul.lst-kix_hait203o5dqo-8{list-style-type:none}.lst-kix_8d6owvwxykff-5>li:before{content:"\0025a0  "}.lst-kix_8d6owvwxykff-4>li:before{content:"\0025cb  "}.lst-kix_8d6owvwxykff-1>li:before{content:"\0025cb  "}.lst-kix_7pcs9kbg0qhi-3>li{counter-increment:lst-ctn-kix_7pcs9kbg0qhi-3}.lst-kix_msukp0gxz1c7-7>li:before{content:"\0025cb  "}.lst-kix_msukp0gxz1c7-6>li:before{content:"\0025cf  "}.lst-kix_msukp0gxz1c7-3>li:before{content:"\0025cf  "}.lst-kix_8d6owvwxykff-8>li:before{content:"\0025a0  "}.lst-kix_msukp0gxz1c7-2>li:before{content:"\0025a0  "}.lst-kix_6wlb53t5sfma-3>li:before{content:"\0025cf  "}.lst-kix_3z0hr7pzpec4-2>li:before{content:"\0025a0  "}.lst-kix_3z0hr7pzpec4-6>li:before{content:"\0025cf  "}.lst-kix_6wlb53t5sfma-7>li:before{content:"\0025cb  "}ol.lst-kix_7pcs9kbg0qhi-7.start{counter-reset:lst-ctn-kix_7pcs9kbg0qhi-7 0}.lst-kix_8dw3ycrgt362-8>li{counter-increment:lst-ctn-kix_8dw3ycrgt362-8}.lst-kix_ao97xhpq4hr9-8>li:before{content:"\0025a0  "}.lst-kix_7n1btf6e2iyv-2>li:before{content:"\0025a0  "}.lst-kix_mfwegjdddisb-6>li:before{content:"\0025cf  "}.lst-kix_e8kaqrotva4-6>li:before{content:"\0025cf  "}.lst-kix_ao97xhpq4hr9-4>li:before{content:"\0025cb  "}.lst-kix_ao97xhpq4hr9-0>li:before{content:"\0025cf  "}.lst-kix_7n1btf6e2iyv-6>li:before{content:"\0025cf  "}.lst-kix_mfwegjdddisb-2>li:before{content:"\0025a0  "}.lst-kix_w93gux8gcekz-1>li:before{content:"-  "}.lst-kix_dnm4ke3nhj1e-2>li:before{content:"\0025a0  "}.lst-kix_dnm4ke3nhj1e-6>li:before{content:"\0025cf  "}ul.lst-kix_38adif7m6rbx-0{list-style-type:none}ul.lst-kix_38adif7m6rbx-1{list-style-type:none}ul.lst-kix_38adif7m6rbx-2{list-style-type:none}ul.lst-kix_38adif7m6rbx-3{list-style-type:none}ul.lst-kix_owgllipbp8j5-0{list-style-type:none}.lst-kix_r60cdwx1dlic-2>li:before{content:"\0025a0  "}ul.lst-kix_owgllipbp8j5-1{list-style-type:none}ul.lst-kix_38adif7m6rbx-8{list-style-type:none}ul.lst-kix_owgllipbp8j5-2{list-style-type:none}.lst-kix_9uzslqp6q29w-7>li:before{content:"\0025cb  "}ul.lst-kix_owgllipbp8j5-3{list-style-type:none}ul.lst-kix_owgllipbp8j5-4{list-style-type:none}ul.lst-kix_owgllipbp8j5-5{list-style-type:none}ul.lst-kix_38adif7m6rbx-4{list-style-type:none}ul.lst-kix_owgllipbp8j5-6{list-style-type:none}ul.lst-kix_38adif7m6rbx-5{list-style-type:none}ul.lst-kix_owgllipbp8j5-7{list-style-type:none}ul.lst-kix_38adif7m6rbx-6{list-style-type:none}ul.lst-kix_owgllipbp8j5-8{list-style-type:none}ul.lst-kix_38adif7m6rbx-7{list-style-type:none}.lst-kix_w93gux8gcekz-5>li:before{content:"-  "}.lst-kix_um8gcdc8t9m9-0>li:before{content:"-  "}.lst-kix_e8kaqrotva4-2>li:before{content:"\0025a0  "}.lst-kix_8dw3ycrgt362-8>li:before{content:"" counter(lst-ctn-kix_8dw3ycrgt362-8,lower-roman) ". "}.lst-kix_mvnr2hoa94kd-5>li:before{content:"\0025a0  "}.lst-kix_5we8o0btcr67-6>li:before{content:"\0025cf  "}.lst-kix_ne2kodfi1kix-2>li:before{content:"\0025a0  "}.lst-kix_8dw3ycrgt362-4>li:before{content:"" counter(lst-ctn-kix_8dw3ycrgt362-4,lower-latin) ". "}.lst-kix_5s83gilt2o7g-2>li:before{content:"\0025a0  "}.lst-kix_ne2kodfi1kix-6>li:before{content:"\0025cf  "}.lst-kix_8dw3ycrgt362-0>li:before{content:"" counter(lst-ctn-kix_8dw3ycrgt362-0,decimal) ". "}.lst-kix_r60cdwx1dlic-6>li:before{content:"\0025cf  "}.lst-kix_7pcs9kbg0qhi-6>li:before{content:"" counter(lst-ctn-kix_7pcs9kbg0qhi-6,decimal) ". "}.lst-kix_7pcs9kbg0qhi-1>li:before{content:"" counter(lst-ctn-kix_7pcs9kbg0qhi-1,lower-latin) ". "}.lst-kix_7pcs9kbg0qhi-3>li:before{content:"" counter(lst-ctn-kix_7pcs9kbg0qhi-3,decimal) ". "}ul.lst-kix_rsr7bmzen4a7-0{list-style-type:none}ul.lst-kix_s4rut6kfjze3-2{list-style-type:none}ul.lst-kix_rsr7bmzen4a7-3{list-style-type:none}ul.lst-kix_s4rut6kfjze3-3{list-style-type:none}ul.lst-kix_rsr7bmzen4a7-4{list-style-type:none}ul.lst-kix_s4rut6kfjze3-4{list-style-type:none}ul.lst-kix_rsr7bmzen4a7-1{list-style-type:none}ul.lst-kix_s4rut6kfjze3-5{list-style-type:none}ul.lst-kix_rsr7bmzen4a7-2{list-style-type:none}ul.lst-kix_s4rut6kfjze3-6{list-style-type:none}ul.lst-kix_rsr7bmzen4a7-7{list-style-type:none}.lst-kix_7pcs9kbg0qhi-4>li:before{content:"" counter(lst-ctn-kix_7pcs9kbg0qhi-4,lower-latin) ". "}ul.lst-kix_s4rut6kfjze3-7{list-style-type:none}ul.lst-kix_rsr7bmzen4a7-8{list-style-type:none}ul.lst-kix_s4rut6kfjze3-8{list-style-type:none}ul.lst-kix_rsr7bmzen4a7-5{list-style-type:none}ul.lst-kix_rsr7bmzen4a7-6{list-style-type:none}ul.lst-kix_9sdxipg1h5wr-5{list-style-type:none}ul.lst-kix_9sdxipg1h5wr-4{list-style-type:none}ul.lst-kix_9sdxipg1h5wr-3{list-style-type:none}ul.lst-kix_9sdxipg1h5wr-2{list-style-type:none}ul.lst-kix_9sdxipg1h5wr-8{list-style-type:none}ul.lst-kix_s4rut6kfjze3-0{list-style-type:none}ul.lst-kix_9sdxipg1h5wr-7{list-style-type:none}ul.lst-kix_s4rut6kfjze3-1{list-style-type:none}ul.lst-kix_9sdxipg1h5wr-6{list-style-type:none}.lst-kix_9sdxipg1h5wr-8>li:before{content:"\0025a0  "}.lst-kix_8dw3ycrgt362-2>li{counter-increment:lst-ctn-kix_8dw3ycrgt362-2}.lst-kix_9sdxipg1h5wr-7>li:before{content:"\0025cb  "}ul.lst-kix_9sdxipg1h5wr-1{list-style-type:none}ul.lst-kix_9sdxipg1h5wr-0{list-style-type:none}.lst-kix_9sdxipg1h5wr-5>li:before{content:"\0025a0  "}.lst-kix_9sdxipg1h5wr-0>li:before{content:"\0025cf  "}.lst-kix_9sdxipg1h5wr-2>li:before{content:"\0025a0  "}.lst-kix_3bekfbfd6o8j-7>li:before{content:"\0025cb  "}.lst-kix_hait203o5dqo-4>li:before{content:"-  "}.lst-kix_hait203o5dqo-2>li:before{content:"-  "}.lst-kix_hait203o5dqo-1>li:before{content:"-  "}.lst-kix_2aliey961vrg-0>li:before{content:"\0025cf  "}.lst-kix_6wlb53t5sfma-2>li:before{content:"\0025a0  "}.lst-kix_2aliey961vrg-5>li:before{content:"\0025a0  "}.lst-kix_lqb82f5hzmh3-3>li:before{content:"\0025cf  "}.lst-kix_2aliey961vrg-3>li:before{content:"\0025cf  "}.lst-kix_6wlb53t5sfma-0>li:before{content:"\0025cf  "}.lst-kix_6wlb53t5sfma-8>li:before{content:"\0025a0  "}.lst-kix_38adif7m6rbx-6>li:before{content:"\0025cf  "}.lst-kix_lqb82f5hzmh3-1>li:before{content:"\0025cb  "}.lst-kix_38adif7m6rbx-8>li:before{content:"\0025a0  "}ul.lst-kix_w93gux8gcekz-8{list-style-type:none}.lst-kix_e8kaqrotva4-7>li:before{content:"\0025cb  "}.lst-kix_c4453ihcjob0-1>li:before{content:"\0025cb  "}.lst-kix_3bekfbfd6o8j-1>li:before{content:"\0025cb  "}.lst-kix_8dw3ycrgt362-6>li{counter-increment:lst-ctn-kix_8dw3ycrgt362-6}.lst-kix_r60cdwx1dlic-3>li:before{content:"\0025cf  "}.lst-kix_w93gux8gcekz-0>li:before{content:"-  "}.lst-kix_w93gux8gcekz-8>li:before{content:"-  "}.lst-kix_e8kaqrotva4-1>li:before{content:"\0025cb  "}.lst-kix_w93gux8gcekz-6>li:before{content:"-  "}ul.lst-kix_w93gux8gcekz-7{list-style-type:none}ul.lst-kix_w93gux8gcekz-6{list-style-type:none}.lst-kix_9i19e8txouig-4>li:before{content:"\0025cb  "}ul.lst-kix_w93gux8gcekz-5{list-style-type:none}ul.lst-kix_w93gux8gcekz-4{list-style-type:none}ul.lst-kix_w93gux8gcekz-3{list-style-type:none}.lst-kix_9uzslqp6q29w-8>li:before{content:"\0025a0  "}ul.lst-kix_w93gux8gcekz-2{list-style-type:none}.lst-kix_9i19e8txouig-2>li:before{content:"\0025a0  "}.lst-kix_c4453ihcjob0-7>li:before{content:"\0025cb  "}ul.lst-kix_w93gux8gcekz-1{list-style-type:none}ul.lst-kix_w93gux8gcekz-0{list-style-type:none}.lst-kix_6shy0i3drli2-6>li:before{content:"-  "}.lst-kix_38adif7m6rbx-0>li:before{content:"\0025cf  "}.lst-kix_r60cdwx1dlic-5>li:before{content:"\0025a0  "}.lst-kix_6shy0i3drli2-4>li:before{content:"-  "}.lst-kix_owgllipbp8j5-4>li:before{content:"\0025cb  "}.lst-kix_5s83gilt2o7g-7>li:before{content:"\0025cb  "}.lst-kix_g3mw20emt8ab-8>li:before{content:"\0025a0  "}.lst-kix_5we8o0btcr67-5>li:before{content:"\0025a0  "}ul.lst-kix_mfwegjdddisb-6{list-style-type:none}.lst-kix_5we8o0btcr67-0>li:before{content:"\0025cf  "}ul.lst-kix_mfwegjdddisb-5{list-style-type:none}ul.lst-kix_mfwegjdddisb-4{list-style-type:none}ul.lst-kix_mfwegjdddisb-3{list-style-type:none}.lst-kix_g3mw20emt8ab-5>li:before{content:"\0025a0  "}ul.lst-kix_mfwegjdddisb-8{list-style-type:none}ul.lst-kix_mfwegjdddisb-7{list-style-type:none}.lst-kix_hm0ybxxbxp2l-1>li:before{content:"\0025cb  "}.lst-kix_mvnr2hoa94kd-4>li:before{content:"\0025cb  "}.lst-kix_hm0ybxxbxp2l-4>li:before{content:"\0025cb  "}.lst-kix_9uzslqp6q29w-2>li:before{content:"\0025a0  "}ul.lst-kix_lqb82f5hzmh3-0{list-style-type:none}ul.lst-kix_5gii2tr4ae90-1{list-style-type:none}ul.lst-kix_5gii2tr4ae90-0{list-style-type:none}ul.lst-kix_5gii2tr4ae90-3{list-style-type:none}ul.lst-kix_5gii2tr4ae90-2{list-style-type:none}ul.lst-kix_5gii2tr4ae90-5{list-style-type:none}ul.lst-kix_5gii2tr4ae90-4{list-style-type:none}ul.lst-kix_5gii2tr4ae90-7{list-style-type:none}ul.lst-kix_5gii2tr4ae90-6{list-style-type:none}ul.lst-kix_5gii2tr4ae90-8{list-style-type:none}.lst-kix_7pcs9kbg0qhi-7>li{counter-increment:lst-ctn-kix_7pcs9kbg0qhi-7}ul.lst-kix_ne2kodfi1kix-3{list-style-type:none}ul.lst-kix_ne2kodfi1kix-2{list-style-type:none}.lst-kix_p3wa2k83s8cn-2>li:before{content:"\0025a0  "}ul.lst-kix_ne2kodfi1kix-1{list-style-type:none}ul.lst-kix_ne2kodfi1kix-0{list-style-type:none}ul.lst-kix_ne2kodfi1kix-7{list-style-type:none}ul.lst-kix_ne2kodfi1kix-6{list-style-type:none}ul.lst-kix_ne2kodfi1kix-5{list-style-type:none}ul.lst-kix_ne2kodfi1kix-4{list-style-type:none}.lst-kix_rsr7bmzen4a7-6>li:before{content:"\0025cf  "}ul.lst-kix_ne2kodfi1kix-8{list-style-type:none}.lst-kix_p3wa2k83s8cn-5>li:before{content:"\0025a0  "}.lst-kix_jbicnccaji3d-2>li:before{content:"\0025a0  "}ul.lst-kix_lqb82f5hzmh3-2{list-style-type:none}ul.lst-kix_lqb82f5hzmh3-1{list-style-type:none}ul.lst-kix_lqb82f5hzmh3-4{list-style-type:none}ul.lst-kix_lqb82f5hzmh3-3{list-style-type:none}ul.lst-kix_lqb82f5hzmh3-6{list-style-type:none}ul.lst-kix_lqb82f5hzmh3-5{list-style-type:none}ul.lst-kix_lqb82f5hzmh3-8{list-style-type:none}ul.lst-kix_lqb82f5hzmh3-7{list-style-type:none}.lst-kix_rop5sudr37z1-4>li:before{content:"\0025cb  "}.lst-kix_jbicnccaji3d-5>li:before{content:"\0025a0  "}.lst-kix_8d6owvwxykff-6>li:before{content:"\0025cf  "}ul.lst-kix_mfwegjdddisb-2{list-style-type:none}.lst-kix_msukp0gxz1c7-1>li:before{content:"\0025cb  "}ul.lst-kix_mfwegjdddisb-1{list-style-type:none}.lst-kix_rop5sudr37z1-7>li:before{content:"\0025cb  "}ul.lst-kix_mfwegjdddisb-0{list-style-type:none}.lst-kix_7pcs9kbg0qhi-0>li{counter-increment:lst-ctn-kix_7pcs9kbg0qhi-0}.lst-kix_3sh9r2c1w16g-4>li:before{content:"\0025cb  "}.lst-kix_8d6owvwxykff-3>li:before{content:"\0025cf  "}.lst-kix_g3mw20emt8ab-0>li:before{content:"\0025cf  "}.lst-kix_3sh9r2c1w16g-1>li:before{content:"\0025cb  "}.lst-kix_msukp0gxz1c7-4>li:before{content:"\0025cb  "}.lst-kix_rsr7bmzen4a7-1>li:before{content:"\0025cb  "}.lst-kix_6wlb53t5sfma-5>li:before{content:"\0025a0  "}.lst-kix_lqb82f5hzmh3-6>li:before{content:"\0025cf  "}ul.lst-kix_um8gcdc8t9m9-1{list-style-type:none}ul.lst-kix_um8gcdc8t9m9-2{list-style-type:none}ul.lst-kix_um8gcdc8t9m9-0{list-style-type:none}.lst-kix_3z0hr7pzpec4-4>li:before{content:"\0025cb  "}ul.lst-kix_um8gcdc8t9m9-5{list-style-type:none}ul.lst-kix_um8gcdc8t9m9-6{list-style-type:none}.lst-kix_38adif7m6rbx-3>li:before{content:"\0025cf  "}ul.lst-kix_um8gcdc8t9m9-3{list-style-type:none}ul.lst-kix_um8gcdc8t9m9-4{list-style-type:none}ul.lst-kix_6shy0i3drli2-7{list-style-type:none}ul.lst-kix_6shy0i3drli2-6{list-style-type:none}ul.lst-kix_um8gcdc8t9m9-7{list-style-type:none}ul.lst-kix_um8gcdc8t9m9-8{list-style-type:none}ul.lst-kix_6shy0i3drli2-8{list-style-type:none}.lst-kix_2aliey961vrg-8>li:before{content:"\0025a0  "}.lst-kix_s4rut6kfjze3-2>li:before{content:"\0025a0  "}.lst-kix_47504ojh0ba1-8>li:before{content:"\0025a0  "}.lst-kix_hait203o5dqo-7>li:before{content:"-  "}ul.lst-kix_6shy0i3drli2-3{list-style-type:none}.lst-kix_5gii2tr4ae90-7>li:before{content:"\0025cb  "}.lst-kix_mfwegjdddisb-0>li:before{content:"\0025cf  "}ul.lst-kix_6shy0i3drli2-2{list-style-type:none}.lst-kix_mfwegjdddisb-8>li:before{content:"\0025a0  "}ul.lst-kix_6shy0i3drli2-5{list-style-type:none}ul.lst-kix_6shy0i3drli2-4{list-style-type:none}.lst-kix_9i19e8txouig-7>li:before{content:"\0025cb  "}ul.lst-kix_6shy0i3drli2-1{list-style-type:none}ul.lst-kix_6shy0i3drli2-0{list-style-type:none}.lst-kix_3bekfbfd6o8j-4>li:before{content:"\0025cb  "}.lst-kix_7n1btf6e2iyv-4>li:before{content:"\0025cb  "}.lst-kix_ao97xhpq4hr9-2>li:before{content:"\0025a0  "}.lst-kix_9reixuath9e3-5>li:before{content:"\0025a0  "}ul.lst-kix_g3mw20emt8ab-8{list-style-type:none}.lst-kix_w93gux8gcekz-3>li:before{content:"-  "}.lst-kix_rj34zh1l62l0-8>li:before{content:"\0025a0  "}.lst-kix_r60cdwx1dlic-0>li:before{content:"\0025cf  "}.lst-kix_vd8i8whhh56x-1>li:before{content:"-  "}ul.lst-kix_g3mw20emt8ab-0{list-style-type:none}ul.lst-kix_g3mw20emt8ab-1{list-style-type:none}ul.lst-kix_g3mw20emt8ab-2{list-style-type:none}.lst-kix_dnm4ke3nhj1e-0>li:before{content:"\0025cf  "}ul.lst-kix_g3mw20emt8ab-3{list-style-type:none}ul.lst-kix_g3mw20emt8ab-4{list-style-type:none}.lst-kix_c4453ihcjob0-4>li:before{content:"\0025cb  "}ul.lst-kix_g3mw20emt8ab-5{list-style-type:none}ul.lst-kix_g3mw20emt8ab-6{list-style-type:none}ul.lst-kix_g3mw20emt8ab-7{list-style-type:none}.lst-kix_rj34zh1l62l0-0>li:before{content:"\0025cf  "}.lst-kix_9uzslqp6q29w-5>li:before{content:"\0025a0  "}.lst-kix_e8kaqrotva4-4>li:before{content:"\0025cb  "}.lst-kix_5iyzxwlmxp1f-5>li:before{content:"\0025a0  "}.lst-kix_47504ojh0ba1-0>li:before{content:"\0025cf  "}.lst-kix_6shy0i3drli2-1>li:before{content:"-  "}.lst-kix_8dw3ycrgt362-6>li:before{content:"" counter(lst-ctn-kix_8dw3ycrgt362-6,decimal) ". "}.lst-kix_mvnr2hoa94kd-7>li:before{content:"\0025cb  "}.lst-kix_ne2kodfi1kix-0>li:before{content:"\0025cf  "}ul.lst-kix_rc9zyflo7924-8{list-style-type:none}ul.lst-kix_rc9zyflo7924-7{list-style-type:none}ul.lst-kix_rj34zh1l62l0-7{list-style-type:none}ul.lst-kix_rc9zyflo7924-4{list-style-type:none}ul.lst-kix_rj34zh1l62l0-8{list-style-type:none}ul.lst-kix_rc9zyflo7924-3{list-style-type:none}ul.lst-kix_rc9zyflo7924-6{list-style-type:none}.lst-kix_r60cdwx1dlic-8>li:before{content:"\0025a0  "}ul.lst-kix_rc9zyflo7924-5{list-style-type:none}.lst-kix_5we8o0btcr67-8>li:before{content:"\0025a0  "}.lst-kix_5s83gilt2o7g-4>li:before{content:"\0025cb  "}ul.lst-kix_rj34zh1l62l0-3{list-style-type:none}ul.lst-kix_rc9zyflo7924-0{list-style-type:none}ul.lst-kix_rj34zh1l62l0-4{list-style-type:none}.lst-kix_owgllipbp8j5-1>li:before{content:"\0025cb  "}ul.lst-kix_rj34zh1l62l0-5{list-style-type:none}ul.lst-kix_rc9zyflo7924-2{list-style-type:none}ul.lst-kix_rj34zh1l62l0-6{list-style-type:none}ul.lst-kix_rc9zyflo7924-1{list-style-type:none}ul.lst-kix_rj34zh1l62l0-0{list-style-type:none}ul.lst-kix_rj34zh1l62l0-1{list-style-type:none}ul.lst-kix_rj34zh1l62l0-2{list-style-type:none}.lst-kix_rc9zyflo7924-0>li:before{content:"\0025cf  "}.lst-kix_rc9zyflo7924-2>li:before{content:"\0025a0  "}.lst-kix_rc9zyflo7924-3>li:before{content:"\0025cf  "}.lst-kix_rc9zyflo7924-1>li:before{content:"\0025cb  "}.lst-kix_8dw3ycrgt362-4>li{counter-increment:lst-ctn-kix_8dw3ycrgt362-4}ul.lst-kix_5s83gilt2o7g-0{list-style-type:none}ul.lst-kix_47504ojh0ba1-8{list-style-type:none}ul.lst-kix_5s83gilt2o7g-4{list-style-type:none}ul.lst-kix_5s83gilt2o7g-3{list-style-type:none}ul.lst-kix_5s83gilt2o7g-2{list-style-type:none}ul.lst-kix_5s83gilt2o7g-1{list-style-type:none}ul.lst-kix_5s83gilt2o7g-8{list-style-type:none}ul.lst-kix_5s83gilt2o7g-7{list-style-type:none}ul.lst-kix_5s83gilt2o7g-6{list-style-type:none}ul.lst-kix_5s83gilt2o7g-5{list-style-type:none}ul.lst-kix_47504ojh0ba1-2{list-style-type:none}ul.lst-kix_47504ojh0ba1-3{list-style-type:none}ul.lst-kix_47504ojh0ba1-0{list-style-type:none}ul.lst-kix_47504ojh0ba1-1{list-style-type:none}ul.lst-kix_47504ojh0ba1-6{list-style-type:none}ul.lst-kix_47504ojh0ba1-7{list-style-type:none}ul.lst-kix_47504ojh0ba1-4{list-style-type:none}ul.lst-kix_47504ojh0ba1-5{list-style-type:none}.lst-kix_rc9zyflo7924-8>li:before{content:"\0025a0  "}ol.lst-kix_7pcs9kbg0qhi-4.start{counter-reset:lst-ctn-kix_7pcs9kbg0qhi-4 0}.lst-kix_rc9zyflo7924-7>li:before{content:"\0025cb  "}.lst-kix_rc9zyflo7924-4>li:before{content:"\0025cb  "}.lst-kix_rc9zyflo7924-6>li:before{content:"\0025cf  "}.lst-kix_rc9zyflo7924-5>li:before{content:"\0025a0  "}.lst-kix_9reixuath9e3-6>li:before{content:"\0025cf  "}ol.lst-kix_8dw3ycrgt362-5{list-style-type:none}ol.lst-kix_8dw3ycrgt362-6{list-style-type:none}ol.lst-kix_8dw3ycrgt362-7{list-style-type:none}ol.lst-kix_8dw3ycrgt362-8{list-style-type:none}.lst-kix_9reixuath9e3-2>li:before{content:"\0025a0  "}.lst-kix_9reixuath9e3-8>li:before{content:"\0025a0  "}.lst-kix_9reixuath9e3-0>li:before{content:"\0025cf  "}.lst-kix_s4rut6kfjze3-7>li:before{content:"\0025cb  "}ul.lst-kix_6wlb53t5sfma-1{list-style-type:none}ul.lst-kix_6wlb53t5sfma-0{list-style-type:none}ul.lst-kix_6wlb53t5sfma-3{list-style-type:none}ul.lst-kix_6wlb53t5sfma-2{list-style-type:none}ol.lst-kix_7pcs9kbg0qhi-7{list-style-type:none}.lst-kix_47504ojh0ba1-5>li:before{content:"\0025a0  "}ol.lst-kix_7pcs9kbg0qhi-8{list-style-type:none}ul.lst-kix_6wlb53t5sfma-8{list-style-type:none}ol.lst-kix_7pcs9kbg0qhi-5{list-style-type:none}ol.lst-kix_7pcs9kbg0qhi-6{list-style-type:none}ul.lst-kix_6wlb53t5sfma-5{list-style-type:none}.lst-kix_47504ojh0ba1-3>li:before{content:"\0025cf  "}.lst-kix_47504ojh0ba1-7>li:before{content:"\0025cb  "}ul.lst-kix_6wlb53t5sfma-4{list-style-type:none}ul.lst-kix_6wlb53t5sfma-7{list-style-type:none}ul.lst-kix_3sh9r2c1w16g-8{list-style-type:none}.lst-kix_s4rut6kfjze3-3>li:before{content:"\0025cf  "}ul.lst-kix_6wlb53t5sfma-6{list-style-type:none}ul.lst-kix_3sh9r2c1w16g-7{list-style-type:none}.lst-kix_5gii2tr4ae90-8>li:before{content:"\0025a0  "}.lst-kix_47504ojh0ba1-1>li:before{content:"\0025cb  "}ol.lst-kix_8dw3ycrgt362-5.start{counter-reset:lst-ctn-kix_8dw3ycrgt362-5 0}.lst-kix_s4rut6kfjze3-5>li:before{content:"\0025a0  "}ol.lst-kix_8dw3ycrgt362-1{list-style-type:none}ul.lst-kix_3sh9r2c1w16g-6{list-style-type:none}ol.lst-kix_8dw3ycrgt362-2{list-style-type:none}ul.lst-kix_3sh9r2c1w16g-5{list-style-type:none}ol.lst-kix_8dw3ycrgt362-3{list-style-type:none}ul.lst-kix_3sh9r2c1w16g-4{list-style-type:none}ol.lst-kix_8dw3ycrgt362-4{list-style-type:none}.lst-kix_9reixuath9e3-4>li:before{content:"\0025cb  "}ul.lst-kix_3sh9r2c1w16g-3{list-style-type:none}ul.lst-kix_3sh9r2c1w16g-2{list-style-type:none}ul.lst-kix_3sh9r2c1w16g-1{list-style-type:none}ul.lst-kix_3sh9r2c1w16g-0{list-style-type:none}ol.lst-kix_8dw3ycrgt362-0{list-style-type:none}.lst-kix_s4rut6kfjze3-1>li:before{content:"\0025cb  "}.lst-kix_vd8i8whhh56x-2>li:before{content:"-  "}.lst-kix_vd8i8whhh56x-4>li:before{content:"-  "}ul.lst-kix_c4453ihcjob0-1{list-style-type:none}ul.lst-kix_c4453ihcjob0-2{list-style-type:none}ul.lst-kix_c4453ihcjob0-0{list-style-type:none}.lst-kix_rj34zh1l62l0-5>li:before{content:"\0025a0  "}ul.lst-kix_c4453ihcjob0-5{list-style-type:none}ul.lst-kix_c4453ihcjob0-6{list-style-type:none}ul.lst-kix_9reixuath9e3-0{list-style-type:none}ul.lst-kix_c4453ihcjob0-3{list-style-type:none}.lst-kix_5gii2tr4ae90-0>li:before{content:"\0025cf  "}ul.lst-kix_c4453ihcjob0-4{list-style-type:none}.lst-kix_vd8i8whhh56x-0>li:before{content:"-  "}.lst-kix_vd8i8whhh56x-6>li:before{content:"-  "}.lst-kix_vd8i8whhh56x-8>li:before{content:"-  "}ul.lst-kix_9reixuath9e3-2{list-style-type:none}ul.lst-kix_9reixuath9e3-1{list-style-type:none}ul.lst-kix_9reixuath9e3-4{list-style-type:none}ul.lst-kix_c4453ihcjob0-7{list-style-type:none}ul.lst-kix_9reixuath9e3-3{list-style-type:none}ul.lst-kix_c4453ihcjob0-8{list-style-type:none}.lst-kix_rj34zh1l62l0-7>li:before{content:"\0025cb  "}ul.lst-kix_9reixuath9e3-6{list-style-type:none}ul.lst-kix_9reixuath9e3-5{list-style-type:none}ul.lst-kix_9reixuath9e3-8{list-style-type:none}ul.lst-kix_9reixuath9e3-7{list-style-type:none}.lst-kix_5gii2tr4ae90-2>li:before{content:"\0025a0  "}.lst-kix_5gii2tr4ae90-4>li:before{content:"\0025cb  "}.lst-kix_5iyzxwlmxp1f-8>li:before{content:"\0025a0  "}.lst-kix_rj34zh1l62l0-1>li:before{content:"\0025cb  "}ol.lst-kix_7pcs9kbg0qhi-0{list-style-type:none}.lst-kix_5gii2tr4ae90-6>li:before{content:"\0025cf  "}.lst-kix_5iyzxwlmxp1f-6>li:before{content:"\0025cf  "}ol.lst-kix_7pcs9kbg0qhi-3{list-style-type:none}ol.lst-kix_7pcs9kbg0qhi-4{list-style-type:none}ol.lst-kix_7pcs9kbg0qhi-1{list-style-type:none}ol.lst-kix_7pcs9kbg0qhi-2{list-style-type:none}.lst-kix_rj34zh1l62l0-3>li:before{content:"\0025cf  "}.lst-kix_5iyzxwlmxp1f-0>li:before{content:"\0025cf  "}.lst-kix_5iyzxwlmxp1f-2>li:before{content:"\0025a0  "}.lst-kix_5iyzxwlmxp1f-4>li:before{content:"\0025cb  "}ul.lst-kix_rop5sudr37z1-0{list-style-type:none}ul.lst-kix_rop5sudr37z1-1{list-style-type:none}ul.lst-kix_rop5sudr37z1-2{list-style-type:none}ul.lst-kix_rop5sudr37z1-3{list-style-type:none}.lst-kix_8dw3ycrgt362-3>li{counter-increment:lst-ctn-kix_8dw3ycrgt362-3}.lst-kix_g3mw20emt8ab-6>li:before{content:"\0025cf  "}.lst-kix_owgllipbp8j5-0>li:before{content:"\0025cf  "}.lst-kix_g3mw20emt8ab-7>li:before{content:"\0025cb  "}.lst-kix_owgllipbp8j5-6>li:before{content:"\0025cf  "}.lst-kix_owgllipbp8j5-7>li:before{content:"\0025cb  "}.lst-kix_g3mw20emt8ab-2>li:before{content:"\0025a0  "}.lst-kix_g3mw20emt8ab-3>li:before{content:"\0025cf  "}ul.lst-kix_rop5sudr37z1-8{list-style-type:none}ul.lst-kix_rop5sudr37z1-4{list-style-type:none}ul.lst-kix_rop5sudr37z1-5{list-style-type:none}ul.lst-kix_rop5sudr37z1-6{list-style-type:none}ul.lst-kix_rop5sudr37z1-7{list-style-type:none}.lst-kix_8dw3ycrgt362-5>li{counter-increment:lst-ctn-kix_8dw3ycrgt362-5}.lst-kix_rop5sudr37z1-2>li:before{content:"\0025a0  "}.lst-kix_rop5sudr37z1-1>li:before{content:"\0025cb  "}.lst-kix_p3wa2k83s8cn-0>li:before{content:"\0025cf  "}.lst-kix_p3wa2k83s8cn-3>li:before{content:"\0025cf  "}.lst-kix_jbicnccaji3d-3>li:before{content:"\0025cf  "}.lst-kix_jbicnccaji3d-0>li:before{content:"\0025cf  "}.lst-kix_jbicnccaji3d-4>li:before{content:"\0025cb  "}.lst-kix_rsr7bmzen4a7-7>li:before{content:"\0025cb  "}ul.lst-kix_7n1btf6e2iyv-3{list-style-type:none}.lst-kix_rsr7bmzen4a7-4>li:before{content:"\0025cb  "}ul.lst-kix_7n1btf6e2iyv-2{list-style-type:none}.lst-kix_p3wa2k83s8cn-4>li:before{content:"\0025cb  "}ul.lst-kix_7n1btf6e2iyv-1{list-style-type:none}ul.lst-kix_7n1btf6e2iyv-0{list-style-type:none}.lst-kix_jbicnccaji3d-8>li:before{content:"\0025a0  "}.lst-kix_jbicnccaji3d-7>li:before{content:"\0025cb  "}.lst-kix_p3wa2k83s8cn-7>li:before{content:"\0025cb  "}ol.lst-kix_7pcs9kbg0qhi-5.start{counter-reset:lst-ctn-kix_7pcs9kbg0qhi-5 0}.lst-kix_3sh9r2c1w16g-6>li:before{content:"\0025cf  "}.lst-kix_rop5sudr37z1-6>li:before{content:"\0025cf  "}.lst-kix_rsr7bmzen4a7-8>li:before{content:"\0025a0  "}.lst-kix_3sh9r2c1w16g-7>li:before{content:"\0025cb  "}.lst-kix_p3wa2k83s8cn-8>li:before{content:"\0025a0  "}.lst-kix_rop5sudr37z1-5>li:before{content:"\0025a0  "}.lst-kix_3sh9r2c1w16g-3>li:before{content:"\0025cf  "}.lst-kix_3sh9r2c1w16g-2>li:before{content:"\0025a0  "}.lst-kix_rsr7bmzen4a7-3>li:before{content:"\0025cf  "}.lst-kix_rsr7bmzen4a7-0>li:before{content:"\0025cf  "}ul.lst-kix_r60cdwx1dlic-8{list-style-type:none}.lst-kix_2aliey961vrg-6>li:before{content:"\0025cf  "}.lst-kix_lqb82f5hzmh3-4>li:before{content:"\0025cb  "}ul.lst-kix_r60cdwx1dlic-5{list-style-type:none}ul.lst-kix_r60cdwx1dlic-4{list-style-type:none}ul.lst-kix_r60cdwx1dlic-7{list-style-type:none}.lst-kix_7pcs9kbg0qhi-1>li{counter-increment:lst-ctn-kix_7pcs9kbg0qhi-1}.lst-kix_9reixuath9e3-3>li:before{content:"\0025cf  "}.lst-kix_9reixuath9e3-7>li:before{content:"\0025cb  "}ul.lst-kix_r60cdwx1dlic-6{list-style-type:none}ul.lst-kix_r60cdwx1dlic-1{list-style-type:none}ul.lst-kix_r60cdwx1dlic-0{list-style-type:none}.lst-kix_2aliey961vrg-2>li:before{content:"\0025a0  "}ul.lst-kix_r60cdwx1dlic-3{list-style-type:none}ul.lst-kix_r60cdwx1dlic-2{list-style-type:none}.lst-kix_s4rut6kfjze3-8>li:before{content:"\0025a0  "}.lst-kix_38adif7m6rbx-5>li:before{content:"\0025a0  "}.lst-kix_lqb82f5hzmh3-0>li:before{content:"\0025cf  "}.lst-kix_s4rut6kfjze3-0>li:before{content:"\0025cf  "}ul.lst-kix_9i19e8txouig-8{list-style-type:none}ul.lst-kix_5we8o0btcr67-0{list-style-type:none}ul.lst-kix_9i19e8txouig-6{list-style-type:none}ul.lst-kix_9i19e8txouig-7{list-style-type:none}ul.lst-kix_9i19e8txouig-4{list-style-type:none}ul.lst-kix_5we8o0btcr67-3{list-style-type:none}.lst-kix_9i19e8txouig-5>li:before{content:"\0025a0  "}ul.lst-kix_9i19e8txouig-5{list-style-type:none}ul.lst-kix_5we8o0btcr67-4{list-style-type:none}ul.lst-kix_9i19e8txouig-2{list-style-type:none}ul.lst-kix_5we8o0btcr67-1{list-style-type:none}ul.lst-kix_9i19e8txouig-3{list-style-type:none}ul.lst-kix_5we8o0btcr67-2{list-style-type:none}.lst-kix_s4rut6kfjze3-4>li:before{content:"\0025cb  "}ul.lst-kix_9i19e8txouig-0{list-style-type:none}ul.lst-kix_5we8o0btcr67-7{list-style-type:none}ul.lst-kix_9i19e8txouig-1{list-style-type:none}ul.lst-kix_5we8o0btcr67-8{list-style-type:none}ul.lst-kix_5we8o0btcr67-5{list-style-type:none}.lst-kix_47504ojh0ba1-2>li:before{content:"\0025a0  "}ul.lst-kix_5we8o0btcr67-6{list-style-type:none}ul.lst-kix_7n1btf6e2iyv-7{list-style-type:none}ul.lst-kix_jbicnccaji3d-0{list-style-type:none}ul.lst-kix_7n1btf6e2iyv-6{list-style-type:none}ul.lst-kix_jbicnccaji3d-1{list-style-type:none}ul.lst-kix_7n1btf6e2iyv-5{list-style-type:none}ul.lst-kix_jbicnccaji3d-2{list-style-type:none}ul.lst-kix_7n1btf6e2iyv-4{list-style-type:none}ul.lst-kix_jbicnccaji3d-3{list-style-type:none}ul.lst-kix_7n1btf6e2iyv-8{list-style-type:none}ul.lst-kix_jbicnccaji3d-8{list-style-type:none}.lst-kix_3bekfbfd6o8j-2>li:before{content:"\0025a0  "}ul.lst-kix_jbicnccaji3d-4{list-style-type:none}.lst-kix_lqb82f5hzmh3-8>li:before{content:"\0025a0  "}ul.lst-kix_jbicnccaji3d-5{list-style-type:none}ul.lst-kix_jbicnccaji3d-6{list-style-type:none}.lst-kix_47504ojh0ba1-6>li:before{content:"\0025cf  "}ul.lst-kix_jbicnccaji3d-7{list-style-type:none}.lst-kix_c4453ihcjob0-6>li:before{content:"\0025cf  "}.lst-kix_c4453ihcjob0-2>li:before{content:"\0025a0  "}.lst-kix_rj34zh1l62l0-6>li:before{content:"\0025cf  "}.lst-kix_5gii2tr4ae90-1>li:before{content:"\0025cb  "}.lst-kix_vd8i8whhh56x-7>li:before{content:"-  "}.lst-kix_9i19e8txouig-1>li:before{content:"\0025cb  "}.lst-kix_rj34zh1l62l0-2>li:before{content:"\0025a0  "}ol.lst-kix_7pcs9kbg0qhi-8.start{counter-reset:lst-ctn-kix_7pcs9kbg0qhi-8 0}.lst-kix_5gii2tr4ae90-5>li:before{content:"\0025a0  "}.lst-kix_5iyzxwlmxp1f-7>li:before{content:"\0025cb  "}.lst-kix_6shy0i3drli2-3>li:before{content:"-  "}.lst-kix_6shy0i3drli2-7>li:before{content:"-  "}.lst-kix_7pcs9kbg0qhi-8>li{counter-increment:lst-ctn-kix_7pcs9kbg0qhi-8}.lst-kix_5iyzxwlmxp1f-3>li:before{content:"\0025cf  "}.lst-kix_38adif7m6rbx-1>li:before{content:"\0025cb  "}.lst-kix_owgllipbp8j5-3>li:before{content:"\0025cf  "}.lst-kix_vd8i8whhh56x-3>li:before{content:"-  "}ol.lst-kix_8dw3ycrgt362-4.start{counter-reset:lst-ctn-kix_8dw3ycrgt362-4 0}.lst-kix_7pcs9kbg0qhi-7>li:before{content:"" counter(lst-ctn-kix_7pcs9kbg0qhi-7,lower-latin) ". "}.lst-kix_7pcs9kbg0qhi-8>li:before{content:"" counter(lst-ctn-kix_7pcs9kbg0qhi-8,lower-roman) ". "}.lst-kix_7pcs9kbg0qhi-2>li:before{content:"" counter(lst-ctn-kix_7pcs9kbg0qhi-2,lower-roman) ". "}ol.lst-kix_7pcs9kbg0qhi-3.start{counter-reset:lst-ctn-kix_7pcs9kbg0qhi-3 0}.lst-kix_7pcs9kbg0qhi-5>li:before{content:"" counter(lst-ctn-kix_7pcs9kbg0qhi-5,lower-roman) ". "}.lst-kix_9sdxipg1h5wr-6>li:before{content:"\0025cf  "}.lst-kix_9sdxipg1h5wr-3>li:before{content:"\0025cf  "}.lst-kix_9sdxipg1h5wr-4>li:before{content:"\0025cb  "}.lst-kix_9sdxipg1h5wr-1>li:before{content:"\0025cb  "}.lst-kix_3bekfbfd6o8j-6>li:before{content:"\0025cf  "}.lst-kix_3bekfbfd6o8j-8>li:before{content:"\0025a0  "}.lst-kix_hait203o5dqo-5>li:before{content:"-  "}.lst-kix_hait203o5dqo-3>li:before{content:"-  "}.lst-kix_7pcs9kbg0qhi-6>li{counter-increment:lst-ctn-kix_7pcs9kbg0qhi-6}.lst-kix_hait203o5dqo-0>li:before{content:"-  "}.lst-kix_7pcs9kbg0qhi-0>li:before{content:"" counter(lst-ctn-kix_7pcs9kbg0qhi-0,decimal) ". "}.lst-kix_2aliey961vrg-1>li:before{content:"\0025cb  "}.lst-kix_2aliey961vrg-7>li:before{content:"\0025cb  "}.lst-kix_6wlb53t5sfma-4>li:before{content:"\0025cb  "}.lst-kix_6wlb53t5sfma-6>li:before{content:"\0025cf  "}.lst-kix_lqb82f5hzmh3-5>li:before{content:"\0025a0  "}.lst-kix_38adif7m6rbx-4>li:before{content:"\0025cb  "}.lst-kix_9i19e8txouig-8>li:before{content:"\0025a0  "}.lst-kix_hait203o5dqo-6>li:before{content:"-  "}.lst-kix_e8kaqrotva4-5>li:before{content:"\0025a0  "}.lst-kix_hait203o5dqo-8>li:before{content:"-  "}.lst-kix_9i19e8txouig-6>li:before{content:"\0025cf  "}.lst-kix_3bekfbfd6o8j-5>li:before{content:"\0025a0  "}.lst-kix_lqb82f5hzmh3-7>li:before{content:"\0025cb  "}.lst-kix_3bekfbfd6o8j-3>li:before{content:"\0025cf  "}.lst-kix_w93gux8gcekz-2>li:before{content:"-  "}.lst-kix_c4453ihcjob0-5>li:before{content:"\0025a0  "}.lst-kix_r60cdwx1dlic-1>li:before{content:"\0025cb  "}.lst-kix_c4453ihcjob0-3>li:before{content:"\0025cf  "}.lst-kix_9uzslqp6q29w-6>li:before{content:"\0025cf  "}.lst-kix_9i19e8txouig-0>li:before{content:"\0025cf  "}.lst-kix_mvnr2hoa94kd-6>li:before{content:"\0025cf  "}.lst-kix_w93gux8gcekz-4>li:before{content:"-  "}.lst-kix_e8kaqrotva4-3>li:before{content:"\0025cf  "}ol.lst-kix_7pcs9kbg0qhi-1.start{counter-reset:lst-ctn-kix_7pcs9kbg0qhi-1 0}.lst-kix_6shy0i3drli2-2>li:before{content:"-  "}.lst-kix_mvnr2hoa94kd-8>li:before{content:"\0025a0  "}.lst-kix_6shy0i3drli2-8>li:before{content:"-  "}.lst-kix_6shy0i3drli2-0>li:before{content:"-  "}.lst-kix_38adif7m6rbx-2>li:before{content:"\0025a0  "}ol.lst-kix_8dw3ycrgt362-6.start{counter-reset:lst-ctn-kix_8dw3ycrgt362-6 0}.lst-kix_r60cdwx1dlic-7>li:before{content:"\0025cb  "}.lst-kix_owgllipbp8j5-2>li:before{content:"\0025a0  "}.lst-kix_5s83gilt2o7g-8>li:before{content:"\0025a0  "}ol.lst-kix_7pcs9kbg0qhi-0.start{counter-reset:lst-ctn-kix_7pcs9kbg0qhi-0 0}.lst-kix_owgllipbp8j5-5>li:before{content:"\0025a0  "}.lst-kix_owgllipbp8j5-8>li:before{content:"\0025a0  "}.lst-kix_5we8o0btcr67-4>li:before{content:"\0025cb  "}.lst-kix_hm0ybxxbxp2l-8>li:before{content:"\0025a0  "}.lst-kix_msukp0gxz1c7-8>li:before{content:"\0025a0  "}.lst-kix_g3mw20emt8ab-1>li:before{content:"\0025cb  "}.lst-kix_5we8o0btcr67-1>li:before{content:"\0025cb  "}.lst-kix_g3mw20emt8ab-4>li:before{content:"\0025cb  "}ul.lst-kix_9uzslqp6q29w-0{list-style-type:none}.lst-kix_hm0ybxxbxp2l-0>li:before{content:"\0025cf  "}ul.lst-kix_9uzslqp6q29w-1{list-style-type:none}.lst-kix_9uzslqp6q29w-1>li:before{content:"\0025cb  "}.lst-kix_mvnr2hoa94kd-3>li:before{content:"\0025cf  "}.lst-kix_mvnr2hoa94kd-0>li:before{content:"\0025cf  "}.lst-kix_hm0ybxxbxp2l-5>li:before{content:"\0025a0  "}.lst-kix_rop5sudr37z1-0>li:before{content:"\0025cf  "}ol.lst-kix_8dw3ycrgt362-1.start{counter-reset:lst-ctn-kix_8dw3ycrgt362-1 0}ul.lst-kix_e8kaqrotva4-7{list-style-type:none}ul.lst-kix_e8kaqrotva4-8{list-style-type:none}ul.lst-kix_e8kaqrotva4-5{list-style-type:none}ul.lst-kix_e8kaqrotva4-6{list-style-type:none}ul.lst-kix_e8kaqrotva4-3{list-style-type:none}ul.lst-kix_e8kaqrotva4-4{list-style-type:none}ul.lst-kix_e8kaqrotva4-1{list-style-type:none}ul.lst-kix_e8kaqrotva4-2{list-style-type:none}.lst-kix_p3wa2k83s8cn-1>li:before{content:"\0025cb  "}ul.lst-kix_e8kaqrotva4-0{list-style-type:none}.lst-kix_jbicnccaji3d-1>li:before{content:"\0025cb  "}.lst-kix_p3wa2k83s8cn-6>li:before{content:"\0025cf  "}.lst-kix_rsr7bmzen4a7-5>li:before{content:"\0025a0  "}.lst-kix_8dw3ycrgt362-7>li{counter-increment:lst-ctn-kix_8dw3ycrgt362-7}.lst-kix_rop5sudr37z1-3>li:before{content:"\0025cf  "}ul.lst-kix_9uzslqp6q29w-8{list-style-type:none}ol.lst-kix_8dw3ycrgt362-2.start{counter-reset:lst-ctn-kix_8dw3ycrgt362-2 0}ul.lst-kix_9uzslqp6q29w-6{list-style-type:none}ul.lst-kix_9uzslqp6q29w-7{list-style-type:none}ul.lst-kix_9uzslqp6q29w-4{list-style-type:none}ul.lst-kix_9uzslqp6q29w-5{list-style-type:none}ul.lst-kix_9uzslqp6q29w-2{list-style-type:none}.lst-kix_jbicnccaji3d-6>li:before{content:"\0025cf  "}ul.lst-kix_9uzslqp6q29w-3{list-style-type:none}.lst-kix_rop5sudr37z1-8>li:before{content:"\0025a0  "}ul.lst-kix_vd8i8whhh56x-7{list-style-type:none}ul.lst-kix_vd8i8whhh56x-6{list-style-type:none}.lst-kix_msukp0gxz1c7-0>li:before{content:"\0025cf  "}ul.lst-kix_vd8i8whhh56x-5{list-style-type:none}ul.lst-kix_vd8i8whhh56x-4{list-style-type:none}ul.lst-kix_vd8i8whhh56x-8{list-style-type:none}.lst-kix_3sh9r2c1w16g-5>li:before{content:"\0025a0  "}.lst-kix_8d6owvwxykff-2>li:before{content:"\0025a0  "}.lst-kix_rsr7bmzen4a7-2>li:before{content:"\0025a0  "}ul.lst-kix_2aliey961vrg-7{list-style-type:none}ul.lst-kix_2aliey961vrg-6{list-style-type:none}.lst-kix_3sh9r2c1w16g-0>li:before{content:"\0025cf  "}ul.lst-kix_2aliey961vrg-8{list-style-type:none}.lst-kix_msukp0gxz1c7-5>li:before{content:"\0025a0  "}ul.lst-kix_2aliey961vrg-3{list-style-type:none}ul.lst-kix_2aliey961vrg-2{list-style-type:none}ul.lst-kix_2aliey961vrg-5{list-style-type:none}ul.lst-kix_2aliey961vrg-4{list-style-type:none}ul.lst-kix_2aliey961vrg-1{list-style-type:none}ul.lst-kix_2aliey961vrg-0{list-style-type:none}.lst-kix_8d6owvwxykff-7>li:before{content:"\0025cb  "}ul.lst-kix_vd8i8whhh56x-3{list-style-type:none}ul.lst-kix_vd8i8whhh56x-2{list-style-type:none}ul.lst-kix_vd8i8whhh56x-1{list-style-type:none}ul.lst-kix_vd8i8whhh56x-0{list-style-type:none}.lst-kix_lqb82f5hzmh3-2>li:before{content:"\0025a0  "}.lst-kix_6wlb53t5sfma-1>li:before{content:"\0025cb  "}ul.lst-kix_mvnr2hoa94kd-8{list-style-type:none}.lst-kix_ao97xhpq4hr9-6>li:before{content:"\0025cf  "}.lst-kix_2aliey961vrg-4>li:before{content:"\0025cb  "}.lst-kix_9reixuath9e3-1>li:before{content:"\0025cb  "}.lst-kix_7n1btf6e2iyv-0>li:before{content:"\0025cf  "}ul.lst-kix_mvnr2hoa94kd-0{list-style-type:none}ul.lst-kix_mvnr2hoa94kd-1{list-style-type:none}ul.lst-kix_mvnr2hoa94kd-2{list-style-type:none}.lst-kix_7pcs9kbg0qhi-2>li{counter-increment:lst-ctn-kix_7pcs9kbg0qhi-2}ul.lst-kix_mvnr2hoa94kd-3{list-style-type:none}ul.lst-kix_mvnr2hoa94kd-4{list-style-type:none}ul.lst-kix_mvnr2hoa94kd-5{list-style-type:none}ul.lst-kix_mvnr2hoa94kd-6{list-style-type:none}ul.lst-kix_mvnr2hoa94kd-7{list-style-type:none}.lst-kix_38adif7m6rbx-7>li:before{content:"\0025cb  "}.lst-kix_3z0hr7pzpec4-8>li:before{content:"\0025a0  "}.lst-kix_7n1btf6e2iyv-8>li:before{content:"\0025a0  "}.lst-kix_mfwegjdddisb-4>li:before{content:"\0025cb  "}.lst-kix_3sh9r2c1w16g-8>li:before{content:"\0025a0  "}.lst-kix_3bekfbfd6o8j-0>li:before{content:"\0025cf  "}.lst-kix_e8kaqrotva4-8>li:before{content:"\0025a0  "}.lst-kix_47504ojh0ba1-4>li:before{content:"\0025cb  "}.lst-kix_s4rut6kfjze3-6>li:before{content:"\0025cf  "}.lst-kix_c4453ihcjob0-0>li:before{content:"\0025cf  "}ul.lst-kix_3bekfbfd6o8j-7{list-style-type:none}ul.lst-kix_3bekfbfd6o8j-8{list-style-type:none}ul.lst-kix_3bekfbfd6o8j-5{list-style-type:none}ul.lst-kix_3bekfbfd6o8j-6{list-style-type:none}ul.lst-kix_3bekfbfd6o8j-3{list-style-type:none}.lst-kix_dnm4ke3nhj1e-4>li:before{content:"\0025cb  "}ul.lst-kix_3bekfbfd6o8j-4{list-style-type:none}ul.lst-kix_3bekfbfd6o8j-1{list-style-type:none}ul.lst-kix_3bekfbfd6o8j-2{list-style-type:none}ul.lst-kix_ao97xhpq4hr9-0{list-style-type:none}.lst-kix_r60cdwx1dlic-4>li:before{content:"\0025cb  "}ul.lst-kix_3bekfbfd6o8j-0{list-style-type:none}.lst-kix_vd8i8whhh56x-5>li:before{content:"-  "}ul.lst-kix_ao97xhpq4hr9-2{list-style-type:none}ul.lst-kix_ao97xhpq4hr9-1{list-style-type:none}ul.lst-kix_ao97xhpq4hr9-4{list-style-type:none}.lst-kix_w93gux8gcekz-7>li:before{content:"-  "}ul.lst-kix_ao97xhpq4hr9-3{list-style-type:none}ul.lst-kix_ao97xhpq4hr9-6{list-style-type:none}ul.lst-kix_ao97xhpq4hr9-5{list-style-type:none}ul.lst-kix_ao97xhpq4hr9-8{list-style-type:none}ul.lst-kix_ao97xhpq4hr9-7{list-style-type:none}.lst-kix_e8kaqrotva4-0>li:before{content:"\0025cf  "}.lst-kix_5gii2tr4ae90-3>li:before{content:"\0025cf  "}.lst-kix_rj34zh1l62l0-4>li:before{content:"\0025cb  "}.lst-kix_9i19e8txouig-3>li:before{content:"\0025cf  "}.lst-kix_c4453ihcjob0-8>li:before{content:"\0025a0  "}.lst-kix_6shy0i3drli2-5>li:before{content:"-  "}.lst-kix_8dw3ycrgt362-2>li:before{content:"" counter(lst-ctn-kix_8dw3ycrgt362-2,lower-roman) ". "}.lst-kix_5iyzxwlmxp1f-1>li:before{content:"\0025cb  "}.lst-kix_5s83gilt2o7g-0>li:before{content:"\0025cf  "}.lst-kix_ne2kodfi1kix-4>li:before{content:"\0025cb  "}ol.lst-kix_8dw3ycrgt362-0.start{counter-reset:lst-ctn-kix_8dw3ycrgt362-0 0}.lst-kix_3z0hr7pzpec4-0>li:before{content:"\0025cf  "}ol{margin:0;padding:0}table td,table th{padding:0}.c93{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#cfe2f3;border-left-style:solid;border-bottom-width:1pt;width:161.2pt;border-top-color:#000000;border-bottom-style:solid}.c86{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#cfe2f3;border-left-style:solid;border-bottom-width:1pt;width:276pt;border-top-color:#000000;border-bottom-style:solid}.c97{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#cfe2f3;border-left-style:solid;border-bottom-width:1pt;width:128.2pt;border-top-color:#000000;border-bottom-style:solid}.c41{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#cfe2f3;border-left-style:solid;border-bottom-width:1pt;width:135pt;border-top-color:#000000;border-bottom-style:solid}.c104{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#cfe2f3;border-left-style:solid;border-bottom-width:1pt;width:213pt;border-top-color:#000000;border-bottom-style:solid}.c83{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#cfe2f3;border-left-style:solid;border-bottom-width:1pt;width:149.2pt;border-top-color:#000000;border-bottom-style:solid}.c85{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#cfe2f3;border-left-style:solid;border-bottom-width:1pt;width:105.8pt;border-top-color:#000000;border-bottom-style:solid}.c38{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:161.2pt;border-top-color:#000000;border-bottom-style:solid}.c59{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:135pt;border-top-color:#000000;border-bottom-style:solid}.c47{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:510.2pt;border-top-color:#000000;border-bottom-style:solid}.c120{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#ffffff;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:170.1pt;border-top-color:#000000;border-bottom-style:solid}.c79{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:170.1pt;border-top-color:#ffffff;border-bottom-style:solid}.c109{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#ffffff;vertical-align:bottom;border-right-color:#ffffff;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:105.8pt;border-top-color:#000000;border-bottom-style:solid}.c42{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:114pt;border-top-color:#000000;border-bottom-style:solid}.c13{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:98.2pt;border-top-color:#000000;border-bottom-style:solid}.c29{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:149.2pt;border-top-color:#000000;border-bottom-style:solid}.c63{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:510pt;border-top-color:#000000;border-bottom-style:solid}.c5{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:122.2pt;border-top-color:#000000;border-bottom-style:solid}.c0{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:105.8pt;border-top-color:#000000;border-bottom-style:solid}.c66{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:510.8pt;border-top-color:#000000;border-bottom-style:solid}.c117{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:105.8pt;border-top-color:#000000;border-bottom-style:solid}.c122{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:239.2pt;border-top-color:#000000;border-bottom-style:solid}.c98{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:276pt;border-top-color:#000000;border-bottom-style:solid}.c39{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:213pt;border-top-color:#000000;border-bottom-style:solid}.c111{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:510pt;border-top-color:#000000;border-bottom-style:solid}.c19{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:128.2pt;border-top-color:#000000;border-bottom-style:solid}.c112{border-right-style:solid;padding:8.5pt 8.5pt 8.5pt 8.5pt;border-bottom-color:#d9d9d9;border-top-width:1pt;border-right-width:1pt;border-left-color:#d9d9d9;vertical-align:top;border-right-color:#d9d9d9;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:330pt;border-top-color:#d9d9d9;border-bottom-style:solid}.c89{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#ffffff;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:276pt;border-top-color:#000000;border-bottom-style:solid}.c6{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:239.2pt;border-top-color:#000000;border-bottom-style:solid}.c121{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:122.2pt;border-top-color:#000000;border-bottom-style:solid}.c115{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#ffffff;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:510pt;border-top-color:#000000;border-bottom-style:solid}.c105{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:239.2pt;border-top-color:#000000;border-bottom-style:solid}.c116{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:510.8pt;border-top-color:#000000;border-bottom-style:solid}.c28{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:276pt;border-top-color:#000000;border-bottom-style:solid}.c27{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:170.1pt;border-top-color:#000000;border-bottom-style:solid}.c94{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:122.2pt;border-top-color:#000000;border-bottom-style:solid}.c114{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:239.2pt;border-top-color:#000000;border-bottom-style:solid}.c82{padding-top:6pt;border-top-width:1pt;border-bottom-color:#0b5394;padding-bottom:6pt;line-height:1.0;border-top-style:solid;background-color:#e7f3fd;text-indent:10.1pt;border-bottom-width:1pt;border-top-color:#0b5394;border-bottom-style:solid;orphans:2;widows:2;text-align:left}.c17{-webkit-text-decoration-skip:none;color:#1155cc;font-weight:400;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:10pt;font-family:"Arial";font-style:normal}.c34{-webkit-text-decoration-skip:none;color:#666666;font-weight:400;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:12pt;font-family:"Trebuchet MS";font-style:normal}.c35{padding-top:8pt;border-bottom-color:#3c78d8;border-bottom-width:1pt;padding-bottom:0pt;line-height:1.0;border-bottom-style:solid;orphans:2;widows:2;text-align:left}.c7{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c48{padding-top:6pt;padding-bottom:3pt;line-height:1.0;orphans:2;widows:2;text-align:left;height:14pt}.c14{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c64{margin-left:54pt;padding-top:3pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Inconsolata";font-style:normal}.c60{margin-left:36pt;padding-top:3pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c22{color:#24292e;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Inconsolata";font-style:normal}.c68{margin-left:18pt;padding-top:3pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c9{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c21{color:#45818e;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Trebuchet MS";font-style:normal}.c44{padding-top:0pt;padding-bottom:0pt;line-height:1.4285714285714286;orphans:2;widows:2;text-align:left}.c8{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c88{padding-top:4pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c57{color:#ff0000;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Georgia";font-style:italic}.c52{font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:normal}.c92{padding-top:10pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c51{padding-top:6pt;padding-bottom:3pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c125{margin-left:36pt;padding-top:3pt;padding-bottom:4pt;line-height:1.0;text-align:left}.c3{text-decoration-skip-ink:none;font-size:9pt;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c12{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left;height:11pt}.c54{color:#000000;text-decoration:none;vertical-align:baseline;font-size:8pt;font-style:normal}.c23{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:center;height:11pt}.c11{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c58{font-weight:400;vertical-align:baseline;font-family:"Arial";font-style:normal}.c55{color:#000000;text-decoration:none;vertical-align:baseline;font-style:normal}.c90{margin-left:-1.5pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c126{margin-left:auto;border-spacing:0;border-collapse:collapse;margin-right:auto}.c15{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c31{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c20{border-spacing:0;border-collapse:collapse;margin-right:auto}.c56{color:#0000ff;text-decoration:none;vertical-align:baseline;font-style:normal}.c84{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:center}.c46{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:center}.c102{background-color:#ecf0f3;font-style:italic;color:#222222}.c49{orphans:2;widows:2;height:11pt}.c101{color:#1155cc;font-size:18pt;font-family:"Trebuchet MS"}.c77{color:#3c78d8;font-size:16pt;font-family:"Trebuchet MS"}.c73{color:#1c4587;font-size:30pt;font-family:"Trebuchet MS"}.c72{color:#ff0000;text-decoration:none;font-size:11pt}.c16{font-size:10pt;font-family:"Inconsolata";font-weight:400}.c67{text-decoration:none;vertical-align:baseline;font-style:normal}.c26{font-weight:400;font-family:"Consolas"}.c40{font-weight:400;font-family:"Inconsolata"}.c25{font-size:9pt;font-weight:700}.c30{padding:0;margin:0}.c43{margin-left:36pt;padding-left:0pt}.c45{margin-left:108pt;padding-left:0pt}.c100{font-family:"Courier New";font-weight:400}.c123{font-weight:400;vertical-align:baseline}.c74{font-style:italic;color:#3e4349}.c76{margin-left:72pt;padding-left:0pt}.c78{max-width:510.2pt;padding:21.3pt 42.5pt 21.3pt 42.5pt}.c4{color:inherit;text-decoration:inherit}.c103{orphans:2;widows:2}.c75{height:19pt}.c108{height:26pt}.c107{height:22pt}.c61{background-color:#ffffff}.c10{height:0pt}.c65{color:#0000ff}.c36{font-weight:700}.c37{font-size:9pt}.c110{color:#d73a49}.c119{font-style:italic}.c80{font-family:"Arial"}.c124{font-size:12pt}.c96{height:21pt}.c24{height:24pt}.c69{height:12pt}.c62{color:#032f62}.c32{color:#24292e}.c95{height:44pt}.c99{height:16pt}.c70{height:33pt}.c50{height:11pt}.c81{font-size:11pt}.c91{color:#000000}.c113{text-decoration:none}.c118{color:#1155cc}.c33{page-break-after:avoid}.c71{height:54pt}.c106{background-color:#cfe2f3}.c87{background-color:#d9d9d9}.c53{font-size:10pt}.c18{height:15pt}.title{padding-top:0pt;color:#1c4587;font-weight:700;font-size:30pt;padding-bottom:0pt;font-family:"Trebuchet MS";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:11pt;padding-bottom:0pt;font-family:"Georgia";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:6pt;color:#1155cc;border-top-width:1pt;border-bottom-color:#0b5394;font-weight:700;font-size:18pt;padding-bottom:6pt;line-height:1.0;page-break-after:avoid;border-top-style:solid;background-color:#e7f3fd;border-bottom-width:1pt;border-top-color:#0b5394;font-family:"Trebuchet MS";border-bottom-style:solid;orphans:2;widows:2;text-align:left}h2{padding-top:8pt;color:#3c78d8;border-bottom-color:#3c78d8;font-weight:700;font-size:16pt;padding-bottom:0pt;line-height:1.0;page-break-after:avoid;border-bottom-width:1pt;font-family:"Trebuchet MS";border-bottom-style:solid;orphans:2;widows:2;text-align:left}h3{padding-top:6pt;color:#45818e;font-weight:700;font-size:14pt;padding-bottom:3pt;font-family:"Trebuchet MS";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:6pt;-webkit-text-decoration-skip:none;color:#666666;text-decoration:underline;font-size:12pt;padding-bottom:3pt;line-height:1.0;page-break-after:avoid;text-decoration-skip-ink:none;font-family:"Trebuchet MS";orphans:2;widows:2;text-align:left}h5{padding-top:6pt;color:#777777;font-weight:700;font-size:11pt;padding-bottom:3pt;font-family:"Trebuchet MS";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:6pt;color:#666666;font-size:11pt;padding-bottom:3pt;font-family:"Trebuchet MS";line-height:1.0;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c61 c78"><p class="c8 c33 title" id="h.tc504ybtnf8q"><span class="c67 c36 c73">Framework Migration Guide</span></p><p class="c8 c33 subtitle" id="h.4pdauswx7nci"><span>Authors: Chainer Team</span></p><p class="c7"><span class="c9"></span></p><a id="t.88a16daa6e82c66329d7f6be06ced4fcbae269e2"></a><a id="t.0"></a><table class="c20"><tbody><tr class="c10"><td class="c112" colspan="1" rowspan="1"><p class="c11 c50"><span class="c52 c91"></span></p><p class="c88"><span class="c17"><a class="c4" href="#h.6qt1ntczqwrx">General Information</a></span></p><p class="c68"><span class="c17"><a class="c4" href="#h.r2o0yn30s8tq">Concepts and components in both frameworks</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.ms7vvkoz6vru">Array Library</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.8z53kzu8pby0">Core Framework and Training Loop</a></span></p><p class="c68"><span class="c17"><a class="c4" href="#h.y7ovx8en8cp7">Migration scenarios</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.e88d7eicrcd0">I want to port my Chainer script to PyTorch, step by step</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.8w1snpmhh4kj">I want to let my Chainer code train a PyTorch model</a></span></p><p class="c68"><span class="c17"><a class="c4" href="#h.9wc1iaeyqb2c">Migration tools (cpm)</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.im0z6zf5ujzw">cpm.TorchModule</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.pflkcrjo8y89">cpm.ChainerParameter</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.46et3pwf65s">cpm.LinkAsTorchModel</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.49ptm66ugzcy">cpm.ignite.add_trainer_extension</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.207juqqyebo8">cpm.use_torch_in_cupy_malloc</a></span></p><p class="c92"><span class="c17"><a class="c4" href="#h.9eib52bt6ke5">Porting Guides</a></span></p><p class="c68"><span class="c17"><a class="c4" href="#h.7u4t6laltff5">Dataset and data pre/post-processing</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.tw9winyigiz6">Negative strides</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.51r33byocuk1">NumPy bridge</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.84jg73vglm0b">CuPy bridge</a></span></p><p class="c68"><span class="c17"><a class="c4" href="#h.h1ei3avajrbn">Training loop</a></span></p><p class="c68"><span class="c17"><a class="c4" href="#h.3b2g5rapv9ec">Evaluation loop</a></span></p><p class="c68"><span class="c17"><a class="c4" href="#h.wanb8rb4d6lo">Training and evaluation using Ignite</a></span></p><p class="c68"><span class="c17"><a class="c4" href="#h.m8sz4mg7ioxl">Using Chainer extensions with Ignite</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.ojt9418jpkms">Snapshots</a></span></p><p class="c68"><span class="c17"><a class="c4" href="#h.s8lyt5panb7">Porting custom updater using Ignite</a></span></p><p class="c68"><span class="c17"><a class="c4" href="#h.xmsyb5asd2c9">Rewriting existing Chainer model</a></span></p><p class="c68"><span class="c31 c53"><a class="c4" href="#h.mkuuagm60br0">Functions and Links</a></span></p><p class="c60"><span class="c31 c53"><a class="c4" href="#h.e17stx2v9ds3">Functions</a></span></p><p class="c60"><span class="c31 c53"><a class="c4" href="#h.ryz2089jygqa">Links</a></span></p><p class="c68"><span class="c17"><a class="c4" href="#h.hb9kqa7i3enr">Configuration</a></span></p><p class="c68"><span class="c17"><a class="c4" href="#h.rxt9pteccajv">Hooks</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.gsgtoxixjcm4">Function Hooks</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.rvlhszhkp1bw">Link Hooks</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.5a204an0cllk">Optimizer Hooks</a></span></p><p class="c68"><span class="c17"><a class="c4" href="#h.79n4spowwnun">Training PyTorch model using Chainer</a></span></p><p class="c68"><span class="c17"><a class="c4" href="#h.33jrfcvcf9zh">Distributed training</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.iyhfmfndl13j">Pytorch model using torch.distributed</a></span></p><p class="c64"><span class="c17"><a class="c4" href="#h.moliknyk6ru3">Invocation</a></span></p><p class="c64"><span class="c17"><a class="c4" href="#h.7r5y5xoqrywb">Initialization</a></span></p><p class="c64"><span class="c17"><a class="c4" href="#h.nzh1eoy3bny9">Dataset scattering</a></span></p><p class="c64"><span class="c17"><a class="c4" href="#h.kyzvorr2x2ij">Data transfer to devices</a></span></p><p class="c64"><span class="c17"><a class="c4" href="#h.s0hd5ycxwpdh">Optimizer wrapping</a></span></p><p class="c64"><span class="c17"><a class="c4" href="#h.d1nulkakooh">Initial values broadcast</a></span></p><p class="c64"><span class="c17"><a class="c4" href="#h.x5dny5mqq9px">Metrics average and reductions</a></span></p><p class="c64"><span class="c17"><a class="c4" href="#h.5t9pfndndqnr">https://pytorch.org/docs/stable/distributed.html#multi-gpu-collective-functions</a></span></p><p class="c64"><span class="c17"><a class="c4" href="#h.3lb7ncfjheoo">Synchronization</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.dis62849w9cz">Pytorch model using Horovod</a></span></p><p class="c64"><span class="c17"><a class="c4" href="#h.tje6mmfdx3pf">Horovod initialization</a></span></p><p class="c64"><span class="c17"><a class="c4" href="#h.37g288q2db5i">Dataset scattering</a></span></p><p class="c64"><span class="c17"><a class="c4" href="#h.z7g1nmbbb3uh">Optimizer wrapping</a></span></p><p class="c64"><span class="c17"><a class="c4" href="#h.gq621f9b16zf">Initial values broadcast</a></span></p><p class="c64"><span class="c17"><a class="c4" href="#h.9t9k4lfat6t2">Metrics average and reductions</a></span></p><p class="c64"><span class="c17"><a class="c4" href="#h.bfpbumwh7xzs">Horovod code structure</a></span></p><p class="c64"><span class="c17"><a class="c4" href="#h.apxtaciyccdc">Obtaining Horovod traces to measure performance</a></span></p><p class="c64"><span class="c17"><a class="c4" href="#h.9jn0jqinrgx3">Tuning Horovod performance</a></span></p><p class="c64"><span class="c17"><a class="c4" href="#h.wuax6jpon8sy">Using Horovod with apex</a></span></p><p class="c64"><span class="c17"><a class="c4" href="#h.y8eom3uzrv56">Alternatives to Horovod</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.qfxp9de828j4">Chainer model using Horovod</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.vlwpxcx5nw9c">Torch model using ChainerMN</a></span></p><p class="c68"><span class="c17"><a class="c4" href="#h.2jl4lfh90jqb">Porting code that edits the computational graph</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.gbqjtjbzzzno">Unchaining nodes</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.mc69ie7hbl6j">Backprop modes</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.bka3yqtw2rpy">Train/Test modes</a></span></p><p class="c92"><span class="c17"><a class="c4" href="#h.r8th8e47f02c">Ecosystem</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.d863gr6235hf">PyTorch</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.w69092dw2rtl">Ignite</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.b2r58wgcvv09">torchvision</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.ctcyjos25n6z">torchtext</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.l9nxjlcurusl">torchaudio</a></span></p><p class="c60"><span class="c17"><a class="c4" href="#h.p90hj6w1ucn0">Fairseq</a></span></p><p class="c103 c125"><span class="c17"><a class="c4" href="#h.eaofa6s7sf0k">Other</a></span></p><p class="c11 c50"><span class="c52 c91"></span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><p class="c7"><span class="c9"></span></p><p class="c8"><span class="c9">This document provides technical information for migration from Chainer to PyTorch.</span></p><p class="c7"><span class="c9"></span></p><h1 class="c33 c82" id="h.6qt1ntczqwrx"><span class="c67 c36 c101">General Information</span></h1><h2 class="c35 c33" id="h.r2o0yn30s8tq"><span class="c77 c67 c36">Concepts and components in both frameworks</span></h2><h3 class="c51 c33" id="h.ms7vvkoz6vru"><span class="c21">Array Library</span></h3><p class="c8"><span>Chainer uses NumPy/CuPy (</span><span class="c26">xp.ndarray</span><span>) as an array library, and wraps them as </span><span class="c26">chainer.Variable</span><span>&nbsp;to support autograd. Similarly, PyTorch uses </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/cppdocs/%23aten&amp;sa=D&amp;ust=1575460959627000">ATen</a></span><span>&nbsp;(</span><span class="c26">at::Tensor</span><span>&nbsp;(C++)) as an array library (&quot;tensor library&quot; in PyTorch terms), and wraps it as </span><span class="c26">torch::Tensor</span><span>&nbsp;(C++ API) / </span><span class="c26">torch.Tensor</span><span>&nbsp;(Python API) to support autograd. </span><span class="c26">torch.*</span><span>&nbsp;provides API similar to (but not compatible with) NumPy, e.g. </span><span class="c26">torch.dot, torch.float32</span><span class="c9">, etc.</span></p><h3 class="c51 c33" id="h.8z53kzu8pby0"><span class="c21">Core Framework and Training Loop</span></h3><p class="c8"><span class="c9">As both frameworks share the same concept, define-by-run, the look-and-feel of code written in PyTorch is pretty similar to Chainer. Here is the high-level mapping of features:</span></p><p class="c7"><span class="c9"></span></p><a id="t.e6a46275bcd72c5ee54dae665a0d891476f5e165"></a><a id="t.1"></a><table class="c20"><tbody><tr class="c10"><td class="c27 c106" colspan="1" rowspan="1"><p class="c46"><span class="c14">Chainer</span></p></td><td class="c27 c106" colspan="1" rowspan="1"><p class="c46"><span class="c14">PyTorch</span></p></td><td class="c27 c106" colspan="1" rowspan="1"><p class="c46"><span class="c14">Notes</span></p></td></tr><tr class="c10"><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c14">Variable</span></p><p class="c11"><span class="c9">chainer.Variable</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c14">Tensor</span></p><p class="c11"><span class="c9">torch.Tensor</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c11 c50"><span class="c9"></span></p></td></tr><tr class="c10"><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c14">Function</span></p><p class="c11"><span class="c9">chainer.FunctionNode</span></p><p class="c11"><span class="c9">(chainer.functions.*)</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c14">Function</span></p><p class="c11"><span class="c9">torch.autograd.Function</span></p><p class="c11"><span class="c9">(torch.nn.functional.*)</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c9">`torch.*` also provides NumPy-like (but not compatible) operations.</span></p></td></tr><tr class="c10"><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c14">Link / Chain</span></p><p class="c11"><span class="c9">chainer.{Link, Chain}</span></p><p class="c11"><span class="c9">(chainer.links.*)</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c14">Module</span></p><p class="c11"><span class="c9">torch.nn.Module</span></p><p class="c11"><span class="c9">(torch.nn.*)</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c11 c50"><span class="c9"></span></p></td></tr><tr class="c10"><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c14">Sequential</span></p><p class="c11"><span class="c9">chainer.Sequential</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c14">Sequential</span></p><p class="c11"><span class="c9">torch.nn.Sequential</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c9">You can use function modules as member (e.g., torch.nn.ReLU instead of torch.nn.functional.relu).</span></p></td></tr><tr class="c10"><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c14">Dataset</span></p><p class="c11"><span class="c9">chainer.dataset.DatasetMixin</span></p><p class="c11"><span class="c9">(chainer.datasets.*)</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c14">Dataset</span></p><p class="c11"><span class="c9">torch.utils.data.Dataset</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c11"><span>There are no TransformDataset in PyTorch (there is one in CPM as cpm.TransformDataset); </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torchvision/datasets.html&amp;sa=D&amp;ust=1575460959641000">datasets conventionally accepts</a></span><span class="c9">&nbsp;`transforms` argument that perform per-example preprocessing.</span></p></td></tr><tr class="c10"><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c14">Iterator</span></p><p class="c11"><span class="c9">chainer.iterators.*</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c36">DataLoader</span></p><p class="c11"><span class="c9">torch.utils.data.DataLoader</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c11"><span>Unlike Chainer&#39;s Iterator, DataLoader automatically collates all samples into one Tensor by default; use </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/data.html%23working-with-collate-fn&amp;sa=D&amp;ust=1575460959644000">collate_fn</a></span><span class="c9">&nbsp;to customize this behavior.</span></p><p class="c11"><span class="c9">DataLoader itself supports multi-process iteration (using num_workers option).</span></p></td></tr><tr class="c10"><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c14">Optimizer</span></p><p class="c11"><span class="c9">chainer.Optimizer</span></p><p class="c11"><span>(</span><span class="c9">chainer.optimizers.*)</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c14">Optimizer</span></p><p class="c11"><span class="c9">torch.optim.Optimizer</span></p><p class="c11"><span>(</span><span class="c9">torch.optim.*)</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c11 c50"><span class="c9"></span></p></td></tr><tr class="c96"><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c14">Trainer</span></p><p class="c11"><span class="c9">chainer.training.Trainer</span></p></td><td class="c120" colspan="1" rowspan="3"><p class="c11"><span class="c14">Engine</span></p><p class="c11"><span class="c9">ignite.Engine</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c9">ignite.engine.create_supervised_trainer()</span></p></td></tr><tr class="c96"><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c36">Updater</span><span class="c9">&nbsp;(with converter)</span></p><p class="c11"><span class="c9">chainer.training.Updater</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c9">As noted above, Iterator concatenates examples by default. Transfer to device is handled by Engine (or custom loop code if you don&#39;t use Ignite)</span></p></td></tr><tr class="c96"><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c14">Evaluator</span></p><p class="c11"><span class="c9">chainer.training.extensions.Evaluator</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c9">ignite.engine.create_supervised_evaluator()</span></p></td></tr><tr class="c10"><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c14">Extension</span></p><p class="c11"><span class="c9">chainer.training.Extension</span></p><p class="c11"><span class="c9">(chainer.training.extensions.*)</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c11"><span class="c14">Handler</span></p><p class="c11"><span class="c9">(ignite.handlers.*, ignite.contrib.handlers.*)</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c11 c50"><span class="c9"></span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><p class="c8"><span>Refer to the </span><span class="c31"><a class="c4" href="#h.9eib52bt6ke5">Porting Guide</a></span><span class="c9">&nbsp;section for the details of the difference of each component.</span></p><h2 class="c35 c33" id="h.y7ovx8en8cp7"><span class="c77 c67 c36">Migration scenarios</span></h2><h3 class="c33 c51" id="h.e88d7eicrcd0"><span class="c21">I want to port my Chainer script to PyTorch, step by step</span></h3><p class="c8"><span class="c9">Arguably the model is the hardest part to port without affecting the outcome of the training.</span></p><p class="c8"><span class="c9">It might be easier to port in this order:</span></p><ol class="c30 lst-kix_7pcs9kbg0qhi-0 start" start="1"><li class="c8 c43"><span class="c9">Training script (optimizer / updater / evaluator / ...)</span></li></ol><ul class="c30 lst-kix_3bekfbfd6o8j-0 start"><li class="c8 c76"><span>In order to use PyTorch optimizer to train a Chainer model, you will need </span><span class="c31 c40"><a class="c4" href="#h.46et3pwf65s">cpm.LinkAsTorchModel</a></span><span class="c9">.</span></li></ul><ol class="c30 lst-kix_7pcs9kbg0qhi-0" start="2"><li class="c8 c43"><span class="c9">Dataset / preprocessing</span></li></ol><ul class="c30 lst-kix_rj34zh1l62l0-0 start"><li class="c8 c76"><span class="c9">Dataset is in general compatible between Chainer and PyTorch. This part can be delayed but also should be easy to do.</span></li></ul><ol class="c30 lst-kix_7pcs9kbg0qhi-0" start="3"><li class="c8 c43"><span class="c9">Model</span></li></ol><ul class="c30 lst-kix_e8kaqrotva4-0 start"><li class="c8 c76"><span class="c9">See the mapping of functions/modules below in this document.</span></li></ul><h3 class="c51 c33" id="h.8w1snpmhh4kj"><span class="c21">I want to let my Chainer code train a PyTorch model</span></h3><p class="c8"><span>You can use </span><span class="c31 c40"><a class="c4" href="#h.im0z6zf5ujzw">cpm.TorchModule</a></span><span class="c9">&nbsp;to wrap a PyTorch module as a Chainer model.</span></p><h2 class="c33 c35" id="h.9wc1iaeyqb2c"><span class="c77 c67 c36">Migration tools (cpm)</span></h2><p class="c8"><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://github.com/chainer/chainer-pytorch-migration&amp;sa=D&amp;ust=1575460959661000">chainer-pytorch-migration</a></span><span class="c9">&nbsp;Python module (called &quot;cpm&quot; in this document) provides various utilities to help migration from Chainer to PyTorch.</span></p><p class="c7"><span class="c9"></span></p><p class="c8"><span class="c9">Example code assumes that cpm is imported as follows:</span></p><a id="t.b6d4e8a49de865470ffee8db15d9b8ba2e23ba94"></a><a id="t.2"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c11"><span class="c55 c16">import chainer_pytorch_migration as cpm</span></p><p class="c11"><span class="c16">import chainer_pytorch_migration.ignite</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><h3 class="c51 c33" id="h.im0z6zf5ujzw"><span class="c21">cpm.TorchModule</span></h3><p class="c8"><span class="c9">This class wraps a PyTorch module as a Chainer link. It allows training PyTorch models in Chainer training scripts. The graph (forward/backward) must be constructed and traversed in PyTorch.</span></p><a id="t.a38bfd190b7eeeae684f9cee2c1f0d3585c106d8"></a><a id="t.3"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c11"><span class="c55 c16">model = torchvision.models.resnet50()</span></p><p class="c11"><span class="c55 c16">model.cuda()</span></p><p class="c11"><span class="c55 c16">w_model = cpm.TorchModule(model)</span></p><p class="c11"><span class="c16">w_model.to_gpu(device) </span><span class="c56 c16"># Just synchronizes the metadata, does not transfer data</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><h3 class="c51 c33" id="h.pflkcrjo8y89"><span class="c21">cpm.ChainerParameter</span></h3><p class="c8"><span>This class wraps a Chainer parameter as a PyTorch parameter. It allows training of Chainer models (</span><span class="c40">chainer.Link</span><span>) in PyTorch training scripts (with </span><span class="c40">torch.optim.Optimizer</span><span>). The graph (forward/backward) must be constructed and traversed in Chainer. </span><span class="c26">cpm.LinkAsTorchModel</span><span class="c9">&nbsp;internally uses it.</span></p><p class="c7"><span class="c9"></span></p><a id="t.629215085eff3b976e0bfd5a36f2220c2566c72f"></a><a id="t.4"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c11"><span class="c56 c16"># initialized parameter</span></p><p class="c11"><span class="c55 c16">arr = numpy.full(shape, 17, &#39;float32&#39;)</span></p><p class="c11"><span class="c55 c16">chainer_param = chainer.Parameter(arr)</span></p><p class="c11"><span class="c16">torch_param = cpm.ChainerParameter(chainer_param)</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><h3 class="c51 c33" id="h.46et3pwf65s"><span class="c21">cpm.LinkAsTorchModel</span></h3><p class="c8"><span>This class automatically creates all the </span><span class="c40">cpm.ChainerParameter</span><span>&nbsp;objects for a given chainer link and provides methods such as </span><span class="c40">parameters()</span><span>, </span><span class="c40">named_parameters()</span><span>&nbsp;or </span><span class="c40">state_dict() </span><span class="c9">required by pytorch optimizers or tools such as horovod.</span></p><p class="c7"><span class="c9"></span></p><a id="t.03722b3a1101d0cb8921f9a97706853df2b7559f"></a><a id="t.5"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c11"><span class="c2">model = ChainerModel()</span></p><p class="c11"><span class="c2">model.to_device(ch_device)</span></p><p class="c11"><span class="c56 c40 c81"># Initialize parameters before converting to `ChainerParameter`s.</span></p><p class="c11"><span class="c2">model(ch_device.xp.zeros((1, 784)).astype(&#39;f&#39;))</span></p><p class="c11"><span class="c56 c40 c81"># Convert parameters to `ChainerParameter`s to share memory with PyTorch.</span></p><p class="c11"><span class="c2">torched_model = cip.LinkAsTorchModel(model)</span></p><p class="c11"><span class="c40">optimizer = optim.SGD(torched_model.parameters(), lr=args.lr)</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><h3 class="c51 c33" id="h.49ptm66ugzcy"><span class="c21">cpm.ignite.add_trainer_extension</span></h3><p class="c8"><span class="c9">This function registers a chainer trainer extension to be used with ignite.</span></p><p class="c8"><span class="c9">Function call requires the ignite trainer, torch optimizer and the chainer extension as the parameters</span></p><a id="t.03de8277e29c4d3c8e35d4343afc863ae26c47ed"></a><a id="t.6"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c8"><span class="c55 c16">optimizer.target = model</span></p><p class="c8"><span class="c55 c16">trainer.out = &#39;path to store extension results&#39;</span></p><p class="c8"><span class="c16">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.ExponentialShift(&#39;lr&#39;, 0.9, 1.0, 0.1))</span></p></td></tr></tbody></table><p class="c7"><span class="c55 c16"></span></p><h3 class="c51 c33" id="h.207juqqyebo8"><span class="c21">cpm.use_torch_in_cupy_malloc</span></h3><p class="c8"><span class="c9">This function makes CuPy use memory pool from PyTorch. You need to call it before any operations using CuPy.</span></p><a id="t.2dc2957b7d65ee7765c6eeb00ea74d0c30669a6e"></a><a id="t.7"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c11"><span class="c55 c16">cpm.use_mempool_in_cupy_malloc()</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><h1 class="c82 c33" id="h.9eib52bt6ke5"><span class="c101 c67 c36">Porting Guides</span></h1><h2 class="c35 c33" id="h.7u4t6laltff5"><span class="c77 c67 c36">Dataset and data pre/post-processing</span></h2><p class="c8"><span>PyTorch datasets (</span><span class="c40">pytorch.utils.data.Dataset</span><span class="c9">) are basically compatible with Chainer&rsquo;s. In most cases they are interchangeable in both directions.</span></p><h3 class="c51 c33" id="h.tw9winyigiz6"><span class="c21">Negative strides</span></h3><p class="c8"><span>As of PyTorch 1.2.0, PyTorch cannot handle data arrays with negative strides (can result from </span><span class="c40">numpy.flip</span><span>&nbsp;or </span><span class="c40">chainercv.transforms.flip</span><span class="c9">, for example).</span></p><p class="c7"><span class="c9"></span></p><p class="c8"><span>Perhaps the easiest way to circumvent this problem is to wrap the dataset with </span><span class="c40">numpy.ascontiguousarray</span><span class="c9">.</span></p><p class="c7"><span class="c9"></span></p><a id="t.941bd69b434ad04726fb40c437dd8753bdd82a23"></a><a id="t.8"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c8"><span class="c2">def avoid_negative_strides(in_data):</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; data, label = in_data</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; data = numpy.ascontiguousarray(data)</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; return data, label</span></p><p class="c7"><span class="c2"></span></p><p class="c8"><span class="c2">dataset = cpm.TransformDataset(dataset, avoid_negative_strides)</span></p><p class="c8"><span class="c40">data_loader = torch.utils.data.DataLoader(dataset, ...)</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><p class="c8"><span>Another way is to customize the collation function with </span><span class="c40">collate_fn</span><span>&nbsp;argument in </span><span class="c40">torch.utils.data.DataLoader</span><span class="c9">.</span></p><p class="c7"><span class="c9"></span></p><a id="t.a749c5add683a394ba81c8606178ef82a83ebc58"></a><a id="t.9"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c8"><span class="c2">def collate(batch):</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; data = numpy.stack([d for d, l in batch])</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; label = numpy.stack([l for d, l in batch])</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; data_tensor = torch.from_numpy(data)</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; label_tensor = torch.from_numpy(label)</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; return data_tensor, label_tensor</span></p><p class="c7"><span class="c2"></span></p><p class="c8"><span class="c40">data_loader = torch.utils.data.DataLoader(dataset, ..., collate_fn=collate)</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><h3 class="c51 c33" id="h.51r33byocuk1"><span class="c21">NumPy bridge</span></h3><p class="c8"><span class="c40">torch.DataLoader</span><span>&nbsp;automatically converts NumPy arrays to PyTorch tensors, but if you want to do that manually, refer to </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/tutorials/beginner/former_torchies/tensor_tutorial.html%23numpy-bridge&amp;sa=D&amp;ust=1575460959687000">NumPy Bridge</a></span><span>.</span></p><h3 class="c51 c33" id="h.84jg73vglm0b"><span class="c21">CuPy bridge</span></h3><p class="c8"><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://docs-cupy.chainer.org/en/stable/reference/interoperability.html%23dlpack&amp;sa=D&amp;ust=1575460959688000">DLPack</a></span><span>&nbsp;can be used to bridge between CuPy and </span><span class="c40">torch.Tensor</span><span>. Note that DLPack does not handle ownership, so you have to make sure the original buffer (the original </span><span class="c26">cupy.ndarray</span><span>&nbsp;object or dltensor capsule object returned by </span><span class="c26">toDlpack()</span><span class="c9">) survives while the converted tensor/array is in use.</span></p><p class="c7"><span class="c9"></span></p><p class="c8"><span>To fully convert CuPy/PyTorch including shared ownership, use </span><span class="c40">cpm.asarray</span><span>&nbsp;and </span><span class="c40">cpm.astensor</span><span class="c9">.</span></p><p class="c7"><span class="c9"></span></p><p class="c8"><span>It is also recommended to call </span><span class="c31"><a class="c4" href="#h.207juqqyebo8">cpm.use_torch_in_cupy_malloc</a></span><span class="c9">&nbsp;before using CuPy to let it share the allocator with PyTorch.</span></p><p class="c7"><span class="c9"></span></p><p class="c8"><span>Note: As of PyTorch 1.3.0, </span><span class="c40">__cuda_array_interface__</span><span>&nbsp;is broken (</span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/pull/24947&amp;sa=D&amp;ust=1575460959691000">pytorch/pytorch/#24947</a></span><span>). After fixing this issue, you will be able to convert between them just using </span><span class="c40">cupy.asarray</span><span>&nbsp;and </span><span class="c40">torch.as_tensor</span><span class="c9">&nbsp;instead of cpm counterparts.</span></p><p class="c7"><span class="c9"></span></p><h2 class="c35 c33" id="h.h1ei3avajrbn"><span class="c77 c67 c36">Training loop</span></h2><p class="c8"><span>This is an example code of training loop. Note </span><span class="c40">model.train()</span><span class="c9">.</span></p><p class="c7"><span class="c9"></span></p><p class="c7"><span class="c9"></span></p><a id="t.df4d8e7b83e3847f40cedf4a49147baac0a37f94"></a><a id="t.10"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c8"><span class="c2">device = torch.device(&#39;cuda:0&#39;)</span></p><p class="c8"><span class="c2">for i_epoch in range(args.epoch):</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; train_loss = 0</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; train_correct = 0</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; model.train()</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; for x, t in data_loader:</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; x = x.to(device)</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; t = t.to(device).long()</span></p><p class="c7"><span class="c2"></span></p><p class="c8"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; optimizer.zero_grad()</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; y = model(x)</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; loss = F.nll_loss(y, t)</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; loss.backward()</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; optimizer.step()</span></p><p class="c7"><span class="c2"></span></p><p class="c8"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; train_loss += loss.sum().item()</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; _, pred = torch.max(y, 1)</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; train_correct += (pred == t).sum().item()</span></p><p class="c7"><span class="c2"></span></p><p class="c8"><span class="c2">&nbsp; &nbsp; train_loss /= len(data_loader.dataset)</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; train_accuracy = train_correct / len(data_loader.dataset)</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; print(&#39;Train average loss: {:.03f}&#39;.format(train_loss))</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; print(&#39;Train accuracy : {:.03f} %&#39;.format(train_accuracy * 100))</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><h2 class="c35 c33" id="h.3b2g5rapv9ec"><span class="c77 c67 c36">Evaluation loop</span></h2><p class="c8"><span>This is an example code of evaluation loop. Note </span><span class="c40">model.eval() </span><span>and </span><span class="c40">with torch.no_grad()</span><span>.</span></p><p class="c7"><span class="c9"></span></p><a id="t.11fc8eb3ce1b6cb26c10953d413254d7b7fbaa04"></a><a id="t.11"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c8"><span class="c2">device = torch.device(&#39;cuda:0&#39;)</span></p><p class="c8"><span class="c2">total_loss = 0</span></p><p class="c8"><span class="c2">total_correct = 0</span></p><p class="c8"><span class="c2">model.eval()</span></p><p class="c8"><span class="c2">with torch.no_grad():</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; for x, t in data_loader:</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; x = x.to(device)</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; t = t.to(device).long()</span></p><p class="c7"><span class="c2"></span></p><p class="c8"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; y = model(x)</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; total_loss += F.nll_loss(y, t, reduction=&#39;sum&#39;).item()</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; _, pred = torch.max(y, 1)</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; total_correct += (pred == t).sum().item()</span></p><p class="c7"><span class="c2"></span></p><p class="c8"><span class="c2">average_loss = total_loss / len(loader.dataset)</span></p><p class="c8"><span class="c2">accuracy = total_correct / len(loader.dataset)</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><h2 class="c35 c33" id="h.wanb8rb4d6lo"><span class="c77 c67 c36">Training and evaluation using Ignite</span></h2><p class="c8"><span>Ignite is something corresponding to </span><span class="c40">chainer.training.Trainer</span><span class="c9">&nbsp;in Chainer.</span></p><p class="c8"><span>This Chainer code:</span></p><p class="c7"><span class="c2"></span></p><p class="c7"><span class="c2"></span></p><p class="c7"><span class="c9"></span></p><a id="t.06fe944358155c5c1c1720ada7a200c56fa902b2"></a><a id="t.12"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c8"><span class="c2">updater = chainer.training.StandardUpdater(</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; train_iter,</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; optimizer,</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; device=device)</span></p><p class="c8"><span class="c2">trainer = chainer.training.Trainer(updater, (100, &lsquo;epoch&rsquo;))</span></p><p class="c8"><span class="c2">trainer.extend(</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; extensions.Evaluator(</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; val_iter,</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; model,</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; device=device),</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; trigger=(1, &lsquo;epoch&rsquo;))</span></p><p class="c8"><span class="c2">trainer.run()</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><p class="c8"><span>can be written in PyTorch using Ignite:</span></p><p class="c7"><span class="c9"></span></p><a id="t.26f609c9f19badd14a1ca750000df5cbc6d342ee"></a><a id="t.13"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c8"><span class="c2">trainer = ignite.engine.create_supervised_trainer(</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; model,</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; optimizer,</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; F.nll_loss,</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; device=device)</span></p><p class="c8"><span class="c2">evaluator = ignite.engine.create_supervised_evaluator(</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; model,</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; metrics={</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &#39;accuracy&#39;: ignite.metrics.Accuracy(),</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &#39;loss&#39;: ignite.metrics.Loss(F.nll_loss),</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; },</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; device=device)</span></p><p class="c7"><span class="c2"></span></p><p class="c8"><span class="c2">@trainer.on(ignite.engine.Events.EPOCH_COMPLETED)</span></p><p class="c8"><span class="c2">def validation(engine):</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; evaluator.run(val_loader)</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; average_accuracy = evaluator.state.metrics[&lsquo;accuracy&rsquo;]</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; average_loss = evaluator.state.metrics[&lsquo;loss&rsquo;]</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; print(average_accuracy, average_loss)</span></p><p class="c7"><span class="c2"></span></p><p class="c8"><span class="c2">trainer.run(train_loader, max_epochs=100)</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><p class="c8"><span>For a list of supported metrics, see </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/ignite/metrics.html&amp;sa=D&amp;ust=1575460959724000">https://pytorch.org/ignite/metrics.html</a></span><span class="c9">.</span></p><h2 class="c35 c33" id="h.m8sz4mg7ioxl"><span class="c77 c67 c36">Using Chainer extensions with Ignite</span></h2><p class="c8"><span>Using </span><span class="c31"><a class="c4" href="#h.49ptm66ugzcy">cpm.ignite.add_trainer_extension</a></span><span class="c9">&nbsp;it is possible to register a chainer extension to be called within the ignite training loop.</span></p><p class="c8"><span class="c9">A list of the supported extensions follows:</span></p><p class="c7"><span class="c9"></span></p><a id="t.d4eff46624142b2b1a44288ca2ae5657d3d651eb"></a><a id="t.14"></a><table class="c90"><tbody><tr class="c10"><td class="c42 c87" colspan="1" rowspan="1"><p class="c46"><span class="c52 c91">Works</span></p></td><td class="c13 c87" colspan="1" rowspan="1"><p class="c46"><span class="c52 c91">Doesn&rsquo;t work</span></p></td></tr><tr class="c10"><td class="c42" colspan="1" rowspan="1"><p class="c46"><span class="c54 c40">ExponentialShift</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c46"><span class="c54 c40">DumpGraph</span></p></td></tr><tr class="c10"><td class="c42" colspan="1" rowspan="1"><p class="c46"><span class="c54 c40">FailOnNonNumber</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c46"><span class="c54 c40">Evaluator</span></p></td></tr><tr class="c75"><td class="c42" colspan="1" rowspan="1"><p class="c46"><span class="c54 c40">InverseShift</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c46"><span class="c54 c40">unchain_variables</span></p></td></tr><tr class="c10"><td class="c42" colspan="1" rowspan="1"><p class="c46"><span class="c54 c40">LinearShift</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c23"><span class="c54 c40"></span></p></td></tr><tr class="c10"><td class="c42" colspan="1" rowspan="1"><p class="c46"><span class="c54 c40">LogReport</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c23"><span class="c40 c54"></span></p></td></tr><tr class="c10"><td class="c42" colspan="1" rowspan="1"><p class="c46"><span class="c54 c40">MicroAverage</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c23"><span class="c54 c40"></span></p></td></tr><tr class="c10"><td class="c42" colspan="1" rowspan="1"><p class="c46"><span class="c54 c40">MultistepShift</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c23"><span class="c54 c40"></span></p></td></tr><tr class="c10"><td class="c42" colspan="1" rowspan="1"><p class="c46"><span class="c54 c40">ParameterStatistics</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c23"><span class="c54 c40"></span></p></td></tr><tr class="c10"><td class="c42" colspan="1" rowspan="1"><p class="c46"><span class="c54 c40">PlotReport</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c23"><span class="c54 c40"></span></p></td></tr><tr class="c10"><td class="c42" colspan="1" rowspan="1"><p class="c46"><span class="c54 c40">PolynomialShift</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c23"><span class="c54 c40"></span></p></td></tr><tr class="c10"><td class="c42" colspan="1" rowspan="1"><p class="c46"><span class="c54 c40">PrintReport</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c23"><span class="c54 c40"></span></p></td></tr><tr class="c10"><td class="c42" colspan="1" rowspan="1"><p class="c46"><span class="c54 c40">ProgressBar</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c23"><span class="c54 c40"></span></p></td></tr><tr class="c10"><td class="c42" colspan="1" rowspan="1"><p class="c46"><span class="c54 c40">snapshot(read docs)</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c23"><span class="c54 c40"></span></p></td></tr><tr class="c10"><td class="c42" colspan="1" rowspan="1"><p class="c46"><span class="c54 c40">StepShift</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c23"><span class="c54 c40"></span></p></td></tr><tr class="c10"><td class="c42" colspan="1" rowspan="1"><p class="c46"><span class="c54 c40">observe_lr</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c23"><span class="c54 c40"></span></p></td></tr><tr class="c10"><td class="c42" colspan="1" rowspan="1"><p class="c46"><span class="c54 c40">VariableStatisticsPlot</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c23"><span class="c54 c40"></span></p></td></tr><tr class="c10"><td class="c42" colspan="1" rowspan="1"><p class="c46"><span class="c54 c40">WarmupShift</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c23"><span class="c54 c40"></span></p></td></tr></tbody></table><p class="c8"><span class="c9">Some drawbacks rely on that metrics associated to the model or links might not accessible by default.</span></p><p class="c8"><span class="c9">For example the user will need to report the loss or accuracy per iteration by using an ignite callback as this was done inside the chainer model.</span></p><p class="c7"><span class="c9"></span></p><p class="c8"><span class="c9">Also for some extensions to work it is necessary for the user to assign the torch or chainer model to the optimizer target attribute and the output directory path for the LogReport, plotters and snapshot extensions</span></p><a id="t.d3bbb7d0330927644916c6808491d67b611bb39a"></a><a id="t.15"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c11"><span class="c16 c55">from chainer import reporter<br>@trainer.on(Events.ITERATION_COMPLETED)</span></p><p class="c11"><span class="c55 c16">def report_loss(engine):</span></p><p class="c11"><span class="c55 c16">&nbsp; &nbsp; reporter.report({&#39;loss&#39;:engine.state.output})</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><p class="c8"><span class="c9">An example of how to register multiple extensions:</span></p><a id="t.8bbf20fa9e631df5f36bd1501c7e922ff7c73524"></a><a id="t.16"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c11"><span class="c16 c65"># Torch optimizer</span><span class="c55 c16"><br>optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)</span></p><p class="c11"><span class="c56 c16"># Ignite trainer</span></p><p class="c11"><span class="c55 c16">trainer = create_supervised_trainer(model, optimizer, F.nll_loss, device=device)</span></p><p class="c11"><span class="c16"><br></span><span class="c56 c16"># Add the model to the target attribute of the optimizer</span></p><p class="c11"><span class="c55 c16">optimizer.target = model</span></p><p class="c11 c50"><span class="c55 c16"></span></p><p class="c11"><span class="c16 c65"># Set the output dir for some of the extensions</span></p><p class="c11"><span class="c55 c16">trainer.out = &#39;result&#39;</span></p><p class="c11 c50"><span class="c55 c16"></span></p><p class="c11"><span class="c56 c16"># Restore the snapshot</span></p><p class="c11"><span class="c55 c16">cpm.ignite.load_chainer_snapshot(trainer, optimizer, &#39;result/snapshot_iter_4691&#39;)</span></p><p class="c11 c50"><span class="c55 c16"></span></p><p class="c11"><span class="c56 c16"># Add a bunch of extensions</span></p><p class="c11"><span class="c55 c16">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.ProgressBar())</span></p><p class="c11"><span class="c55 c16">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.observe_lr())</span></p><p class="c11"><span class="c55 c16">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.MicroAverage(&#39;loss&#39;,&#39;lr&#39;,&#39;mav&#39;,(1, &#39;iteration&#39;)))</span></p><p class="c11"><span class="c55 c16">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.LogReport())</span></p><p class="c11"><span class="c55 c16">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.FailOnNonNumber())</span></p><p class="c11"><span class="c55 c16">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.ExponentialShift(&#39;lr&#39;, 0.9, 1.0, 0.1))</span></p><p class="c11"><span class="c55 c16">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.ParameterStatistics(model, prefix=&#39;model&#39;))</span></p><p class="c11"><span class="c55 c16">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.VariableStatisticsPlot(model))</span></p><p class="c11"><span class="c55 c16">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.PrintReport(</span></p><p class="c11"><span class="c55 c16">&nbsp; &nbsp; [&#39;epoch&#39;, &#39;iteration&#39;, &#39;loss&#39;, &#39;lr&#39;, &#39;mav&#39;, &#39;model/fc2/weight/grad/percentile/1&#39;]))</span></p><p class="c11"><span class="c55 c16">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.PlotReport([&#39;loss&#39;],</span></p><p class="c11"><span class="c55 c16">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;epoch&#39;, filename=&#39;loss.png&#39;))</span></p><p class="c11"><span class="c16">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.snapshot(writer=</span><span class="c16">writer)</span><span class="c16">, trigger=(1, &#39;epoch&#39;)) &nbsp;# writer is a SimpleWriter</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><h3 class="c51 c33" id="h.ojt9418jpkms"><span class="c21">Snapshots</span></h3><p class="c7"><span class="c9"></span></p><p class="c8"><span class="c9">When using the snapshot extension with an ignite trainer, the pytorch objects are saved to an additional &ldquo;snapshot-torch&rdquo; file in the output folder. This allows to keep using these snapshots once the migration is finished and directly load pytorch models or the optimizer state from these files.</span></p><p class="c8"><span class="c9">Additionally, if you are mixing chainer models or optimizers with ignite and pytorch, these objects will be saved in the chainer snapshot file.</span></p><p class="c7"><span class="c9"></span></p><p class="c8"><span>The correct way to restore a snapshot is by using </span><span class="c40">cpm.ignite.load_chainer_snapshot(engine, optimizer, snapshot_path) </span><span class="c9">with the Chainer snapshot path.</span></p><p class="c8"><span class="c58 c72">Note that previously taken Chainer snapshots are not compatible.</span></p><h2 class="c35 c33" id="h.s8lyt5panb7"><span class="c77 c67 c36">Porting custom updater using Ignite</span></h2><p class="c8"><span class="c9">You can pass a step function to an Ignite engine.</span></p><ul class="c30 lst-kix_ne2kodfi1kix-0 start"><li class="c8 c43"><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/ignite/blob/55cb30b06330a1fd7bf1c7e0d23cba89b10f75bf/examples/gan/dcgan.py%23L308&amp;sa=D&amp;ust=1575460959759000">DCGAN example</a></span></li></ul><h2 class="c35 c33" id="h.xmsyb5asd2c9"><span class="c77 c67 c36">Rewriting existing Chainer model</span></h2><p class="c8"><span>Use </span><span class="c31"><a class="c4" href="#h.mkuuagm60br0">Mapping of functions and links</a></span><span class="c9">&nbsp;to find and replace with the corresponding feature in PyTorch. You can also find existing model implementations in:</span></p><ul class="c30 lst-kix_mfwegjdddisb-0 start"><li class="c8 c43"><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/examples&amp;sa=D&amp;ust=1575460959760000">PyTorch Examples</a></span></li><li class="c8 c43"><span class="c26">torchvision.models</span><span>&nbsp;module (CV models) (</span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torchvision/models.html&amp;sa=D&amp;ust=1575460959761000">API Reference</a></span><span class="c9">)</span></li><li class="c8 c43"><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/hub&amp;sa=D&amp;ust=1575460959761000">PyTorch Hub</a></span><span>&nbsp;(models from community) (</span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/master/hub.html&amp;sa=D&amp;ust=1575460959762000">API Reference</a></span><span class="c9">)</span></li></ul><p class="c7"><span class="c9"></span></p><p class="c8"><span class="c9">Common pitfalls:</span></p><ul class="c30 lst-kix_r60cdwx1dlic-0 start"><li class="c8 c43"><span class="c9">Image format: RGB or BGR</span></li><li class="c8 c43"><span class="c9">Image normalization: [0,1] or [0,255]</span></li><li class="c8 c43"><span>Some old PyTorch examples and community projects are using </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/autograd.html%23variable-deprecated&amp;sa=D&amp;ust=1575460959763000">torch.autograd.Variable</a></span><span class="c9">, which is a deprecated interface.</span></li><li class="c8 c43"><span>Some well-known models such as resnet might have different behavior in ChainerCV and torchvision. For example, </span><span class="c26">chainercv.links.ResNet50</span><span>&nbsp;applies softmax to the output while </span><span class="c26">torchvision.models.resnet50</span><span class="c9">&nbsp;does not.</span></li></ul><h2 class="c35 c33" id="h.mkuuagm60br0"><span class="c77 c67 c36">Functions and Links</span></h2><p class="c8"><span class="c9">You can find the PyTorch equivalent of Chainer&#39;s functions and links in tables below.</span></p><p class="c7"><span class="c9"></span></p><p class="c8"><span class="c9">Notes:</span></p><ul class="c30 lst-kix_c4453ihcjob0-0 start"><li class="c8 c43"><span>Unlike NumPy/CuPy, PyTorch Tensor itself supports gradient computation (you can safely use </span><span class="c26">torch.*</span><span>&nbsp;or </span><span class="c26">torch.nn.functional.*</span><span>&nbsp;on </span><span class="c26">torch.Tensor</span><span class="c9">)</span></li><li class="c8 c43"><span>Conventions of keyword arguments: </span><span class="c26">dim</span><span>&nbsp;and </span><span class="c26">keepdim</span><span>&nbsp;is used in PyTorch instead of </span><span class="c26">axis</span><span>&nbsp;and </span><span class="c26">keepdims</span><span class="c9">&nbsp;in Chainer/NumPy.</span></li><li class="c8 c43"><span>Unlike Chainer, PyTorch provides the Module version of each function (e.g., </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.ReLU&amp;sa=D&amp;ust=1575460959767000">nn.ReLU</a></span><span>&nbsp;for </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.relu&amp;sa=D&amp;ust=1575460959767000">F.relu</a></span><span>), so you can use the Module version when defining model using functions in </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23sequential&amp;sa=D&amp;ust=1575460959768000">Sequential</a></span><span class="c9">&nbsp;container.</span></li></ul><h3 class="c51 c33" id="h.e17stx2v9ds3"><span class="c21">Functions</span></h3><p class="c8"><span class="c26">F</span><span>&nbsp;refers to </span><span class="c26">chainer.functions</span><span>&nbsp;(Chainer) / </span><span class="c26">torch.nn.functional</span><span>&nbsp;(PyTorch).</span></p><p class="c7"><span class="c9"></span></p><a id="t.7fa7c1da8285fdbfa01e4ca8958aa5937015caa3"></a><a id="t.17"></a><table class="c20"><tbody><tr class="c24"><td class="c97" colspan="1" rowspan="1"><p class="c84 c103"><span class="c25">Chainer</span></p></td><td class="c85" colspan="1" rowspan="1"><p class="c84 c103"><span class="c25">PyTorch</span></p></td><td class="c86" colspan="1" rowspan="1"><p class="c84 c103"><span class="c25">Notes</span></p></td></tr><tr class="c18"><td class="c115" colspan="3" rowspan="1"><p class="c8"><span class="c25">Arithmetic functions</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.add.html%23chainer.functions.add&amp;sa=D&amp;ust=1575460959776000">F.add</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.add&amp;sa=D&amp;ust=1575460959777000">torch.add</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Batched addition (accumulating multiple tensors in a single call) is not supported.</span></p></td></tr><tr class="c18"><td class="c111" colspan="3" rowspan="1"><p class="c8"><span class="c25">Activation functions</span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.clipped_relu.html%23chainer.functions.clipped_relu&amp;sa=D&amp;ust=1575460959780000">F.clipped_relu</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Rewrite as:</span></p><p class="c8"><span class="c26 c37">x.</span><span class="c3 c26"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/tensors.html%23torch.Tensor.clamp&amp;sa=D&amp;ust=1575460959782000">clamp</a></span><span class="c55 c26 c37">(0, z)</span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.crelu.html%23chainer.functions.crelu&amp;sa=D&amp;ust=1575460959783000">F.crelu</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Rewrite as:</span></p><p class="c8"><span class="c3 c26"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.cat&amp;sa=D&amp;ust=1575460959784000">torch.cat</a></span><span class="c55 c26 c37">((F.relu(x), F.relu(-x)))</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.elu.html%23chainer.functions.elu&amp;sa=D&amp;ust=1575460959785000">F.elu</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.elu&amp;sa=D&amp;ust=1575460959786000">F.elu</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.hard_sigmoid.html%23chainer.functions.hard_sigmoid&amp;sa=D&amp;ust=1575460959787000">F.hard_sigmoid</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Rewrite as:</span></p><p class="c8"><span class="c3 c26"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.clamp&amp;sa=D&amp;ust=1575460959788000">torch.clamp</a></span><span class="c55 c26 c37">(x * 0.2 + 0.5, 0, 1)</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.leaky_relu.html%23chainer.functions.leaky_relu&amp;sa=D&amp;ust=1575460959789000">F.leaky_relu</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.leaky_relu&amp;sa=D&amp;ust=1575460959790000">F.leaky_relu</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">The default slope value is different.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.log_softmax.html%23chainer.functions.log_softmax&amp;sa=D&amp;ust=1575460959792000">F.log_softmax</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.log_softmax&amp;sa=D&amp;ust=1575460959793000">F.log_softmax</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.lstm.html%23chainer.functions.lstm&amp;sa=D&amp;ust=1575460959794000">F.lstm</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">See L.LSTM.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.maxout.html%23chainer.functions.maxout&amp;sa=D&amp;ust=1575460959796000">F.maxout</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">Need to implement manually; see </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/issues/805&amp;sa=D&amp;ust=1575460959797000">https://github.com/pytorch/pytorch/issues/805</a></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.prelu.html%23chainer.functions.prelu&amp;sa=D&amp;ust=1575460959798000">F.prelu</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.prelu&amp;sa=D&amp;ust=1575460959799000">F.prelu</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.rrelu.html%23chainer.functions.rrelu&amp;sa=D&amp;ust=1575460959801000">F.rrelu</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.rrelu&amp;sa=D&amp;ust=1575460959801000">F.rrelu</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">`training` option must be explicitly specified instead of `train` config in Chainer.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.relu.html%23chainer.functions.relu&amp;sa=D&amp;ust=1575460959803000">F.relu</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.relu&amp;sa=D&amp;ust=1575460959804000">F.relu</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.relu6.html%23chainer.functions.relu6&amp;sa=D&amp;ust=1575460959805000">F.relu6</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.relu6&amp;sa=D&amp;ust=1575460959806000">F.relu6</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.selu.html%23chainer.functions.selu&amp;sa=D&amp;ust=1575460959807000">F.selu</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.selu&amp;sa=D&amp;ust=1575460959809000">F.selu</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.sigmoid.html%23chainer.functions.sigmoid&amp;sa=D&amp;ust=1575460959811000">F.sigmoid</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.sigmoid&amp;sa=D&amp;ust=1575460959812000">F.sigmoid</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.slstm.html%23chainer.functions.slstm&amp;sa=D&amp;ust=1575460959814000">F.slstm</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">Some OSS implementations are available (e.g., </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/reachtarunhere/S-LSTM-PyTorch&amp;sa=D&amp;ust=1575460959816000">https://github.com/reachtarunhere/S-LSTM-PyTorch</a></span><span class="c1">)</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.softmax.html%23chainer.functions.softmax&amp;sa=D&amp;ust=1575460959817000">F.softmax</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.softmax&amp;sa=D&amp;ust=1575460959818000">F.softmax</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.softplus.html%23chainer.functions.softplus&amp;sa=D&amp;ust=1575460959820000">F.softplus</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.softplus&amp;sa=D&amp;ust=1575460959821000">F.softplus</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">PyTorch falls back to linear function by default; threshold option must be explicitly given.</span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.swish.html%23chainer.functions.swish&amp;sa=D&amp;ust=1575460959823000">F.swish</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Rewrite as:</span></p><p class="c8"><span class="c26 c37">x * </span><span class="c3 c26"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.sigmoid&amp;sa=D&amp;ust=1575460959825000">F.sigmoid</a></span><span class="c55 c26 c37">(beta * x)</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.tanh.html%23chainer.functions.tanh&amp;sa=D&amp;ust=1575460959827000">F.tanh</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.tanh&amp;sa=D&amp;ust=1575460959828000">F.tanh</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.tree_lstm.html%23chainer.functions.tree_lstm&amp;sa=D&amp;ust=1575460959829000">F.tree_lstm</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">Some OSS implementations are available (e.g., </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/dasguptar/treelstm.pytorch&amp;sa=D&amp;ust=1575460959831000">https://github.com/dasguptar/treelstm.pytorch</a></span><span class="c1">)</span></p></td></tr><tr class="c18"><td class="c63" colspan="3" rowspan="1"><p class="c8"><span class="c25">Array manipulations</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.as_strided.html%23chainer.functions.as_strided&amp;sa=D&amp;ust=1575460959834000">F.as_strided</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.as_strided&amp;sa=D&amp;ust=1575460959836000">torch.as_strided</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.broadcast.html%23chainer.functions.broadcast&amp;sa=D&amp;ust=1575460959837000">F.broadcast</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.broadcast_tensors&amp;sa=D&amp;ust=1575460959838000">torch.broadcast_tensors</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">PyTorch operations perform broadcast automatically like as in NumPy: </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/notes/broadcasting.html&amp;sa=D&amp;ust=1575460959840000">https://pytorch.org/docs/stable/notes/broadcasting.html</a></span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.broadcast_to.html%23chainer.functions.broadcast_to&amp;sa=D&amp;ust=1575460959841000">F.broadcast_to</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">N/A: </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/pull/17160&amp;sa=D&amp;ust=1575460959842000">https://github.com/pytorch/pytorch/pull/17160</a></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.cast.html%23chainer.functions.cast&amp;sa=D&amp;ust=1575460959844000">F.cast</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/tensors.html%23torch.Tensor.to&amp;sa=D&amp;ust=1575460959845000">Tensor.to</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.concat.html%23chainer.functions.concat&amp;sa=D&amp;ust=1575460959846000">F.concat</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.cat&amp;sa=D&amp;ust=1575460959847000">torch.cat</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.copy.html%23chainer.functions.copy&amp;sa=D&amp;ust=1575460959849000">F.copy</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/tensors.html%23torch.Tensor.to&amp;sa=D&amp;ust=1575460959850000">Tensor.to</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.depth2space.html%23chainer.functions.depth2space&amp;sa=D&amp;ust=1575460959851000">F.depth2space</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.pixel_shuffle&amp;sa=D&amp;ust=1575460959852000">F.pixel_shuffle</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.diagonal.html%23chainer.functions.diagonal&amp;sa=D&amp;ust=1575460959854000">F.diagonal</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.diagonal&amp;sa=D&amp;ust=1575460959854000">torch.diagonal</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.dstack.html%23chainer.functions.dstack&amp;sa=D&amp;ust=1575460959856000">F.dstack</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Rewrite as:</span></p><p class="c8"><span class="c3 c26"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.cat&amp;sa=D&amp;ust=1575460959858000">torch.cat</a></span><span class="c55 c26 c37">([a,b],dim=2)</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.expand_dims.html%23chainer.functions.expand_dims&amp;sa=D&amp;ust=1575460959859000">F.expand_dims</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">Rewrite as:</span></p><p class="c8"><span class="c3 c26"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.unsqueeze&amp;sa=D&amp;ust=1575460959861000">torch.unsqueeze</a></span><span class="c55 c26 c37">(a, dim)</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.flatten.html%23chainer.functions.flatten&amp;sa=D&amp;ust=1575460959862000">F.flatten</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.flatten&amp;sa=D&amp;ust=1575460959863000">torch.flatten</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.flip.html%23chainer.functions.flip&amp;sa=D&amp;ust=1575460959864000">F.flip</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.flip&amp;sa=D&amp;ust=1575460959865000">torch.flip</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.fliplr.html%23chainer.functions.fliplr&amp;sa=D&amp;ust=1575460959867000">F.fliplr</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.flip&amp;sa=D&amp;ust=1575460959867000">torch.flip</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Use dims=1</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.flipud.html%23chainer.functions.flipud&amp;sa=D&amp;ust=1575460959869000">F.flipud</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.flip&amp;sa=D&amp;ust=1575460959870000">torch.flip</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Use dims=0</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.get_item.html%23chainer.functions.get_item&amp;sa=D&amp;ust=1575460959871000">F.get_item</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Use direct indexing: `x[indexes]`. Negative strides are not supported.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.hstack.html%23chainer.functions.hstack&amp;sa=D&amp;ust=1575460959873000">F.hstack</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Rewrite as:</span></p><p class="c8"><span class="c3 c26"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.cat&amp;sa=D&amp;ust=1575460959875000">torch.cat</a></span><span class="c55 c26 c37">([a,b],dim=1)</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.im2col.html%23chainer.functions.im2col&amp;sa=D&amp;ust=1575460959876000">F.im2col</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.unfold&amp;sa=D&amp;ust=1575460959877000">F.unfold</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">NCHW is only supported</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.moveaxis.html%23chainer.functions.moveaxis&amp;sa=D&amp;ust=1575460959879000">F.moveaxis</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23Tensor.permute&amp;sa=D&amp;ust=1575460959880000">Tensor.permute</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">See: </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/swap-axes-in-pytorch/970/2&amp;sa=D&amp;ust=1575460959881000">https://discuss.pytorch.org/t/swap-axes-in-pytorch/970/2</a></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.pad.html%23chainer.functions.pad&amp;sa=D&amp;ust=1575460959882000">F.pad</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.pad&amp;sa=D&amp;ust=1575460959883000">F.pad</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Replace `constant_values` argument with `value`. Modes other than `constant` are also available.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.pad_sequence.html%23chainer.functions.pad_sequence&amp;sa=D&amp;ust=1575460959884000">F.pad_sequence</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html?highlight%3Dpad_sequence%23torch.nn.utils.rnn.pad_sequence&amp;sa=D&amp;ust=1575460959885000">nn.utils.rnn.pad_squence</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">You cannot specify the length but the maximum length among the inputs is used.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.permutate.html%23chainer.functions.permutate&amp;sa=D&amp;ust=1575460959887000">F.permutate</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/tensors.html%23torch.Tensor.permute&amp;sa=D&amp;ust=1575460959888000">Tensor.permute</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.repeat.html%23chainer.functions.repeat&amp;sa=D&amp;ust=1575460959889000">F.repeat</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/tensors.html%23torch.Tensor.repeat&amp;sa=D&amp;ust=1575460959890000">Tensor.repeat</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Different behavior to F.repeat. F.tile is more similar.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.reshape.html%23chainer.functions.reshape&amp;sa=D&amp;ust=1575460959892000">F.reshape</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.reshape&amp;sa=D&amp;ust=1575460959892000">torch.reshape</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.resize_images.html%23chainer.functions.resize_images&amp;sa=D&amp;ust=1575460959894000">F.resize_images</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.interpolate&amp;sa=D&amp;ust=1575460959895000">F.interpolate</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.rollaxis.html%23chainer.functions.rollaxis&amp;sa=D&amp;ust=1575460959896000">F.rollaxis</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/tensors.html%23torch.Tensor.permute&amp;sa=D&amp;ust=1575460959897000">Tensor.premute</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">See </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/swap-axes-in-pytorch/970/2&amp;sa=D&amp;ust=1575460959898000">https://discuss.pytorch.org/t/swap-axes-in-pytorch/970/2</a></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.scatter_add.html%23chainer.functions.scatter_add&amp;sa=D&amp;ust=1575460959898000">F.scatter_add</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/tensors.html%23torch.Tensor.scatter_add&amp;sa=D&amp;ust=1575460959899000">Tensor.scatter_add</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.select_item.html%23chainer.functions.select_item&amp;sa=D&amp;ust=1575460959901000">F.select_item</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Rewrite as:</span></p><p class="c8"><span class="c3 c26"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.gather&amp;sa=D&amp;ust=1575460959902000">torch.gather</a></span><span class="c55 c26 c37">(x, 1, t[:, None])[:, 0]</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.separate.html%23chainer.functions.separate&amp;sa=D&amp;ust=1575460959904000">F.separate</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.split&amp;sa=D&amp;ust=1575460959905000">torch.split</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Requires manual manipulation of the results to achieve some of the separate functionality.</span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.space2depth.html%23chainer.functions.space2depth&amp;sa=D&amp;ust=1575460959906000">F.space2depth</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">You need to implement it yourself. Ref:</span></p><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/is-there-any-layer-like-tensorflows-space-to-depth-function/3487/14&amp;sa=D&amp;ust=1575460959908000">https://discuss.pytorch.org/t/is-there-any-layer-like-tensorflows-space-to-depth-function/3487/14</a></span></p></td></tr><tr class="c71"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.spatial_transformer_grid.html%23chainer.functions.spatial_transformer_grid&amp;sa=D&amp;ust=1575460959910000">F.spatial_transformer_grid</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.affine_grid&amp;sa=D&amp;ust=1575460959910000">F.affine_grid</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">The second argument `size` takes `torch.Size` object that denotes the target output image size (N, C, H, W), while `F.spatial_transformer_grid` takes just a tuple of (H, W). The size of returned tensor is also different: (N x H x W x 2) is returned instead of (N x 2 x H x W). Also note the breaking change regarding align_corners in v1.3.0 (</span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/releases/tag/v1.3.0&amp;sa=D&amp;ust=1575460959911000">https://github.com/pytorch/pytorch/releases/tag/v1.3.0</a></span><span class="c1">)</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.spatial_transformer_sampler.html%23chainer.functions.spatial_transformer_sampler&amp;sa=D&amp;ust=1575460959912000">F.spatial_transformer_sampler</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.grid_sample&amp;sa=D&amp;ust=1575460959913000">F.grid_sample</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Grid shape is (N, 2, H, W) in Chainer while (N, H, W, 2) in PyTorch.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.split_axis.html%23chainer.functions.split_axis&amp;sa=D&amp;ust=1575460959914000">F.split_axis</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.split&amp;sa=D&amp;ust=1575460959915000">torch.split</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">No `force_tuple`.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.squeeze.html%23chainer.functions.squeeze&amp;sa=D&amp;ust=1575460959916000">F.squeeze</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.squeeze&amp;sa=D&amp;ust=1575460959917000">torch.squeeze</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.stack.html%23chainer.functions.stack&amp;sa=D&amp;ust=1575460959918000">F.stack</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.stack&amp;sa=D&amp;ust=1575460959919000">torch.stack</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">Use </span><span class="c3 c26"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.stack&amp;sa=D&amp;ust=1575460959920000">torch.stack</a></span><span class="c37">&nbsp;or </span><span class="c3 c26"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.cat&amp;sa=D&amp;ust=1575460959921000">torch.cat</a></span><span class="c55 c26 c37">([a,b],dim=axis)</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.swapaxes.html%23chainer.functions.swapaxes&amp;sa=D&amp;ust=1575460959922000">F.swapaxes</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">Use permute instead: </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/swap-axes-in-pytorch/970/7&amp;sa=D&amp;ust=1575460959923000">https://discuss.pytorch.org/t/swap-axes-in-pytorch/970/7</a></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.tile.html%23chainer.functions.tile&amp;sa=D&amp;ust=1575460959925000">F.tile</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.repeat&amp;sa=D&amp;ust=1575460959925000">F.repeat</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.transpose.html%23chainer.functions.transpose&amp;sa=D&amp;ust=1575460959927000">F.transpose</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.t&amp;sa=D&amp;ust=1575460959927000">torch.t</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">Use </span><span class="c3 c26"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.t%2520/%2520Tensor.permute&amp;sa=D&amp;ust=1575460959928000">Tensor.permute</a></span><span class="c37">&nbsp;or </span><span class="c3 c26"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.t&amp;sa=D&amp;ust=1575460959928000">torch.t</a></span><span class="c1">&nbsp;for no axes version</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.transpose_sequence.html%23chainer.functions.transpose_sequence&amp;sa=D&amp;ust=1575460959929000">F.transpose_sequence</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.vstack.html%23chainer.functions.vstack&amp;sa=D&amp;ust=1575460959932000">F.vstack</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Rewrite as:</span></p><p class="c8"><span class="c3 c26"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.cat&amp;sa=D&amp;ust=1575460959934000">torch.cat</a></span><span class="c55 c26 c37">([a,b],dim=0)</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.where.html%23chainer.functions.where&amp;sa=D&amp;ust=1575460959935000">F.where</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.where&amp;sa=D&amp;ust=1575460959935000">torch.where</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c99"><td class="c63" colspan="3" rowspan="1"><p class="c8"><span class="c25">Neural network connections</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.bilinear.html%23chainer.functions.bilinear&amp;sa=D&amp;ust=1575460959938000">F.bilinear</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.bilinear&amp;sa=D&amp;ust=1575460959939000">F.bilinear</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.convolution_1d.html%23chainer.functions.convolution_1d&amp;sa=D&amp;ust=1575460959940000">F.convolution_1d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.conv1d&amp;sa=D&amp;ust=1575460959941000">F.conv1d</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">No `cover_all`.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.convolution_2d.html%23chainer.functions.convolution_2d&amp;sa=D&amp;ust=1575460959943000">F.convolution_2d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.conv2d&amp;sa=D&amp;ust=1575460959944000">F.conv2d</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">No `cover_all`.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.convolution_3d.html%23chainer.functions.convolution_3d&amp;sa=D&amp;ust=1575460959945000">F.convolution_3d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.conv3d&amp;sa=D&amp;ust=1575460959946000">F.conv3d</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">No `cover_all`.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.convolution_nd.html%23chainer.functions.convolution_nd&amp;sa=D&amp;ust=1575460959948000">F.convolution_nd</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">See </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/is-there-a-way-to-realize-4d-convolution-using-the-convnd-function/5999&amp;sa=D&amp;ust=1575460959950000">https://discuss.pytorch.org/t/is-there-a-way-to-realize-4d-convolution-using-the-convnd-function/5999</a></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.deconvolution_1d.html%23chainer.functions.deconvolution_1d&amp;sa=D&amp;ust=1575460959951000">F.deconvolution_1d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.conv_transpose1d&amp;sa=D&amp;ust=1575460959952000">F.conv_transpose1d</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.deconvolution_2d.html%23chainer.functions.deconvolution_2d&amp;sa=D&amp;ust=1575460959954000">F.deconvolution_2d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.conv_transpose2d&amp;sa=D&amp;ust=1575460959955000">F.conv_transpose2d</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.deconvolution_3d.html%23chainer.functions.deconvolution_3d&amp;sa=D&amp;ust=1575460959957000">F.deconvolution_3d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.conv_transpose3d&amp;sa=D&amp;ust=1575460959958000">F.conv_transpose3d</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.deconvolution_nd.html%23chainer.functions.deconvolution_nd&amp;sa=D&amp;ust=1575460959959000">F.deconvolution_nd</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">N/A, see </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/is-there-a-way-to-realize-4d-convolution-using-the-convnd-function/5999&amp;sa=D&amp;ust=1575460959961000">https://discuss.pytorch.org/t/is-there-a-way-to-realize-4d-convolution-using-the-convnd-function/5999</a></span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.depthwise_convolution_2d.html%23chainer.functions.depthwise_convolution_2d&amp;sa=D&amp;ust=1575460959962000">F.depthwise_convolution_2d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.conv2d&amp;sa=D&amp;ust=1575460959963000">F.conv2d</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">Use `groups` argument; see </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/depthwise-and-separable-convolutions-in-pytorch/7315/2&amp;sa=D&amp;ust=1575460959964000">https://discuss.pytorch.org/t/depthwise-and-separable-convolutions-in-pytorch/7315/2</a></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.deformable_convolution_2d_sampler.html%23chainer.functions.deformable_convolution_2d_sampler&amp;sa=D&amp;ust=1575460959965000">F.deformable_convolution_2d_sampler</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">Not implemented: </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/issues/2260&amp;sa=D&amp;ust=1575460959966000">https://github.com/pytorch/pytorch/issues/2260</a></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.dilated_convolution_2d.html%23chainer.functions.dilated_convolution_2d&amp;sa=D&amp;ust=1575460959967000">F.dilated_convolution_2d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.conv2d&amp;sa=D&amp;ust=1575460959968000">F.conv2d</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Use `dilation` argument.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.embed_id.html%23chainer.functions.embed_id&amp;sa=D&amp;ust=1575460959969000">F.embed_id</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23embedding&amp;sa=D&amp;ust=1575460959970000">Embedding</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.linear.html%23chainer.functions.linear&amp;sa=D&amp;ust=1575460959971000">F.linear</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.linear&amp;sa=D&amp;ust=1575460959972000">F.linear</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">There is no option for `n_batch_axes`.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.local_convolution_2d.html%23chainer.functions.local_convolution_2d&amp;sa=D&amp;ust=1575460959973000">F.local_convolution_2d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">See </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/pull/1583&amp;sa=D&amp;ust=1575460959975000">https://github.com/pytorch/pytorch/pull/1583</a></span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.n_step_bigru.html%23chainer.functions.n_step_bigru&amp;sa=D&amp;ust=1575460959976000">F.n_step_bigru</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">Undocumented _C._VariableFunctions function torch.gru? The &quot;link&quot; is available </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.GRU&amp;sa=D&amp;ust=1575460959978000">https://pytorch.org/docs/stable/nn.html#torch.nn.GRU</a></span><span class="c1">&nbsp;and this is probably the expected usage.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.n_step_bilstm.html%23chainer.functions.n_step_bilstm&amp;sa=D&amp;ust=1575460959979000">F.n_step_bilstm</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">See L.NStepBiLSTM.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.n_step_birnn.html%23chainer.functions.n_step_birnn&amp;sa=D&amp;ust=1575460959980000">F.n_step_birnn</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">See L.NStepBiRNNTanh or L.NStepBiRNNReLU.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.n_step_gru.html%23chainer.functions.n_step_gru&amp;sa=D&amp;ust=1575460959982000">F.n_step_gru</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">See L.NStepBiGRU.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.n_step_lstm.html%23chainer.functions.n_step_lstm&amp;sa=D&amp;ust=1575460959984000">F.n_step_lstm</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">See L.NStepLSTM.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.n_step_rnn.html%23chainer.functions.n_step_rnn&amp;sa=D&amp;ust=1575460959986000">F.n_step_rnn</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">See L.NStepRNNTanh or L.NStepRNNReLU.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.shift.html%23chainer.functions.shift&amp;sa=D&amp;ust=1575460959988000">F.shift</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">See </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/issues/16408&amp;sa=D&amp;ust=1575460959990000">https://github.com/pytorch/pytorch/issues/16408</a></span></p></td></tr><tr class="c18"><td class="c63" colspan="3" rowspan="1"><p class="c8"><span class="c25">Evaluation functions</span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.accuracy.html%23chainer.functions.accuracy&amp;sa=D&amp;ust=1575460959992000">F.accuracy</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">N/A, Ignite has an implementation: </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/ignite/metrics.html%23ignite.metrics.Accuracy&amp;sa=D&amp;ust=1575460959993000">https://pytorch.org/ignite/metrics.html#ignite.metrics.Accuracy</a></span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.binary_accuracy.html%23chainer.functions.binary_accuracy&amp;sa=D&amp;ust=1575460959995000">F.binary_accuracy</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">N/A, Ignite has an implementation: </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/ignite/metrics.html%23ignite.metrics.Accuracy&amp;sa=D&amp;ust=1575460959996000">https://pytorch.org/ignite/metrics.html#ignite.metrics.Accuracy</a></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.classification_summary.html%23chainer.functions.classification_summary&amp;sa=D&amp;ust=1575460959997000">F.classification_summary</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.f1_score.html%23chainer.functions.f1_score&amp;sa=D&amp;ust=1575460959999000">F.f1_score</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">See </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/calculating-precision-recall-and-f1-score-in-case-of-multi-label-classification/28265/1&amp;sa=D&amp;ust=1575460960001000">https://discuss.pytorch.org/t/calculating-precision-recall-and-f1-score-in-case-of-multi-label-classification/28265/1</a></span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.precision.html%23chainer.functions.precision&amp;sa=D&amp;ust=1575460960002000">F.precision</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">N/A, Ignite has an implementation: </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/ignite/metrics.html%23ignite.metrics.Precision&amp;sa=D&amp;ust=1575460960003000">https://pytorch.org/ignite/metrics.html#ignite.metrics.Precision</a></span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.r2_score.html%23chainer.functions.r2_score&amp;sa=D&amp;ust=1575460960004000">F.r2_score</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">Not available. It&#39;s an evaluation metric that&#39;s not differentiable. It&#39;s implemented in Ignite though and could be used (as a reference) </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/ignite/pull/496&amp;sa=D&amp;ust=1575460960005000">https://github.com/pytorch/ignite/pull/496</a></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.recall.html%23chainer.functions.recall&amp;sa=D&amp;ust=1575460960006000">F.recall</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">N/A, Ignite has an implementation: </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/ignite/metrics.html%23ignite.metrics.Recall&amp;sa=D&amp;ust=1575460960007000">https://pytorch.org/ignite/metrics.html#ignite.metrics.Recall</a></span></p></td></tr><tr class="c18"><td class="c63" colspan="3" rowspan="1"><p class="c8"><span class="c25">Loss functions</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.absolute_error.html%23chainer.functions.absolute_error&amp;sa=D&amp;ust=1575460960009000">F.absolute_error</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.bernoulli_nll.html%23chainer.functions.bernoulli_nll&amp;sa=D&amp;ust=1575460960011000">F.bernoulli_nll</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Possibly: -torch.distributions.Bernoulli(y).log_prob(x).sum()</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.black_out.html%23chainer.functions.black_out&amp;sa=D&amp;ust=1575460960013000">F.black_out</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.connectionist_temporal_classification.html%23chainer.functions.connectionist_temporal_classification&amp;sa=D&amp;ust=1575460960015000">F.connectionist_temporal_classification</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.ctc_loss&amp;sa=D&amp;ust=1575460960016000">F.ctc_loss</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.contrastive.html%23chainer.functions.contrastive&amp;sa=D&amp;ust=1575460960017000">F.contrastive</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">See </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/adambielski/siamese-triplet&amp;sa=D&amp;ust=1575460960019000">https://github.com/adambielski/siamese-triplet</a></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.crf1d.html%23chainer.functions.crf1d&amp;sa=D&amp;ust=1575460960019000">F.crf1d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">Not available: </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/issues/11134&amp;sa=D&amp;ust=1575460960021000">https://github.com/pytorch/pytorch/issues/11134</a></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.argmax_crf1d.html%23chainer.functions.argmax_crf1d&amp;sa=D&amp;ust=1575460960022000">F.argmax_crf1d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">Not available: </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/issues/11134&amp;sa=D&amp;ust=1575460960023000">https://github.com/pytorch/pytorch/issues/11134</a></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.cross_covariance.html%23chainer.functions.cross_covariance&amp;sa=D&amp;ust=1575460960024000">F.cross_covariance</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.decov.html%23chainer.functions.decov&amp;sa=D&amp;ust=1575460960025000">F.decov</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.discriminative_margin_based_clustering_loss.html%23chainer.functions.discriminative_margin_based_clustering_loss&amp;sa=D&amp;ust=1575460960027000">F.discriminative_margin_based_clustering_loss</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">Not available. See </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/Wizaron/instance-segmentation-pytorch&amp;sa=D&amp;ust=1575460960028000">https://github.com/Wizaron/instance-segmentation-pytorch</a></span><span class="c1">&nbsp;for a reproducing work.</span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.gaussian_kl_divergence.html%23chainer.functions.gaussian_kl_divergence&amp;sa=D&amp;ust=1575460960029000">F.gaussian_kl_divergence</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.gaussian_nll.html%23chainer.functions.gaussian_nll&amp;sa=D&amp;ust=1575460960031000">F.gaussian_nll</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.hinge.html%23chainer.functions.hinge&amp;sa=D&amp;ust=1575460960033000">F.hinge</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23hinge-embedding-loss&amp;sa=D&amp;ust=1575460960034000">F.hinge_embedding_loss</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.huber_loss.html%23chainer.functions.huber_loss&amp;sa=D&amp;ust=1575460960035000">F.huber_loss</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.smooth_l1_loss&amp;sa=D&amp;ust=1575460960036000">F.smooth_l1_loss</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Use reduction=&#39;sum&#39; to keep reduction method</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.mean_absolute_error.html%23chainer.functions.mean_absolute_error&amp;sa=D&amp;ust=1575460960037000">F.mean_absolute_error</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.l1_loss&amp;sa=D&amp;ust=1575460960038000">F.l1_loss</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">See also: ignite.metrics.MeanAbsoluteError</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.mean_squared_error.html%23chainer.functions.mean_squared_error&amp;sa=D&amp;ust=1575460960040000">F.mean_squared_error</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.mse_loss&amp;sa=D&amp;ust=1575460960040000">F.mse_loss</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.negative_sampling.html%23chainer.functions.negative_sampling&amp;sa=D&amp;ust=1575460960042000">F.negative_sampling</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">See </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/kefirski/pytorch_NEG_loss&amp;sa=D&amp;ust=1575460960043000">https://github.com/kefirski/pytorch_NEG_loss</a></span><span class="c37">, </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/theeluwin/pytorch-sgns&amp;sa=D&amp;ust=1575460960044000">https://github.com/theeluwin/pytorch-sgns</a></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.sigmoid_cross_entropy.html%23chainer.functions.sigmoid_cross_entropy&amp;sa=D&amp;ust=1575460960045000">F.sigmoid_cross_entropy</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.binary_cross_entropy_with_logits&amp;sa=D&amp;ust=1575460960046000">F.binary_cross_entropy_with_logits</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.softmax_cross_entropy.html%23chainer.functions.softmax_cross_entropy&amp;sa=D&amp;ust=1575460960048000">F.softmax_cross_entropy</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.CrossEntropyLoss&amp;sa=D&amp;ust=1575460960049000">F.CrossEntropyLoss</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.squared_error.html%23chainer.functions.squared_error&amp;sa=D&amp;ust=1575460960051000">F.squared_error</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.triplet.html%23chainer.functions.triplet&amp;sa=D&amp;ust=1575460960053000">F.triplet</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.triplet_margin_loss&amp;sa=D&amp;ust=1575460960054000">F.triplet_margin_loss</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c63" colspan="3" rowspan="1"><p class="c8"><span class="c25">Mathematical functions</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.absolute.html%23chainer.functions.absolute&amp;sa=D&amp;ust=1575460960058000">F.absolute</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.abs&amp;sa=D&amp;ust=1575460960059000">torch.abs</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.arccos.html%23chainer.functions.arccos&amp;sa=D&amp;ust=1575460960061000">F.arccos</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.acos&amp;sa=D&amp;ust=1575460960062000">torch.acos</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.arcsin.html%23chainer.functions.arcsin&amp;sa=D&amp;ust=1575460960063000">F.arcsin</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.asin&amp;sa=D&amp;ust=1575460960064000">torch.asin</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.arctan.html%23chainer.functions.arctan&amp;sa=D&amp;ust=1575460960065000">F.arctan</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.atan&amp;sa=D&amp;ust=1575460960066000">torch.atan</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.arctan2.html%23chainer.functions.arctan2&amp;sa=D&amp;ust=1575460960068000">F.arctan2</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.atan2&amp;sa=D&amp;ust=1575460960069000">torch.atan2</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.arctanh.html%23chainer.functions.arctanh&amp;sa=D&amp;ust=1575460960070000">F.arctanh</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">N/A: </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/issues/10324&amp;sa=D&amp;ust=1575460960072000">https://github.com/pytorch/pytorch/issues/10324</a></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.argmax.html%23chainer.functions.argmax&amp;sa=D&amp;ust=1575460960073000">F.argmax</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.argmax&amp;sa=D&amp;ust=1575460960074000">torch.argmax</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.argmin.html%23chainer.functions.argmin&amp;sa=D&amp;ust=1575460960076000">F.argmin</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.argmin&amp;sa=D&amp;ust=1575460960078000">torch.argmin</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.average.html%23chainer.functions.average&amp;sa=D&amp;ust=1575460960079000">F.average</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">See F.mean.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.batch_inv.html%23chainer.functions.batch_inv&amp;sa=D&amp;ust=1575460960082000">F.batch_inv</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.inverse&amp;sa=D&amp;ust=1575460960083000">torch.inverse</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">linalg ops batch is on progress, inverse is already merged</span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.batch_l2_norm_squared.html%23chainer.functions.batch_l2_norm_squared&amp;sa=D&amp;ust=1575460960085000">F.batch_l2_norm_squared</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Rewrite as:</span></p><p class="c8"><span class="c55 c26 c37">x.reshape(len(x), -1).norm(dim=1) ** 2</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.batch_matmul.html%23chainer.functions.batch_matmul&amp;sa=D&amp;ust=1575460960087000">F.batch_matmul</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.matmul&amp;sa=D&amp;ust=1575460960088000">torch.matmul</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.bias.html%23chainer.functions.bias&amp;sa=D&amp;ust=1575460960090000">F.bias</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Rewrite as</span></p><p class="c8"><span class="c55 c26 c37">x + y[(...,) + (None,) * (x.ndim - y.ndim - axis)]</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.ceil.html%23chainer.functions.ceil&amp;sa=D&amp;ust=1575460960093000">F.ceil</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.ceil&amp;sa=D&amp;ust=1575460960094000">torch.ceil</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.clip.html%23chainer.functions.clip&amp;sa=D&amp;ust=1575460960095000">F.clip</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.clamp&amp;sa=D&amp;ust=1575460960096000">torch.clamp</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.cos.html%23chainer.functions.cos&amp;sa=D&amp;ust=1575460960098000">F.cos</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.cos&amp;sa=D&amp;ust=1575460960098000">torch.cos</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.cosh.html%23chainer.functions.cosh&amp;sa=D&amp;ust=1575460960100000">F.cosh</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.cosh&amp;sa=D&amp;ust=1575460960101000">torch.cosh</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.cumprod.html%23chainer.functions.cumprod&amp;sa=D&amp;ust=1575460960102000">F.cumprod</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.cumprod&amp;sa=D&amp;ust=1575460960103000">torch.cumprod</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.cumsum.html%23chainer.functions.cumsum&amp;sa=D&amp;ust=1575460960104000">F.cumsum</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.cumsum&amp;sa=D&amp;ust=1575460960105000">torch.cumsum</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.det.html%23chainer.functions.det&amp;sa=D&amp;ust=1575460960107000">F.det</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.det&amp;sa=D&amp;ust=1575460960108000">torch.det</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.batch_det.html%23chainer.functions.batch_det&amp;sa=D&amp;ust=1575460960110000">F.batch_det</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.det&amp;sa=D&amp;ust=1575460960110000">torch.det</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Arbitrary number of batch axes are supported.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.digamma.html%23chainer.functions.digamma&amp;sa=D&amp;ust=1575460960112000">F.digamma</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.digamma&amp;sa=D&amp;ust=1575460960113000">torch.digamma</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.einsum.html%23chainer.functions.einsum&amp;sa=D&amp;ust=1575460960114000">F.einsum</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.einsum&amp;sa=D&amp;ust=1575460960115000">torch.einsum</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.erf.html%23chainer.functions.erf&amp;sa=D&amp;ust=1575460960117000">F.erf</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.erf&amp;sa=D&amp;ust=1575460960117000">torch.erf</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.erfc.html%23chainer.functions.erfc&amp;sa=D&amp;ust=1575460960119000">F.erfc</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.erfc&amp;sa=D&amp;ust=1575460960120000">torch.erfc</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.erfcinv.html%23chainer.functions.erfcinv&amp;sa=D&amp;ust=1575460960121000">F.erfcinv</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">Not available. Implement it similar to erf, erfinv? </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/pull/2799&amp;sa=D&amp;ust=1575460960122000">https://github.com/pytorch/pytorch/pull/2799</a></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.erfcx.html%23chainer.functions.erfcx&amp;sa=D&amp;ust=1575460960123000">F.erfcx</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.erfinv.html%23chainer.functions.erfinv&amp;sa=D&amp;ust=1575460960125000">F.erfinv</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.erfinv&amp;sa=D&amp;ust=1575460960126000">torch.erfinv</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.exp.html%23chainer.functions.exp&amp;sa=D&amp;ust=1575460960127000">F.exp</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.exp&amp;sa=D&amp;ust=1575460960128000">torch.exp</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.expm1.html%23chainer.functions.expm1&amp;sa=D&amp;ust=1575460960130000">F.expm1</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.expm1&amp;sa=D&amp;ust=1575460960130000">torch.expm1</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.fft.html%23chainer.functions.fft&amp;sa=D&amp;ust=1575460960132000">F.fft</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.fft&amp;sa=D&amp;ust=1575460960133000">torch.fft</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Interface is quite different.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.fix.html%23chainer.functions.fix&amp;sa=D&amp;ust=1575460960134000">F.fix</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.fmod.html%23chainer.functions.fmod&amp;sa=D&amp;ust=1575460960137000">F.fmod</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.fmod&amp;sa=D&amp;ust=1575460960138000">torch.fmod</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.floor.html%23chainer.functions.floor&amp;sa=D&amp;ust=1575460960140000">F.floor</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.floor&amp;sa=D&amp;ust=1575460960141000">torch.floor</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.identity.html%23chainer.functions.identity&amp;sa=D&amp;ust=1575460960142000">F.identity</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Identity&amp;sa=D&amp;ust=1575460960143000">nn.Identity</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.ifft.html%23chainer.functions.ifft&amp;sa=D&amp;ust=1575460960145000">F.ifft</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.ifft&amp;sa=D&amp;ust=1575460960146000">torch.ifft</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.inv.html%23chainer.functions.inv&amp;sa=D&amp;ust=1575460960147000">F.inv</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.inverse&amp;sa=D&amp;ust=1575460960148000">torch.inverse</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.lgamma.html%23chainer.functions.lgamma&amp;sa=D&amp;ust=1575460960150000">F.lgamma</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/cppdocs/api/function_namespaceat_1ae80021c749d42d0625e90973b18a00bc.html%23_CPPv4N2at6lgammaERK6Tensor&amp;sa=D&amp;ust=1575460960151000">torch.lgamma</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">Currently undocumented: </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/pull/27812&amp;sa=D&amp;ust=1575460960152000">https://github.com/pytorch/pytorch/pull/27812</a></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.linear_interpolate.html%23chainer.functions.linear_interpolate&amp;sa=D&amp;ust=1575460960153000">F.linear_interpolate</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Normal math should suffice.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.log.html%23chainer.functions.log&amp;sa=D&amp;ust=1575460960155000">F.log</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.log&amp;sa=D&amp;ust=1575460960156000">torch.log</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.log10.html%23chainer.functions.log10&amp;sa=D&amp;ust=1575460960157000">F.log10</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.log10&amp;sa=D&amp;ust=1575460960158000">torch.log10</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.log1p.html%23chainer.functions.log1p&amp;sa=D&amp;ust=1575460960160000">F.log1p</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.log1p&amp;sa=D&amp;ust=1575460960161000">torch.log1p</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.log2.html%23chainer.functions.log2&amp;sa=D&amp;ust=1575460960162000">F.log2</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.log2&amp;sa=D&amp;ust=1575460960163000">torch.log2</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.log_ndtr.html%23chainer.functions.log_ndtr&amp;sa=D&amp;ust=1575460960165000">F.log_ndtr</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.logsumexp.html%23chainer.functions.logsumexp&amp;sa=D&amp;ust=1575460960167000">F.logsumexp</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.logsumexp&amp;sa=D&amp;ust=1575460960167000">torch.logsumexp</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.matmul.html%23chainer.functions.matmul&amp;sa=D&amp;ust=1575460960169000">F.matmul</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.matmul&amp;sa=D&amp;ust=1575460960170000">torch.matmul</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.max.html%23chainer.functions.max&amp;sa=D&amp;ust=1575460960171000">F.max</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.max&amp;sa=D&amp;ust=1575460960172000">torch.max</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.maximum.html%23chainer.functions.maximum&amp;sa=D&amp;ust=1575460960174000">F.maximum</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.max&amp;sa=D&amp;ust=1575460960175000">torch.max</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.mean.html%23chainer.functions.mean&amp;sa=D&amp;ust=1575460960176000">F.mean</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.mean&amp;sa=D&amp;ust=1575460960177000">torch.mean</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Weighted average is not supported; rewrite as (without keepdims):</span></p><p class="c8"><span class="c3 c26"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.tensordot&amp;sa=D&amp;ust=1575460960178000">torch.tensordot</a></span><span class="c55 c26 c37">(x, weights / weights.sum(), ([axis], [0]))</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.min.html%23chainer.functions.min&amp;sa=D&amp;ust=1575460960179000">F.min</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.min&amp;sa=D&amp;ust=1575460960180000">torch.min</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.minimum.html%23chainer.functions.minimum&amp;sa=D&amp;ust=1575460960181000">F.minimum</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.min&amp;sa=D&amp;ust=1575460960182000">torch.min</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.ndtr.html%23chainer.functions.ndtr&amp;sa=D&amp;ust=1575460960184000">F.ndtr</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23gelu&amp;sa=D&amp;ust=1575460960185000">F.gelu</a></span><span class="c1">(x) is corresponding to x * F.ndtr(x).</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.ndtri.html%23chainer.functions.ndtri&amp;sa=D&amp;ust=1575460960186000">F.ndtri</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.prod.html%23chainer.functions.prod&amp;sa=D&amp;ust=1575460960188000">F.prod</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.prod&amp;sa=D&amp;ust=1575460960189000">torch.prod</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c95"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.polygamma.html%23chainer.functions.polygamma&amp;sa=D&amp;ust=1575460960190000">F.polygamma</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/cppdocs/api/function_namespaceat_1a98080f784a3c761958a42f273ac5cfd2.html&amp;sa=D&amp;ust=1575460960191000">torch.polygamma</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">Not documented: </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/issues/25347&amp;sa=D&amp;ust=1575460960192000">https://github.com/pytorch/pytorch/issues/25347</a></span></p><p class="c8"><span class="c37">n&gt;=2 not supported: </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/blob/1a92b225db8519ab4697954a5559674f58e91aa7/aten/src/ATen/native/cpu/UnaryOpsKernel.cpp%23L187&amp;sa=D&amp;ust=1575460960193000">https://github.com/pytorch/pytorch/blob/1a92b225db8519ab4697954a5559674f58e91aa7/aten/src/ATen/native/cpu/UnaryOpsKernel.cpp#L187</a></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.rsqrt.html%23chainer.functions.rsqrt&amp;sa=D&amp;ust=1575460960194000">F.rsqrt</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.rsqrt&amp;sa=D&amp;ust=1575460960195000">torch.rsqrt</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">-</span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.scale.html%23chainer.functions.scale&amp;sa=D&amp;ust=1575460960196000">F.scale</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Rewrite as:</span></p><p class="c8"><span class="c55 c26 c37">x * y[(...,) + (None,) * (x.ndim - y.ndim - 1)]</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.sin.html%23chainer.functions.sin&amp;sa=D&amp;ust=1575460960198000">F.sin</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.sin&amp;sa=D&amp;ust=1575460960199000">torch.sin</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.sinh.html%23chainer.functions.sinh&amp;sa=D&amp;ust=1575460960201000">F.sinh</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.sinh&amp;sa=D&amp;ust=1575460960202000">torch.sinh</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.sign.html%23chainer.functions.sign&amp;sa=D&amp;ust=1575460960204000">F.sign</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.sign&amp;sa=D&amp;ust=1575460960205000">torch.sign</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.sparse_matmul.html%23chainer.functions.sparse_matmul&amp;sa=D&amp;ust=1575460960206000">F.sparse_matmul</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/sparse.html%23torch.sparse.mm&amp;sa=D&amp;ust=1575460960207000">torch.sparse.mm</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Only support dense-sparse product. For sparse-dense product, transpose the operands and the output.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.sqrt.html%23chainer.functions.sqrt&amp;sa=D&amp;ust=1575460960209000">F.sqrt</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.sqrt&amp;sa=D&amp;ust=1575460960210000">torch.sqrt</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.square.html%23chainer.functions.square&amp;sa=D&amp;ust=1575460960211000">F.square</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Rewrite as:</span></p><p class="c8"><span class="c55 c26 c37">x * x</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.squared_difference.html%23chainer.functions.squared_difference&amp;sa=D&amp;ust=1575460960213000">F.squared_difference</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.sum.html%23chainer.functions.sum&amp;sa=D&amp;ust=1575460960215000">F.sum</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.sum&amp;sa=D&amp;ust=1575460960215000">torch.sum</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.sum_to.html%23chainer.functions.sum_to&amp;sa=D&amp;ust=1575460960217000">F.sum_to</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.tanh.html%23chainer.functions.tanh&amp;sa=D&amp;ust=1575460960219000">F.tanh</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.tanh&amp;sa=D&amp;ust=1575460960219000">torch.tanh</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.tan.html%23chainer.functions.tan&amp;sa=D&amp;ust=1575460960221000">F.tan</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.tan&amp;sa=D&amp;ust=1575460960222000">torch.tan</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.tensordot.html%23chainer.functions.tensordot&amp;sa=D&amp;ust=1575460960223000">F.tensordot</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.tensordot&amp;sa=D&amp;ust=1575460960224000">torch.tensordot</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c63" colspan="3" rowspan="1"><p class="c8"><span class="c25">Noise injections</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.dropout.html%23chainer.functions.dropout&amp;sa=D&amp;ust=1575460960228000">F.dropout</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23dropout&amp;sa=D&amp;ust=1575460960229000">F.dropout</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">No mask support, elements are randomly zeroed.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.gaussian.html%23chainer.functions.gaussian&amp;sa=D&amp;ust=1575460960230000">F.gaussian</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.distributions.normal.Normal&amp;sa=D&amp;ust=1575460960232000">torch.distributions.normal.Normal</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.gumbel_softmax.html%23chainer.functions.gumbel_softmax&amp;sa=D&amp;ust=1575460960234000">F.gumbel_softmax</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.gumbel_softmax&amp;sa=D&amp;ust=1575460960235000">F.gumbel_softmax</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">The default value of tau is 1, while the Chainer&#39;s function takes 0.1.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.simplified_dropconnect.html%23chainer.functions.simplified_dropconnect&amp;sa=D&amp;ust=1575460960237000">F.simplified_dropconnect</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Not available. Use F.dropout on the weight, or try torchnlp.nn.WeightDrop.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.zoneout.html%23chainer.functions.zoneout&amp;sa=D&amp;ust=1575460960239000">F.zoneout</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c63" colspan="3" rowspan="1"><p class="c8"><span class="c25">Normalization functions</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.batch_normalization.html%23chainer.functions.batch_normalization&amp;sa=D&amp;ust=1575460960243000">F.batch_normalization</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.batch_norm&amp;sa=D&amp;ust=1575460960245000">F.batch_norm</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.batch_renormalization.html%23chainer.functions.batch_renormalization&amp;sa=D&amp;ust=1575460960247000">F.batch_renormalization</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.decorrelated_batch_normalization.html%23chainer.functions.decorrelated_batch_normalization&amp;sa=D&amp;ust=1575460960249000">F.decorrelated_batch_normalization</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.fixed_batch_normalization.html%23chainer.functions.fixed_batch_normalization&amp;sa=D&amp;ust=1575460960252000">F.fixed_batch_normalization</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.batch_norm&amp;sa=D&amp;ust=1575460960253000">F.batch_norm</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">training=False?</span></p></td></tr><tr class="c70"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.fixed_batch_renormalization.html%23chainer.functions.fixed_batch_renormalization&amp;sa=D&amp;ust=1575460960254000">F.fixed_batch_renormalization</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">Batch Renormalization not implemented: </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/support-for-batch-renormalization/29653&amp;sa=D&amp;ust=1575460960256000">https://discuss.pytorch.org/t/support-for-batch-renormalization/2965</a></span><span class="c37">, </span><span class="c37">&nbsp;</span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/batch-renormalization-implementation-in-thcunn/5144&amp;sa=D&amp;ust=1575460960256000">https://discuss.pytorch.org/t/batch-renormalization-implementation-in-thcunn/5144</a></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.fixed_decorrelated_batch_normalization.html%23chainer.functions.fixed_decorrelated_batch_normalization&amp;sa=D&amp;ust=1575460960257000">F.fixed_decorrelated_batch_normalization</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.group_normalization.html%23chainer.functions.group_normalization&amp;sa=D&amp;ust=1575460960259000">F.group_normalization</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.group_norm&amp;sa=D&amp;ust=1575460960260000">F.group_norm</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Currently undocumented.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.layer_normalization.html%23chainer.functions.layer_normalization&amp;sa=D&amp;ust=1575460960262000">F.layer_normalization</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.layer_norm&amp;sa=D&amp;ust=1575460960262000">layer_norm</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">`gamma = weight` &amp; `beta= bias`</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.local_response_normalization.html%23chainer.functions.local_response_normalization&amp;sa=D&amp;ust=1575460960264000">F.local_response_normalization</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.local_response_norm&amp;sa=D&amp;ust=1575460960265000">F.local_response_norm</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.normalize.html%23chainer.functions.normalize&amp;sa=D&amp;ust=1575460960267000">F.normalize</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.normalize&amp;sa=D&amp;ust=1575460960267000">F.normalize</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">The PyTorch&#39;s `F.normalize` is not only for L2 normalization. But the default behavior is for L2 normalization, i.e., the default value of the second argument `p` is set to 2.</span></p></td></tr><tr class="c18"><td class="c63" colspan="3" rowspan="1"><p class="c8"><span class="c25">Spatial pooling</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.average_pooling_1d.html%23chainer.functions.average_pooling_1d&amp;sa=D&amp;ust=1575460960271000">F.average_pooling_1d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.avg_pool1d&amp;sa=D&amp;ust=1575460960272000">F.avg_pool1d</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.average_pooling_2d.html%23chainer.functions.average_pooling_2d&amp;sa=D&amp;ust=1575460960273000">F.average_pooling_2d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.avg_pool2d&amp;sa=D&amp;ust=1575460960274000">F.avg_pool2d</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Superset of Chainer&#39;s counterpart.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.average_pooling_3d.html%23chainer.functions.average_pooling_3d&amp;sa=D&amp;ust=1575460960276000">F.average_pooling_3d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.avg_pool3d&amp;sa=D&amp;ust=1575460960277000">F.avg_pool3d</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.average_pooling_nd.html%23chainer.functions.average_pooling_nd&amp;sa=D&amp;ust=1575460960279000">F.average_pooling_nd</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">N/A</span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.max_pooling_1d.html%23chainer.functions.max_pooling_1d&amp;sa=D&amp;ust=1575460960281000">F.max_pooling_1d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.max_pool1d&amp;sa=D&amp;ust=1575460960281000">F.max_pool1d</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">In addition to arguments documented in `nn.MaxPool1D`, `return_indices` argument is available to obtain index for unpooling.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.max_pooling_2d.html%23chainer.functions.max_pooling_2d&amp;sa=D&amp;ust=1575460960283000">F.max_pooling_2d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.max_pool2d&amp;sa=D&amp;ust=1575460960284000">F.max_pool2d</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">ditto.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.max_pooling_3d.html%23chainer.functions.max_pooling_3d&amp;sa=D&amp;ust=1575460960286000">F.max_pooling_3d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.max_pool3d&amp;sa=D&amp;ust=1575460960287000">F.max_pool3d</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">ditto.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.max_pooling_nd.html%23chainer.functions.max_pooling_nd&amp;sa=D&amp;ust=1575460960289000">F.max_pooling_nd</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">N/A</span></p></td></tr><tr class="c24"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.roi_average_align_2d.html%23chainer.functions.roi_average_align_2d&amp;sa=D&amp;ust=1575460960291000">F.roi_average_align_2d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torchvision/ops.html%23torchvision.ops.roi_align&amp;sa=D&amp;ust=1575460960292000">torchvision.ops.roi_align</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Requires Torchvision, torchvision has only 2 roi functions, roi_align uses the average of the pixels while roi_pool uses the max value</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.roi_average_pooling_2d.html%23chainer.functions.roi_average_pooling_2d&amp;sa=D&amp;ust=1575460960293000">F.roi_average_pooling_2d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.roi_max_align_2d.html%23chainer.functions.roi_max_align_2d&amp;sa=D&amp;ust=1575460960296000">F.roi_max_align_2d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">N/A</span></p></td></tr><tr class="c71"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.roi_max_pooling_2d.html%23chainer.functions.roi_max_pooling_2d&amp;sa=D&amp;ust=1575460960298000">F.roi_max_pooling_2d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torchvision.ops.roi_pool&amp;sa=D&amp;ust=1575460960299000">torchvision.ops.roi_pool</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">The `roi_pool` function of Torchvision is meant to be roi max pooling according to the source: </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/vision/blob/ccd1b27d2b7312ebddb4d51b3a4f8ade1ba8fa8b/torchvision/csrc/cpu/ROIPool_cpu.cpp%23L65&amp;sa=D&amp;ust=1575460960299000">https://github.com/pytorch/vision/blob/ccd1b27d2b7312ebddb4d51b3a4f8ade1ba8fa8b/torchvision/csrc/cpu/ROIPool_cpu.cpp#L65</a></span></p><p class="c8"><span class="c1">Regarding the API, the way to pass the batch indices of each set of RoI coordinates is different.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.roi_pooling_2d.html%23chainer.functions.roi_pooling_2d&amp;sa=D&amp;ust=1575460960301000">F.roi_pooling_2d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torchvision/ops.html%23torchvision.ops.roi_pool&amp;sa=D&amp;ust=1575460960302000">torchvision.ops.roi_pool</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Requires torchvision.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.spatial_pyramid_pooling_2d.html%23chainer.functions.spatial_pyramid_pooling_2d&amp;sa=D&amp;ust=1575460960303000">F.spatial_pyramid_pooling_2d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Not available. Not too difficult to implement? It&#39;s a combination of existing functions in Chainer.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.unpooling_1d.html%23chainer.functions.unpooling_1d&amp;sa=D&amp;ust=1575460960305000">F.unpooling_1d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.max_unpool1d&amp;sa=D&amp;ust=1575460960306000">F.max_unpool1d</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">Pass `indices` returned from F.max_pool1d.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.unpooling_2d.html%23chainer.functions.unpooling_2d&amp;sa=D&amp;ust=1575460960307000">F.unpooling_2d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.max_unpool2d&amp;sa=D&amp;ust=1575460960308000">F.max_unpool2d</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">ditto.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.unpooling_3d.html%23chainer.functions.unpooling_3d&amp;sa=D&amp;ust=1575460960310000">F.unpooling_3d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.max_unpool3d&amp;sa=D&amp;ust=1575460960311000">F.max_unpool3d</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">ditto.</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.unpooling_nd.html%23chainer.functions.unpooling_nd&amp;sa=D&amp;ust=1575460960312000">F.unpooling_nd</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.upsampling_2d.html%23chainer.functions.upsampling_2d&amp;sa=D&amp;ust=1575460960314000">F.upsampling_2d</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c63" colspan="3" rowspan="1"><p class="c8"><span class="c25">Utility functions</span></p></td></tr><tr class="c18"><td class="c19" colspan="1" rowspan="1"><p class="c8"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.forget.html%23chainer.functions.forget&amp;sa=D&amp;ust=1575460960318000">F.forget</a></span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c7"><span class="c1"></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c8"><span class="c37">See </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/checkpoint.html&amp;sa=D&amp;ust=1575460960319000">https://pytorch.org/docs/stable/checkpoint.html</a></span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><h3 class="c51 c33" id="h.ryz2089jygqa"><span class="c21">Links</span></h3><p class="c8"><span class="c26">L</span><span>&nbsp;refers to </span><span class="c26">chainer.links</span><span>&nbsp;(Chainer), and </span><span class="c26">nn</span><span>&nbsp;refers to </span><span class="c26">torch.nn</span><span class="c9">&nbsp;(PyTorch).</span></p><p class="c7"><span class="c9"></span></p><a id="t.3b37620fdb6ced6923d1d3cbb3cd34113c1d0cb4"></a><a id="t.18"></a><table class="c20"><tbody><tr class="c24"><td class="c83" colspan="1" rowspan="1"><p class="c84"><span class="c25">Chainer</span></p></td><td class="c106 c121" colspan="1" rowspan="1"><p class="c84"><span class="c25">PyTorch</span></p></td><td class="c106 c122" colspan="1" rowspan="1"><p class="c84"><span class="c25">Notes</span></p></td></tr><tr class="c18"><td class="c116" colspan="3" rowspan="1"><p class="c15"><span class="c55 c25 c80">Learnable connections</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Bias.html%23chainer.links.Bias&amp;sa=D&amp;ust=1575460960338000">L.Bias</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Bilinear.html%23chainer.links.Bilinear&amp;sa=D&amp;ust=1575460960340000">L.Bilinear</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Bilinear&amp;sa=D&amp;ust=1575460960340000">nn.Bilinear</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c24"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.ChildSumTreeLSTM.html%23chainer.links.ChildSumTreeLSTM&amp;sa=D&amp;ust=1575460960342000">L.ChildSumTreeLSTM</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c37">N/A. Reference user implementation at: </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/ttpro1995/TreeLSTMSentiment&amp;sa=D&amp;ust=1575460960343000">https://github.com/ttpro1995/TreeLSTMSentiment</a></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Convolution1D.html%23chainer.links.Convolution1D&amp;sa=D&amp;ust=1575460960344000">L.Convolution1D</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Conv1d&amp;sa=D&amp;ust=1575460960345000">nn.Conv1d</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Convolution2D.html%23chainer.links.Convolution2D&amp;sa=D&amp;ust=1575460960346000">L.Convolution2D</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Conv2d&amp;sa=D&amp;ust=1575460960347000">nn.Conv2d</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Convolution3D.html%23chainer.links.Convolution3D&amp;sa=D&amp;ust=1575460960349000">L.Convolution3D</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Conv3d&amp;sa=D&amp;ust=1575460960350000">nn.Conv3d</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.ConvolutionND.html%23chainer.links.ConvolutionND&amp;sa=D&amp;ust=1575460960352000">L.ConvolutionND</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Deconvolution1D.html%23chainer.links.Deconvolution1D&amp;sa=D&amp;ust=1575460960354000">L.Deconvolution1D</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.ConvTranspose1d&amp;sa=D&amp;ust=1575460960355000">nn.ConvTranspose1d</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Deconvolution2D.html%23chainer.links.Deconvolution2D&amp;sa=D&amp;ust=1575460960357000">L.Deconvolution2D</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.ConvTranspose2d&amp;sa=D&amp;ust=1575460960358000">nn.ConvTranspose2d</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Deconvolution3D.html%23chainer.links.Deconvolution3D&amp;sa=D&amp;ust=1575460960359000">L.Deconvolution3D</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.ConvTranspose3d&amp;sa=D&amp;ust=1575460960360000">nn.ConvTranspose3d</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.DeconvolutionND.html%23chainer.links.DeconvolutionND&amp;sa=D&amp;ust=1575460960362000">L.DeconvolutionND</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.DeformableConvolution2D.html%23chainer.links.DeformableConvolution2D&amp;sa=D&amp;ust=1575460960365000">L.DeformableConvolution2D</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c37">N/A: </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/issues/2260&amp;sa=D&amp;ust=1575460960366000">https://github.com/pytorch/pytorch/issues/2260</a></span></p></td></tr><tr class="c70"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.DepthwiseConvolution2D.html%23chainer.links.DepthwiseConvolution2D&amp;sa=D&amp;ust=1575460960368000">L.DepthwiseConvolution2D</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Conv2d&amp;sa=D&amp;ust=1575460960368000">nn.Conv2d</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c37">Use `groups` argument; see </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/depthwise-and-separable-convolutions-in-pytorch/7315/2&amp;sa=D&amp;ust=1575460960369000">https://discuss.pytorch.org/t/depthwise-and-separable-convolutions-in-pytorch/7315/2</a></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.DilatedConvolution2D.html%23chainer.links.DilatedConvolution2D&amp;sa=D&amp;ust=1575460960371000">L.DilatedConvolution2D</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Conv2d&amp;sa=D&amp;ust=1575460960372000">nn.Conv2d</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">Use `dilation` argument.</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.EmbedID.html%23chainer.links.EmbedID&amp;sa=D&amp;ust=1575460960373000">L.EmbedID</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Embedding&amp;sa=D&amp;ust=1575460960374000">nn.Embedding</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.GRU.html%23chainer.links.GRU&amp;sa=D&amp;ust=1575460960376000">L.GRU</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.GRU&amp;sa=D&amp;ust=1575460960377000">nn.GRU</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Highway.html%23chainer.links.Highway&amp;sa=D&amp;ust=1575460960379000">L.Highway</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">N/A</span></p></td></tr><tr class="c70"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Inception.html%23chainer.links.Inception&amp;sa=D&amp;ust=1575460960382000">L.Inception</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">`torchvision.models.inception.InceptionA` seems to be the corresponding module for Chainer&#39;s `L.Inception`, but is not documented.</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.InceptionBN.html%23chainer.links.InceptionBN&amp;sa=D&amp;ust=1575460960385000">L.InceptionBN</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">See torchvision.models.inception for Inception v3</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Linear.html%23chainer.links.Linear&amp;sa=D&amp;ust=1575460960387000">L.Linear</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Linear&amp;sa=D&amp;ust=1575460960388000">nn.Linear</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.LocalConvolution2D.html%23chainer.links.LocalConvolution2D&amp;sa=D&amp;ust=1575460960390000">L.LocalConvolution2D</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.LSTM.html%23chainer.links.LSTM&amp;sa=D&amp;ust=1575460960391000">L.LSTM</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.LSTM&amp;sa=D&amp;ust=1575460960392000">nn.LSTM</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.MLPConvolution2D.html%23chainer.links.MLPConvolution2D&amp;sa=D&amp;ust=1575460960393000">L.MLPConvolution2D</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.NaryTreeLSTM.html%23chainer.links.NaryTreeLSTM&amp;sa=D&amp;ust=1575460960396000">L.NaryTreeLSTM</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.NStepBiGRU.html%23chainer.links.NStepBiGRU&amp;sa=D&amp;ust=1575460960398000">L.NStepBiGRU</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.GRU&amp;sa=D&amp;ust=1575460960399000">nn.GRU</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">bidirectional=True, no explicit activation, no stacking</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.NStepBiLSTM.html%23chainer.links.NStepBiLSTM&amp;sa=D&amp;ust=1575460960400000">L.NStepBiLSTM</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.LSTM&amp;sa=D&amp;ust=1575460960401000">nn.LSTM</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">bidirectional=True, no explicit activation, no stacking</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.NStepBiRNNReLU.html%23chainer.links.NStepBiRNNReLU&amp;sa=D&amp;ust=1575460960403000">L.NStepBiRNNReLU</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.RNN&amp;sa=D&amp;ust=1575460960404000">nn.RNN</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">bidirectional=True, no explicit activation, no stacking</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.NStepBiRNNTanh.html%23chainer.links.NStepBiRNNTanh&amp;sa=D&amp;ust=1575460960406000">L.NStepBiRNNTanh</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.RNN&amp;sa=D&amp;ust=1575460960407000">nn.RNN</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">bidirectional=True, no explicit activation, no stacking</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.NStepGRU.html%23chainer.links.NStepGRU&amp;sa=D&amp;ust=1575460960409000">L.NStepGRU</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.torch.nn.GRU&amp;sa=D&amp;ust=1575460960410000">nn.GRU</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.NStepLSTM.html%23chainer.links.NStepLSTM&amp;sa=D&amp;ust=1575460960412000">L.NStepLSTM</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.LSTM&amp;sa=D&amp;ust=1575460960413000">nn.LSTM</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.NStepRNNReLU.html%23chainer.links.NStepRNNReLU&amp;sa=D&amp;ust=1575460960414000">L.NStepRNNReLU</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.RNN&amp;sa=D&amp;ust=1575460960415000">nn.RNN</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.NStepRNNTanh.html%23chainer.links.NStepRNNTanh&amp;sa=D&amp;ust=1575460960417000">L.NStepRNNTanh</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.RNN&amp;sa=D&amp;ust=1575460960419000">nn.RNN</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Parameter.html%23chainer.links.Parameter&amp;sa=D&amp;ust=1575460960420000">L.Parameter</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">You could use torch.nn.modules.ParameterList with 1 element</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Scale.html%23chainer.links.Scale&amp;sa=D&amp;ust=1575460960422000">L.Scale</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.StatefulGRU.html%23chainer.links.StatefulGRU&amp;sa=D&amp;ust=1575460960425000">L.StatefulGRU</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.GRU&amp;sa=D&amp;ust=1575460960426000">nn.GRU</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.StatelessGRU.html%23chainer.links.StatelessGRU&amp;sa=D&amp;ust=1575460960427000">L.StatelessGRU</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.StatefulMGU.html%23chainer.links.StatefulMGU&amp;sa=D&amp;ust=1575460960430000">L.StatefulMGU</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c37">See </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/jpeg729/pytorch_bits&amp;sa=D&amp;ust=1575460960431000">https://github.com/jpeg729/pytorch_bits</a></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.StatelessMGU.html%23chainer.links.StatelessMGU&amp;sa=D&amp;ust=1575460960432000">L.StatelessMGU</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.StatefulPeepholeLSTM.html%23chainer.links.StatefulPeepholeLSTM&amp;sa=D&amp;ust=1575460960434000">L.StatefulPeepholeLSTM</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c37">See </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/issues/630&amp;sa=D&amp;ust=1575460960436000">https://github.com/pytorch/pytorch/issues/630</a></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.StatefulZoneoutLSTM.html%23chainer.links.StatefulZoneoutLSTM&amp;sa=D&amp;ust=1575460960437000">L.StatefulZoneoutLSTM</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c37">N/A: </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/pull/4838&amp;sa=D&amp;ust=1575460960439000">https://github.com/pytorch/pytorch/pull/4838</a></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.StatelessLSTM.html%23chainer.links.StatelessLSTM&amp;sa=D&amp;ust=1575460960440000">L.StatelessLSTM</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c24"><td class="c66" colspan="3" rowspan="1"><p class="c15"><span class="c55 c25 c80">Activation/loss/normalization functions with parameters</span></p></td></tr><tr class="c95"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.BatchNormalization.html%23chainer.links.BatchNormalization&amp;sa=D&amp;ust=1575460960444000">L.BatchNormalization</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3 c58"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23batchnorm1d&amp;sa=D&amp;ust=1575460960445000">nn.BatchNorm1d</a></span></p><p class="c15"><span class="c3 c58"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23batchnorm1d&amp;sa=D&amp;ust=1575460960446000">nn.BatchNorm2d</a></span></p><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23batchnorm1d&amp;sa=D&amp;ust=1575460960446000">nn.BatchNorm3d</a></span></p></td><td class="c105" colspan="1" rowspan="1"><p class="c15"><span class="c1">The argument `momentum` in the PyTorch implementation seems to be equivalent to `1 - decay` in the Chainer&#39;s link.</span></p><p class="c15"><span class="c1">The default value for the argument `eps` (1e-5) is different from Chainer&#39;s default value (2e-5).</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.BatchRenormalization.html%23chainer.links.BatchRenormalization&amp;sa=D&amp;ust=1575460960448000">L.BatchRenormalization</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">N/A</span></p></td></tr><tr class="c71"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.DecorrelatedBatchNormalization.html%23chainer.links.DecorrelatedBatchNormalization&amp;sa=D&amp;ust=1575460960451000">L.DecorrelatedBatchNormalization</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c37">Not available. A reference implementation (not that well implemented?) </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/huangleiBuaa/IterNorm-pytorch/blob/master/extension/normailzation/dbn.py&amp;sa=D&amp;ust=1575460960452000">https://github.com/huangleiBuaa/IterNorm-pytorch/blob/master/extension/normailzation/dbn.py</a></span><span class="c37">. Otherwise look at the Torch lua official implementation </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/princeton-vl/DecorrelatedBN&amp;sa=D&amp;ust=1575460960453000">https://github.com/princeton-vl/DecorrelatedBN</a></span><span class="c1">.</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.GroupNormalization.html%23chainer.links.GroupNormalization&amp;sa=D&amp;ust=1575460960454000">L.GroupNormalization</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.GroupNorm&amp;sa=D&amp;ust=1575460960455000">nn.GroupNorm</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">affine=True</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.LayerNormalization.html%23chainer.links.LayerNormalization&amp;sa=D&amp;ust=1575460960456000">L.LayerNormalization</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.LayerNorm&amp;sa=D&amp;ust=1575460960457000">nn.LayerNorm</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">elementwise_affine=True</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.BinaryHierarchicalSoftmax.html%23chainer.links.BinaryHierarchicalSoftmax&amp;sa=D&amp;ust=1575460960459000">L.BinaryHierarchicalSoftmax</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.BlackOut.html%23chainer.links.BlackOut&amp;sa=D&amp;ust=1575460960461000">L.BlackOut</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.CRF1d.html%23chainer.links.CRF1d&amp;sa=D&amp;ust=1575460960462000">L.CRF1d</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.SimplifiedDropconnect.html%23chainer.links.SimplifiedDropconnect&amp;sa=D&amp;ust=1575460960465000">L.SimplifiedDropconnect</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.PReLU.html%23chainer.links.PReLU&amp;sa=D&amp;ust=1575460960467000">L.PReLU</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.PReLU&amp;sa=D&amp;ust=1575460960468000">nn.PReLU</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Swish.html%23chainer.links.Swish&amp;sa=D&amp;ust=1575460960469000">L.Swish</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c37">See </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://blog.ceshine.net/post/pytorch-memory-swish/&amp;sa=D&amp;ust=1575460960470000">https://blog.ceshine.net/post/pytorch-memory-swish/</a></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Maxout.html%23chainer.links.Maxout&amp;sa=D&amp;ust=1575460960471000">L.Maxout</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.NegativeSampling.html%23chainer.links.NegativeSampling&amp;sa=D&amp;ust=1575460960473000">L.NegativeSampling</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c66" colspan="3" rowspan="1"><p class="c15"><span class="c55 c25 c80">Machine learning models</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Classifier.html%23chainer.links.Classifier&amp;sa=D&amp;ust=1575460960477000">L.Classifier</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c66" colspan="3" rowspan="1"><p class="c15"><span class="c55 c25 c80">Pre-trained models</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.VGG16Layers.html%23chainer.links.VGG16Layers&amp;sa=D&amp;ust=1575460960482000">L.VGG16Layers</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torchvision/models.html%23id2&amp;sa=D&amp;ust=1575460960483000">torchvision.models.vgg*</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">Superset of Chainer&#39;s VGG variations in torchvision.</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.VGG19Layers.html%23chainer.links.VGG19Layers&amp;sa=D&amp;ust=1575460960484000">L.VGG19Layers</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torchvision/models.html%23torchvision.models.vgg19&amp;sa=D&amp;ust=1575460960485000">torchvision.models.vgg19*</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">ditto</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.model.vision.vgg.prepare.html%23chainer.links.model.vision.vgg.prepare&amp;sa=D&amp;ust=1575460960487000">L.model.vision.vgg.prepare</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.GoogLeNet.html%23chainer.links.GoogLeNet&amp;sa=D&amp;ust=1575460960489000">L.GoogLeNet</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torchvision/models.html%23torchvision.models.googlenet&amp;sa=D&amp;ust=1575460960490000">torchvision.models.googlenet</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.model.vision.googlenet.prepare.html%23chainer.links.model.vision.googlenet.prepare&amp;sa=D&amp;ust=1575460960492000">L.model.vision.googlenet.prepare</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">transform_input=True in torchvision.models.googlenet</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.model.vision.resnet.ResNetLayers.html%23chainer.links.model.vision.resnet.ResNetLayers&amp;sa=D&amp;ust=1575460960494000">L.model.vision.resnet.ResNetLayers</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.ResNet50Layers.html%23chainer.links.ResNet50Layers&amp;sa=D&amp;ust=1575460960496000">L.ResNet50Layers</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torchvision/models.html%23torchvision.models.resnet50&amp;sa=D&amp;ust=1575460960497000">torchvision.models.resnet101</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">torchvision only, pretrained=True</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.ResNet101Layers.html%23chainer.links.ResNet101Layers&amp;sa=D&amp;ust=1575460960499000">L.ResNet101Layers</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torchvision/models.html%23torchvision.models.resnet101&amp;sa=D&amp;ust=1575460960500000">torchvision.models.resnet101</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">torchvision only, pretrained=True</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.ResNet152Layers.html%23chainer.links.ResNet152Layers&amp;sa=D&amp;ust=1575460960502000">L.ResNet152Layers</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torchvision/models.html%23torchvision.models.resnet152&amp;sa=D&amp;ust=1575460960503000">torchvision.models.resnet152</a></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">torchvision only, pretrained=True</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.model.vision.resnet.prepare.html%23chainer.links.model.vision.resnet.prepare&amp;sa=D&amp;ust=1575460960504000">L.model.vision.resnet.prepare</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">N/A</span></p></td></tr><tr class="c18"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.TheanoFunction.html%23chainer.links.TheanoFunction&amp;sa=D&amp;ust=1575460960507000">L.TheanoFunction</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c1">N/A</span></p></td></tr><tr class="c24"><td class="c29" colspan="1" rowspan="1"><p class="c15"><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.caffe.CaffeFunction.html%23chainer.links.caffe.CaffeFunction&amp;sa=D&amp;ust=1575460960509000">L.caffe.CaffeFunction</a></span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c12"><span class="c1"></span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c15"><span class="c37">See </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/marvis/pytorch-caffe&amp;sa=D&amp;ust=1575460960510000">https://github.com/marvis/pytorch-caffe</a></span><span class="c37">&nbsp;or </span><span class="c3"><a class="c4" href="https://www.google.com/url?q=https://github.com/Microsoft/MMdnn&amp;sa=D&amp;ust=1575460960511000">https://github.com/Microsoft/MMdnn</a></span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><h2 class="c35 c33" id="h.hb9kqa7i3enr"><span class="c77 c67 c36">Configuration</span></h2><p class="c8"><span>Here is the mapping of configurations in Chainer (</span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/configuration.html&amp;sa=D&amp;ust=1575460960516000">chainer.config.*</a></span><span class="c9">) and PyTorch:</span></p><p class="c7"><span class="c9"></span></p><a id="t.f3301a8a5c40dafd6342027539056b8cf48e653c"></a><a id="t.19"></a><table class="c126"><tbody><tr class="c10"><td class="c41" colspan="1" rowspan="1"><p class="c46"><span class="c14">Chainer</span></p></td><td class="c104" colspan="1" rowspan="1"><p class="c46"><span class="c14">PyTorch</span></p></td><td class="c93" colspan="1" rowspan="1"><p class="c46"><span class="c14">Notes</span></p></td></tr><tr class="c10"><td class="c59" colspan="1" rowspan="1"><p class="c11"><span class="c55 c26 c81">autotune</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c11"><span class="c55 c26 c81">torch.backends.cudnn.benchmark</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c11"><span class="c9">Not thread-local.</span></p></td></tr><tr class="c10"><td class="c59" colspan="1" rowspan="1"><p class="c11"><span class="c55 c26 c81">cudnn_deterministic</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c11"><span class="c55 c26 c81">torch.backends.cudnn.deterministic</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c11"><span class="c9">Not thread-local.</span></p></td></tr><tr class="c10"><td class="c59" colspan="1" rowspan="1"><p class="c11"><span class="c55 c26 c81">cudnn_fast_batch_normalization</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c11"><span class="c9">N/A</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c11"><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/blob/v1.2.0/aten/src/ATen/native/cudnn/BatchNorm.cpp%23L90-L94&amp;sa=D&amp;ust=1575460960524000">Intentionally unsupported</a></span><span class="c9">&nbsp;as the precision is low in some models.</span></p></td></tr><tr class="c10"><td class="c59" colspan="1" rowspan="1"><p class="c11"><span class="c55 c26 c81">debug</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c11"><span class="c9">N/A</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c11"><span>Use </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/autograd.html%23torch.autograd.detect_anomaly&amp;sa=D&amp;ust=1575460960526000">torch.autograd.detect_anomaly()</a></span><span class="c9">&nbsp;context-manager to check NaN during backward, display the corresponding forward stack trace when error occurred in backward.</span></p></td></tr><tr class="c10"><td class="c59" colspan="1" rowspan="1"><p class="c11"><span class="c55 c26 c81">dtype</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c11"><span class="c31 c26"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.set_default_dtype&amp;sa=D&amp;ust=1575460960528000">torch.set_default_dtype(dtype)</a></span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c11"><span class="c9">Mixed precision support is done via Apex. Not thread-local.</span></p></td></tr><tr class="c10"><td class="c59" colspan="1" rowspan="1"><p class="c11"><span class="c55 c26 c81">enable_backprop</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c11"><span class="c55 c26 c81">torch.no_grad()</span></p><p class="c11"><span class="c55 c26 c81">torch.enable_grad()</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c11"><span>You can use them as context-manager or decorator. See also </span><span class="c31"><a class="c4" href="#h.mc69ie7hbl6j">Backprop modes</a></span><span class="c9">.</span></p></td></tr><tr class="c10"><td class="c59" colspan="1" rowspan="1"><p class="c11"><span class="c55 c26 c81">is_recomputing</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c11"><span class="c9">N/A</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c11"><span>See </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/checkpoint.html&amp;sa=D&amp;ust=1575460960532000">torch.utils.checkpoint.checkpoint</a></span><span class="c9">&nbsp;for F.forget equivalent (it also supports RNG).</span></p></td></tr><tr class="c10"><td class="c59" colspan="1" rowspan="1"><p class="c11"><span class="c55 c26 c81">keep_graph_on_report</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c11"><span class="c9">N/A</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c11 c50"><span class="c9"></span></p></td></tr><tr class="c10"><td class="c59" colspan="1" rowspan="1"><p class="c11"><span class="c55 c26 c81">lazy_grad_sum</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c11"><span class="c9">N/A</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c11 c50"><span class="c9"></span></p></td></tr><tr class="c10"><td class="c59" colspan="1" rowspan="1"><p class="c11"><span class="c55 c26 c81">train</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c11"><span class="c9">N/A</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c11"><span>The mode is configured per Module (using Module.train() and Module.eval()). See also </span><span class="c31"><a class="c4" href="#h.bka3yqtw2rpy">Train/Test modes</a></span><span class="c9">.</span></p></td></tr><tr class="c10"><td class="c59" colspan="1" rowspan="1"><p class="c11"><span class="c55 c26 c81">type_check</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c11"><span class="c9">N/A</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c11 c50"><span class="c9"></span></p></td></tr><tr class="c10"><td class="c59" colspan="1" rowspan="1"><p class="c11"><span class="c55 c26 c81">use_cudnn</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c11"><span class="c55 c26 c81">torch.backends.cudnn.enabled</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c11"><span class="c9">Enabled by default. Not thread-local.</span></p></td></tr><tr class="c10"><td class="c59" colspan="1" rowspan="1"><p class="c11"><span class="c55 c26 c81">use_cudnn_tensor_core</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c11"><span class="c9">N/A</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c11"><span class="c9">Tensor Cores cannot be disabled.</span></p></td></tr><tr class="c10"><td class="c59" colspan="1" rowspan="1"><p class="c11"><span class="c55 c26 c81">use_ideep</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c11"><span class="c9">N/A</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c11"><span class="c9">PyTorch itself supports MKL-DNN. You can check availability using torch.backends.mkldnn.is_available().</span></p></td></tr><tr class="c107"><td class="c59" colspan="1" rowspan="1"><p class="c11"><span class="c55 c26 c81">use_static_graph</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c11"><span class="c9">N/A</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c11 c50"><span class="c9"></span></p></td></tr><tr class="c10"><td class="c59" colspan="1" rowspan="1"><p class="c11"><span class="c55 c26 c81">warn_nondeterministic</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c11"><span class="c9">N/A</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c11 c50"><span class="c9"></span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><p class="c8"><span>See </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/notes/randomness.html&amp;sa=D&amp;ust=1575460960546000">Reproducibility</a></span><span>&nbsp;for the reproducibility (including steps to fix seeds).</span></p><h2 class="c35 c33" id="h.rxt9pteccajv"><span class="c77 c67 c36">Hooks</span></h2><h3 class="c51 c33" id="h.gsgtoxixjcm4"><span class="c21">Function Hooks</span></h3><p class="c8"><span class="c9">There is no equivalent feature in PyTorch.</span></p><p class="c8"><span class="c9">Replacements for Chainer built-in hooks:</span></p><ul class="c30 lst-kix_owgllipbp8j5-0 start"><li class="c8 c43"><span>CUDAProfileHook: </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/master/autograd.html%23torch.autograd.profiler.profile&amp;sa=D&amp;ust=1575460960548000">torch.autograd.profiler.profile</a></span><span>&nbsp;+ </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/master/autograd.html%23torch.autograd.profiler.emit_nvtx&amp;sa=D&amp;ust=1575460960548000">torch.autograd.profiler.emit_nvtx</a></span></li><li class="c8 c43"><span>CupyMemoryProfileHook: N/A (</span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/notes/cuda.html%23memory-management&amp;sa=D&amp;ust=1575460960549000">allocator status can be retrieved</a></span><span class="c9">)</span></li><li class="c8 c43"><span class="c9">PrintHook: N/A</span></li><li class="c8 c43"><span>TimerHook: </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/master/autograd.html%23torch.autograd.profiler.profile&amp;sa=D&amp;ust=1575460960550000">torch.autograd.profiler.profile</a></span></li></ul><h3 class="c51 c33" id="h.rvlhszhkp1bw"><span class="c21">Link Hooks</span></h3><p class="c8"><span>You can register a </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/tutorials/beginner/former_torchies/nnft_tutorial.html%23forward-and-backward-function-hooks&amp;sa=D&amp;ust=1575460960551000">Module Hooks</a></span><span class="c9">&nbsp;per module. There&#39;s no way to inject a hook for every link called under the specific scope.</span></p><p class="c8"><span class="c9">Replacements for Chainer built-in hooks:</span></p><ul class="c30 lst-kix_9reixuath9e3-0 start"><li class="c8 c43"><span>SpectralNormalization: </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.utils.spectral_norm&amp;sa=D&amp;ust=1575460960552000">torch.nn.utils.spectral_norm</a></span><span>&nbsp;/ </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.utils.remove_spectral_norm&amp;sa=D&amp;ust=1575460960552000">torch.nn.utils.remove_spectral_norm</a></span></li><li class="c8 c43"><span class="c9">TimerHook: N/A</span></li></ul><h3 class="c51 c33" id="h.5a204an0cllk"><span class="c21">Optimizer Hooks</span></h3><p class="c8"><span class="c9">There is no equivalent feature in PyTorch.</span></p><p class="c8"><span class="c9">Replacements for Chainer built-in hooks:</span></p><ul class="c30 lst-kix_jbicnccaji3d-0 start"><li class="c8 c43"><span>WeightDecay: specify as </span><span class="c26">weight_decay</span><span>&nbsp;argument to each Optimizer (e.g., </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/optim.html%23torch.optim.Adam&amp;sa=D&amp;ust=1575460960554000">Adam</a></span><span class="c9">)</span></li><li class="c8 c43"><span class="c9">Lasso: N/A</span></li><li class="c8 c43"><span>GradientClipping: </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.utils.clip_grad_norm_&amp;sa=D&amp;ust=1575460960555000">torch.nn.utils.clip_grad_norm_</a></span></li><li class="c8 c43"><span>GradientHardClipping: </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.utils.clip_grad_value_&amp;sa=D&amp;ust=1575460960556000">torch.nn.utils.clip_grad_value_</a></span></li><li class="c8 c43"><span class="c9">GradientNoise: N/A</span></li><li class="c8 c43"><span>GradientLARS: N/A (see </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/issues/18414&amp;sa=D&amp;ust=1575460960556000">pytorch #18414</a></span><span>&nbsp;and </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://github.com/noahgolmant/pytorch-lars&amp;sa=D&amp;ust=1575460960557000">pytorch-lars</a></span><span>)</span></li></ul><h2 class="c35 c33" id="h.79n4spowwnun"><span class="c77 c67 c36">Training PyTorch model using Chainer</span></h2><p class="c8"><span>To quickly try a PyTorch model in a training script using Chainer, </span><span class="c31 c40"><a class="c4" href="#h.jgakn54a8peo">cpm.TorchModule</a></span><span class="c9">&nbsp;is the tool to use. Assuming you have a training script using Chainer, you have to try the following steps:</span></p><p class="c7"><span class="c9"></span></p><ul class="c30 lst-kix_38adif7m6rbx-0 start"><li class="c8 c43"><span>Replace the model to train with </span><span class="c40">cpm.TorchModule(module_you_want_to_use)</span><span>. Use </span><span class="c40">to_gpu</span><span class="c9">&nbsp;to transfer the variables to a GPU device.</span></li><li class="c8 c43"><span class="c9">Rewrite the loss computation and backprop call with PyTorch.</span></li></ul><ul class="c30 lst-kix_38adif7m6rbx-1 start"><li class="c8 c76"><span>If you are using StandardUpdater, make its subclass and override </span><span class="c40">update_core</span><span class="c9">. Write loss calculation and backprop call in PyTorch.</span></li></ul><ul class="c30 lst-kix_38adif7m6rbx-2 start"><li class="c8 c45"><span class="c119">NOTE</span><span>: Once you compute the gradient in PyTorch, it is automatically reflected to Chainer parameters, so it is valid to just call </span><span class="c40">optimizer.update()</span><span class="c9">&nbsp;after that.</span></li></ul><ul class="c30 lst-kix_38adif7m6rbx-1"><li class="c8 c76"><span>If you are using a custom training loop, rewrite the gradient computation part in PyTorch. See the above NOTE, too.</span></li></ul><h2 class="c35 c33" id="h.33jrfcvcf9zh"><span class="c77 c67 c36">Distributed training </span></h2><p class="c8"><span>As of writing, there are two major ways to run distributed deep learning applications:</span><span class="c40">&nbsp;torch.distributed</span><span>&nbsp;and Horovod. We recommend</span><span class="c40">&nbsp;torch.distributed</span><span class="c9">&nbsp;as a first option because of the following reasons.</span></p><p class="c7"><span class="c9"></span></p><ol class="c30 lst-kix_8dw3ycrgt362-0 start" start="1"><li class="c8 c43"><span class="c40">torch.distributed</span><span class="c9">&nbsp;is a part standard modules of PyTorch.</span></li><li class="c8 c43"><span class="c9">It supports some advanced features that Horovod doesn&rsquo;t, such as multi-node batch normalization (e.g. inter-process batch normalization)</span></li></ol><p class="c7"><span class="c9"></span></p><p class="c8"><span class="c9">In this document, we describe both approaches to migrate ChainerMN programs to PyTorch.</span></p><h3 class="c33 c48" id="h.91x1ehh487en"><span class="c21"></span></h3><h3 class="c51 c33" id="h.iyhfmfndl13j"><span class="c21">Pytorch model using torch.distributed&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></h3><p class="c8"><span class="c9">Torch.distributed is the standard module for distributed deep learning of PyTorch. </span></p><p class="c7"><span class="c9"></span></p><p class="c8"><span class="c9">Torch.distributed supports three backends: &ldquo;nccl&rdquo;, &ldquo;mpi&rdquo; and &ldquo;gloo&rdquo;. For users who are migrating from Chainer and ChainerMN and have been using NCCL with MPI, using &ldquo;nccl&rdquo; backend is the most straightforward way. In this section, we assume that you use NCCL and MPI to run your distributed deep learning programs. In particular we assume Open MPI as the MPI implementation used here because it is the recommended option in ChainerMN, but other MPI implementations are mentioned as well.</span></p><h4 class="c51 c33" id="h.moliknyk6ru3"><span class="c34">Invocation</span></h4><p class="c8"><span>In ChainerMN, process invocation is totally coordinated by the MPI runtime. However, in PyTorch and torch.distributed, you may need a few more steps to invoke distributed deep learning processes. The simplest initialization method might be </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/distributed.html%23environment-variable-initialization&amp;sa=D&amp;ust=1575460960563000">environment variable initialization</a></span><span class="c9">. </span></p><p class="c7"><span class="c9"></span></p><p class="c8"><span>The following environmental variables are necessary (whatever system you use to invoke your script, including MPI). Other variables, </span><span class="c40">WORLD_SIZE</span><span>&nbsp;and</span><span class="c40">&nbsp;RANK,</span><span class="c9">&nbsp;are set from inside the following snippet.</span></p><p class="c7"><span class="c9"></span></p><p class="c8"><span class="c40">MASTER_ADDR : </span><span class="c9">Address of the computing node where the rank 0 process runs.</span></p><p class="c8"><span class="c40">MASTER_PORT : </span><span class="c9">A free port of the MASTER_ADDR machine. The port will be used by &nbsp;the rank 0 process.</span></p><p class="c7"><span class="c9"></span></p><p class="c7"><span class="c9"></span></p><p class="c8"><span>Note that process invocation is highly system-dependent issue. PyTorch supports other options such as </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/distributed.html%23tcp-initialization&amp;sa=D&amp;ust=1575460960566000">TCP initialization</a></span><span>&nbsp;and </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/distributed.html%23shared-file-system-initialization&amp;sa=D&amp;ust=1575460960566000">shared file-system initialization</a></span><span class="c9">. Please refer to the official documents for more details.</span></p><p class="c7"><span class="c9"></span></p><h4 class="c51 c33" id="h.7r5y5xoqrywb"><span class="c34">Initialization</span></h4><p class="c8"><span class="c9">The following code snippets shows how to initialize torch.distributed module.</span></p><p class="c7"><span class="c2"></span></p><a id="t.bca77ae00997d02300bdcc0347eb376ffd57872b"></a><a id="t.20"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c8"><span class="c2"># setup env for torch.distributed</span></p><p class="c8"><span class="c2">comm_world_size = int(os.environ[&quot;OMPI_COMM_WORLD_SIZE&quot;])</span></p><p class="c8"><span class="c2">comm_rank = int(os.environ[&quot;OMPI_COMM_WORLD_RANK&quot;])</span></p><p class="c8"><span class="c2">comm_local_rank = int(os.environ[&#39;OMPI_COMM_WORLD_LOCAL_RANK&#39;])</span></p><p class="c7"><span class="c2"></span></p><p class="c8"><span class="c2">os.environ[&quot;WORLD_SIZE&quot;] = str(comm_world_size)</span></p><p class="c8"><span class="c2">os.environ[&quot;RANK&quot;] = str(comm_rank)</span></p><p class="c8"><span class="c2">torch.cuda.set_device(comm_local_rank)</span></p><p class="c8"><span class="c2">torch.distributed.init_process_group(backend=&#39;nccl&#39;, init_method=&#39;env://&#39;)</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><p class="c8"><span class="c9">Environmental variables set by MPI runtime are here, instead of communicator.intra_rank in ChainerMN because torch.distributed does not provide corresponding rank information. If you use MVAPICH2, use MV2_COMM_WORLD_SIZE, MV2_COMM_WORLD_RANK, MV2_COMM_WORLD_LOCAL_RANK respectively. </span></p><p class="c7"><span class="c9"></span></p><h4 class="c51 c33" id="h.nzh1eoy3bny9"><span class="c34">Dataset scattering</span></h4><p class="c8"><span>Each node can get a slice of a globally shared dataset using a </span><span class="c40">DistributedSampler</span><span>.</span></p><a id="t.78413d634350882eaf636e0fb611364974f5000c"></a><a id="t.21"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c44"><span class="c22">sampler = torch.utils.data.distributed.DistributedSampler(dataset, </span></p><p class="c44"><span class="c22">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; num_replicas=comm_world_size,</span></p><p class="c44"><span class="c22">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; rank=comm_rank)</span></p><p class="c44 c50"><span class="c22"></span></p><p class="c44"><span class="c22">loader_kwargs = {&#39;num_workers&#39;: 1, &#39;pin_memory&#39;: True} &nbsp;# Assuming we use GPUs</span></p><p class="c44"><span class="c22">loader = = torch.utils.data.DataLoader(train_dataset,</span></p><p class="c44"><span class="c22">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;batch_size=args.batch_size, </span></p><p class="c44"><span class="c22">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;sampler=sampler, **loader_kwargs)</span></p></td></tr></tbody></table><p class="c44 c50"><span class="c9"></span></p><p class="c8"><span>This will make every worker to only load a slice of the dataset, this sampler can be normally fed to the </span><span class="c40">DataLoader</span><span class="c9">.</span></p><p class="c7"><span class="c9"></span></p><p class="c8"><span>Also, you need to call</span><span class="c40">&nbsp;DistributedSampler.set_epoch()</span><span class="c9">&nbsp;to adjust epoch numbers. &nbsp;Thus typical training loop looks like:</span></p><p class="c7"><span class="c22"></span></p><a id="t.bbd36d8e629516ffbb814279727dc47778519869"></a><a id="t.22"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c44"><span class="c22">for epoch in range(1, args.epochs + 1):</span></p><p class="c44"><span class="c22">&nbsp; &nbsp; train_sampler.set_epoch(epoch)</span></p><p class="c44"><span class="c22">&nbsp; &nbsp; train(args, model, device, train_loader, optimizer, epoch)</span></p><p class="c44"><span class="c22">&nbsp; &nbsp; test(args, model, device, test_loader, len(test_dataset))</span></p><p class="c44"><span class="c22">&nbsp; &nbsp; scheduler.step()</span></p></td></tr></tbody></table><p class="c44 c50"><span class="c9"></span></p><p class="c7"><span class="c2"></span></p><h4 class="c51 c33" id="h.kyzvorr2x2ij"><span class="c34">Data transfer to devices</span></h4><p class="c8"><span>We need to specify the device to which the data is transferred using</span><span class="c40">&nbsp;comm_local_rank</span><span class="c9">. </span></p><p class="c7"><span class="c22"></span></p><a id="t.febd87097d6acdc6ac335c2829150af17406f2f5"></a><a id="t.23"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c44"><span class="c22">class MyNN(nn.module):</span></p><p class="c44"><span class="c22">&nbsp; &nbsp; ...</span></p><p class="c44 c50"><span class="c22"></span></p><p class="c44"><span class="c22">device = torch.device(&quot;cuda:{}&quot;.format(comm_local_rank) if use_cuda else &quot;cpu&quot;)</span></p><p class="c44"><span class="c22">model = MyNN().to(device)</span></p><p class="c44"><span class="c22">model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[comm_local_rank])</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><h4 class="c51 c33" id="h.s0hd5ycxwpdh"><span class="c34">Optimizer wrapping</span></h4><p class="c8"><span>In contrast to </span><span class="c31"><a class="c4" href="#h.z7g1nmbbb3uh">Horovod</a></span><span class="c9">, We can use the same optimizer as in non-distributed execution. </span></p><p class="c7"><span class="c9"></span></p><h4 class="c51 c33" id="h.d1nulkakooh"><span class="c34">Initial values broadcast</span></h4><p class="c8"><span>Parameter values are synchronized (i.e. initial broadcast and allreduce in every iteration) automatically by</span><span class="c40">&nbsp;DistributedDataParallel</span><span class="c9">&nbsp;class and thus no further modification is necessary.</span></p><p class="c7"><span class="c9"></span></p><h4 class="c51 c33" id="h.x5dny5mqq9px"><span class="c34">Metrics average and reductions</span></h4><h4 class="c51 c33" id="h.5t9pfndndqnr"><span class="c118"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/distributed.html%23multi-gpu-collective-functions&amp;sa=D&amp;ust=1575460960584000">https://pytorch.org/docs/stable/distributed.html#multi-gpu-collective-functions</a></span></h4><p class="c7"><span class="c9"></span></p><h4 class="c51 c33" id="h.3lb7ncfjheoo"><span class="c34">Synchronization</span></h4><p class="c8"><span class="c9">To avoid potential data races other kinds of bugs, you may need to use torch.distributed.barrier() to synchronize processes before or after data loading, and finishing the application. </span></p><p class="c7"><span class="c9"></span></p><p class="c7"><span class="c9"></span></p><h3 class="c48 c33" id="h.fm07a8ui8sm1"><span class="c21"></span></h3><h3 class="c51 c33" id="h.dis62849w9cz"><span class="c21">Pytorch model using Horovod</span></h3><p class="c8"><span>PyTorch can use </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://github.com/horovod/horovod&amp;sa=D&amp;ust=1575460960587000">Horovod</a></span><span>&nbsp;to do Data Parallel training in a similar way to ChainerMN.<br>Data is distributed across the nodes and the optimizer is wrapped in with </span><span>Horovod</span><span class="c9">&nbsp;to automatically average the gradients of several MPI processes.</span></p><h4 class="c51 c69 c33" id="h.o3x9ygfly4q"><span class="c34"></span></h4><h4 class="c51 c33" id="h.tje6mmfdx3pf"><span class="c34">Horovod initialization</span></h4><p class="c8"><span>The following snippet shows how to import horovod and retrieve the current worker id and the total number of workers.</span></p><a id="t.1f187a1cc2a0f3f05314bb5efd0eca754b829707"></a><a id="t.24"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c8"><span class="c2">import horovod.torch as hvd</span></p><p class="c8"><span class="c2">hvd.init()</span></p><p class="c8"><span class="c2">print(&lsquo;My rank is {} of {} workers&lsquo;.format(hvd.rank(), hvd.size()))</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><p class="c8"><span class="c40">hvd.local_rank() </span><span>is used to get the rank inside a single node, this is useful to assign GPUs, similar to ChainerMN&rsquo;s</span><span class="c40">&nbsp;intra_rank()</span><span>.</span></p><a id="t.2947184f677b00b78c938df5ebaf8a3de12018f5"></a><a id="t.25"></a><table class="c20"><tbody><tr class="c108"><td class="c47" colspan="1" rowspan="1"><p class="c8"><span class="c22 c61">torch.cuda.set_device(hvd.local_rank())</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><h4 class="c51 c33" id="h.37g288q2db5i"><span class="c34">Dataset scattering</span></h4><p class="c8"><span>Each node can get a slice of a globally shared dataset using a </span><span class="c40">DistributedSampler</span><span>.</span></p><a id="t.49bd94ec55cd43d4b62152a8a3740c05dbfb8bf1"></a><a id="t.26"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c44"><span class="c40 c32">torch.utils.data.distributed.DistributedSampler(dataset, </span><span class="c40">num_replicas=</span><span class="c22">hvd.size(), </span></p><p class="c44"><span class="c40">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; rank=</span><span class="c22">hvd.rank())</span></p></td></tr></tbody></table><p class="c44 c50"><span class="c9"></span></p><p class="c8"><span>This will make every worker to only load a slice of the dataset, this sampler can be normally fed to the </span><span class="c40">DataLoader</span><span class="c9"><br></span></p><h4 class="c51 c33" id="h.z7g1nmbbb3uh"><span class="c34">Optimizer wrapping</span></h4><p class="c8"><span>The optimizer is wrapped in a </span><span class="c40">hvd.DistributedOptimizer</span><span>&nbsp;object with the following configuration parameters.<br><br></span><span class="c40">compression </span><span>: value in</span><span class="c2">&nbsp;{hvd.Compression.fp16, hvd.Compression.none}<br></span></p><p class="c8"><span>compression is used to reduce the size of the allreduce operations performed by the optimizer.<br><br></span><span class="c40">backward_passes_per_step : int </span><span class="c9">default value usually 1</span></p><p class="c7"><span class="c2"></span></p><p class="c8"><span>Number of batches that are performed locally before performing the gradients exchange.</span></p><a id="t.e7c44ee3b69544418ca97691b43afb5b46f1e908"></a><a id="t.27"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c8"><span class="c2">optimizer = hvd.DistributedOptimizer(</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; optimizer, named_parameters=model.named_parameters(),</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; compression=compression,</span></p><p class="c8"><span class="c2">&nbsp; &nbsp; backward_passes_per_step=args.batches_per_allreduce)</span></p></td></tr></tbody></table><p class="c8"><span><br>From the documentation:<br><br></span><span class="c74 c61 c53">DistributedOptimizer exposes the </span><span class="c102 c53">synchronize()</span><span class="c74 c61 c53">&nbsp;method, which forces allreduce operations to finish before continuing the execution. It&rsquo;s useful in conjunction with gradient clipping, or other operations that modify gradients in place before </span><span class="c102 c53">step()</span><span class="c61 c53 c74">is executed. Make sure to use </span><span class="c53 c102">optimizer.skip_synchronize()</span><span class="c74 c61 c53">&nbsp;if you&rsquo;re calling </span><span class="c102 c53">synchronize()</span><span class="c74 c61 c53">&nbsp;in your code.</span></p><p class="c7"><span class="c9"></span></p><h4 class="c51 c33" id="h.gq621f9b16zf"><span class="c34">Initial values broadcast</span></h4><p class="c8"><span>Before starting the training loop, initial model parameters and the optimizer state must be broadcasted to all the workers:</span></p><a id="t.d9c5fa6d0a478715e92abcf59d1d7d36e3acde5b"></a><a id="t.28"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c8"><span class="c2">hvd.broadcast_parameters(model.state_dict(), root_rank=0)</span></p><p class="c8"><span class="c2">hvd.broadcast_optimizer_state(optimizer, root_rank=0)</span></p></td></tr></tbody></table><h4 class="c51 c33 c69" id="h.7hiogyr5jasg"><span class="c34"></span></h4><h4 class="c51 c33" id="h.9t9k4lfat6t2"><span class="c34">Metrics average and reductions</span></h4><p class="c8"><span class="c9">When computing the loss and other metrics such as accuracy, the values of multiple workers can be explicitly exchanged to compute averages:</span></p><a id="t.7b00fd4181f942caf888937294ff90e6381ac1d0"></a><a id="t.29"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c11"><span class="c40 c61">self.sum += hvd.allreduce(val.detach().cpu(), name=metric_name)</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><p class="c8"><span class="c9">Horovod has support to exchange data using other MPI collectives:</span></p><ul class="c30 lst-kix_rsr7bmzen4a7-0 start"><li class="c8 c43"><span class="c2">horovod.torch.allgather</span></li><li class="c8 c43"><span class="c2">horovod.torch.broadcast</span></li></ul><p class="c8"><span>There are _async versions of the three functions that can be queried using </span><span class="c40">poll()</span><span>&nbsp;on the returned handler or </span><span class="c40">synchronize()</span><span class="c9">&nbsp;to wait till completion.</span></p><p class="c7"><span class="c9"></span></p><h4 class="c51 c33" id="h.bfpbumwh7xzs"><span class="c34">Horovod code structure</span></h4><a id="t.e2ebc92c8c2223cbc3ddccd433f6d952be2ae85c"></a><a id="t.30"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c11"><span class="c55 c16">import torch</span></p><p class="c11"><span class="c55 c16">import horovod.torch as hvd</span></p><p class="c11"><span class="c55 c16">&hellip;</span></p><p class="c11"><span class="c55 c16">&hellip;</span></p><p class="c11"><span class="c55 c16">def main():</span></p><p class="c11"><span class="c16">&nbsp; &nbsp; </span><span class="c16 c56"># Initialize horovod</span></p><p class="c8"><span class="c55 c16">&nbsp; &nbsp; hvd.init()</span></p><p class="c8"><span class="c16">&nbsp; &nbsp; </span><span class="c55 c16 c61">torch.cuda.set_device(hvd.local_rank())</span></p><p class="c8"><span class="c16 c61">&nbsp; &nbsp; </span><span class="c56 c16 c61"># Read the dataset and create the iterators</span></p><p class="c8"><span class="c55 c16 c61">&nbsp; &nbsp; dataset = datasets.ImageFolder(&hellip;)</span></p><p class="c8"><span class="c16 c61">&nbsp; &nbsp; train_sampler = </span><span class="c55 c16">torch.utils.data.distributed.DistributedSampler(dataset, num_replicas=hvd.size(), </span></p><p class="c44"><span class="c55 c16">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; rank=hvd.rank())</span></p><p class="c44"><span class="c16">&nbsp; &nbsp; loader = torch.utils.data.DataLoader(dataset, sampler=train_sampler, &hellip;)<br> &nbsp; &nbsp;</span><span class="c56 c16"># Set up the model, checkpoints, &hellip;</span></p><p class="c44"><span class="c55 c16">&nbsp; &nbsp; &hellip;</span></p><p class="c44"><span class="c16">&nbsp; &nbsp; </span><span class="c56 c16"># Create the optimizer</span></p><p class="c44"><span class="c55 c16">&nbsp; &nbsp; optimizer = optim.SGD(model.parameters(), &hellip;)</span></p><p class="c44"><span class="c55 c16">&nbsp; &nbsp; optimizer = hvd.DistributedOptimizer(</span></p><p class="c44"><span class="c55 c16">&nbsp; &nbsp; &nbsp; &nbsp; optimizer, named_parameters=model.named_parameters(),</span></p><p class="c44"><span class="c55 c16">&nbsp; &nbsp; &nbsp; &nbsp; compression= hvd.Compression.none,</span></p><p class="c44"><span class="c55 c16">&nbsp; &nbsp; &nbsp; &nbsp; backward_passes_per_step=args.batches_per_allreduce)<br></span></p><p class="c44"><span class="c16">&nbsp; &nbsp; </span><span class="c56 c16"># Broadcast initial state</span></p><p class="c44"><span class="c16 c67 c32">&nbsp; &nbsp; broadcast parameters &amp; optimizer state.</span></p><p class="c44"><span class="c16 c67 c32">&nbsp; &nbsp; hvd.broadcast_parameters(model.state_dict(), root_rank=0)</span></p><p class="c44"><span class="c16 c67 c32">&nbsp; &nbsp; hvd.broadcast_optimizer_state(optimizer, root_rank=0)</span></p><p class="c44"><span class="c16 c32">&nbsp; &nbsp; </span><span class="c56 c16"># Start training</span></p><p class="c44"><span class="c16 c67 c32">&nbsp; &nbsp; for epoch in range(epochs):</span></p><p class="c44"><span class="c16 c67 c32">&nbsp; &nbsp; &nbsp; &nbsp; train_sampler.set_epoch(epoch)</span></p><p class="c44"><span class="c16 c32 c67">&nbsp; &nbsp; &nbsp; &nbsp; &hellip; </span></p></td></tr></tbody></table><p class="c7"><span class="c2"></span></p><h4 class="c51 c33" id="h.apxtaciyccdc"><span class="c34">Obtaining Horovod traces to measure performance</span></h4><p class="c8"><span>Communication traces showing Horovod communications can be obtained by setting the </span><span class="c40">HOROVOD_TIMELINE</span><span class="c9">&nbsp;environment variable.</span></p><a id="t.64ecae9ad815cf624f1b9ed5b6a24476d88e0a59"></a><a id="t.31"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c11"><span class="c2">mpirun -bind-to-none -np 8 -x HOROVOD_TIMELINE=timeline.json ...</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><p class="c8"><span class="c9">The resultant trace can be visualized in Chrome by using the browser built-in chrome://tracing feature.</span></p><p class="c7"><span class="c9"></span></p><h4 class="c51 c33" id="h.9jn0jqinrgx3"><span class="c34">Tuning Horovod performance</span></h4><p class="c8"><span class="c9">Horovod has several knobs to improve its performance</span></p><p class="c7"><span class="c9"></span></p><ul class="c30 lst-kix_9i19e8txouig-0 start"><li class="c8 c43"><span>TensorFusion improves network utilization when there are many operations to be done on small tensors. Instead of eagerly starting multiple small reductions, horovod combines the small tensors on a buffer and then batch operations in order to perform a more efficient communication/computation overlap. </span><span class="c16 c32">HOROVOD_FUSION_THRESHOLD</span><span class="c32 c53 c100">&nbsp;</span><span class="c32 c53">controls the size of the buffer in bytes (default is 64MB). </span><span class="c16 c32">HOROVOD_CYCLE_TIME </span><span class="c52 c32">specifies the amount of time in ms to wait for tensors to be batched before reducing them.</span></li><li class="c8 c43"><span class="c32 c53">Hierarchical Reduce: </span><span class="c16 c32">HOROVOD_HIERARCHICAL_ALLREDUCE</span><span class="c52 c32">&nbsp;does a hybrid approach where allreduce in-node is done by NCCL, and allreduce across nodes is done by MPI.</span></li><li class="c8 c43"><span class="c16 c32">HOROVOD_AUTOTUNE </span><span class="c32 c53">can be used for horovod to perform a Bayesian optimization on all the configurable parameters at the first epochs of training. More info </span><span class="c31 c53"><a class="c4" href="https://www.google.com/url?q=https://github.com/horovod/horovod/blob/83eaa163b395ae8866a404f94facf82cc8127642/docs/autotune.rst&amp;sa=D&amp;ust=1575460960645000">here</a></span></li></ul><h4 class="c51 c69 c33" id="h.81xyyty2r9qq"><span class="c34"></span></h4><h4 class="c51 c33" id="h.wuax6jpon8sy"><span class="c34">Using Horovod with apex</span></h4><p class="c8"><span>Horovod launches all-reduce in parallel with backward computation, and </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://github.com/NVIDIA/apex&amp;sa=D&amp;ust=1575460960647000">apex</a></span><span class="c9">&nbsp;unscales gradient after backward computation.</span></p><p class="c8"><span class="c9">To avoid race conditions, we have to wait for all-reduce completion before unscaling:</span></p><a id="t.6f2636f4210fb90c92d9a363f1d87ad8d31bcaab"></a><a id="t.32"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c11"><span class="c2">from apex import amp</span></p><p class="c11"><span class="c2">...</span></p><p class="c11"><span class="c2">with amp.scale_loss(loss, optimizer) as scaled_loss:</span></p><p class="c11"><span class="c2">&nbsp; &nbsp; scaled_loss.backward()</span></p><p class="c11"><span class="c2">&nbsp; &nbsp; optimizer.synchronize() &nbsp;# Wait for all-reduce completion</span></p><p class="c11"><span class="c2">with optimizer.skip_synchronize():</span></p><p class="c11"><span class="c2">&nbsp; &nbsp; optimizer.step()</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><p class="c8"><span>Also, </span><span class="c40">backward_passes_per_step </span><span>should be 1 when using Horovod and apex. The current implementation of Horovoda and apex do not work as expected when </span><span class="c40">backward_passes_per_step</span><span class="c9">&nbsp;is not 1.</span></p><p class="c7"><span class="c9"></span></p><h4 class="c51 c33" id="h.y8eom3uzrv56"><span class="c34">Alternatives to Horovod</span></h4><p class="c8"><span class="c9">Horovod is introduced here because it greatly resembles ChainerMN and can be used in our computing infrastructure right away. Alternatives are:<br></span></p><ul class="c30 lst-kix_dnm4ke3nhj1e-0 start"><li class="c8 c43"><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/tutorials/intermediate/dist_tuto.html&amp;sa=D&amp;ust=1575460960651000">Pytorch distributed API</a></span></li><li class="c8 c43"><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://williamfalcon.github.io/pytorch-lightning/Trainer/Distributed%2520training/%23Multi-node&amp;sa=D&amp;ust=1575460960652000">Lightning</a></span></li></ul><p class="c7"><span class="c9"></span></p><h3 class="c51 c33" id="h.qfxp9de828j4"><span class="c21">Chainer model using Horovod</span></h3><p class="c8"><span>To train chainer models in distributed environments using Horovod, the chainer link should be wrapped using </span><span class="c31 c40"><a class="c4" href="#h.46et3pwf65s">cpm.LinkAsTorchModel</a></span><span class="c40">. </span><span class="c9">The use of a PyTorch optimizer is required.</span></p><a id="t.7661993af0cae4de0e215da4478516ee48efe2c4"></a><a id="t.33"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c11"><span class="c2">model = ChainerModel()</span></p><p class="c11"><span class="c2">model.to_device(ch_device)</span></p><p class="c11 c50"><span class="c2"></span></p><p class="c11"><span class="c56 c40 c81"># Initialize parameters before converting to `ChainerParameter`s.</span></p><p class="c11"><span class="c2">model(ch_device.xp.zeros((1, 784)).astype(&#39;f&#39;))</span></p><p class="c11 c50"><span class="c2"></span></p><p class="c11"><span class="c56 c40 c81"># Convert parameters to `ChainerParameter`s to share memory with PyTorch.</span></p><p class="c11"><span class="c2">torched_model = cip.LinkAsTorchModel(model)</span></p><p class="c11 c50"><span class="c2"></span></p><p class="c11"><span class="c2">optimizer = optim.SGD(torched_model.parameters(), lr=args.lr)</span></p><p class="c11 c50"><span class="c2"></span></p><p class="c11"><span class="c2">optimizer = hvd.DistributedOptimizer(</span></p><p class="c11"><span class="c2">&nbsp; &nbsp; optimizer, named_parameters=torched_model.named_parameters())</span></p><p class="c11"><span class="c2">hvd.broadcast_parameters(torched_model.state_dict(), root_rank=0)</span></p><p class="c11"><span class="c40">hvd.broadcast_optimizer_state(optimizer, root_rank=0)</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><h3 class="c51 c33" id="h.vlwpxcx5nw9c"><span class="c21">Torch model using ChainerMN</span></h3><p class="c8"><span class="c9">Using the cpm tool it is also possible to train a Torch model using ChainerMN.</span></p><p class="c8"><span class="c9">The current support is limited only to data parallel training.</span></p><a id="t.0eeb743abfa107ec882dd18dcbb467ec22d093d1"></a><a id="t.34"></a><table class="c20"><tbody><tr class="c10"><td class="c47" colspan="1" rowspan="1"><p class="c11"><span class="c16 c61">from</span><span class="c16 c61">&nbsp;chainer_pytorch_migration </span><span class="c16 c61">import</span><span class="c55 c16 c61">&nbsp;chainermn</span></p><p class="c11 c50"><span class="c67 c26 c61 c37 c32"></span></p><p class="c11"><span class="c67 c26 c61 c37 c32">&hellip;</span></p><p class="c11"><span class="c26 c61 c37 c32">comm </span><span class="c26 c61 c37 c110">=</span><span class="c26 c61 c37 c32">&nbsp;chainermn.create_communicator(</span><span class="c26 c61 c37 c62">&#39;pure_nccl&#39;</span><span class="c67 c26 c61 c37 c32">)<br></span></p><p class="c11"><span class="c67 c26 c61 c37 c32"># Set up standard ResNet-50 model.</span></p><p class="c11"><span class="c67 c26 c61 c37 c32">model = models.resnet50()</span></p><p class="c11"><span class="c67 c26 c61 c37 c32">model.cuda()</span></p><p class="c11"><span class="c67 c26 c61 c37 c32">w_model = links.TorchModule(model)</span></p><p class="c11"><span class="c67 c26 c61 c37 c32">w_model.to_gpu(device)</span></p><p class="c11 c50"><span class="c67 c26 c61 c37 c32"></span></p><p class="c11 c50"><span class="c67 c26 c61 c37 c32"></span></p><p class="c11"><span class="c67 c26 c61 c37 c32">optimizer = optim.SGD(model.parameters(), lr=lr)</span></p><p class="c11 c50"><span class="c67 c26 c61 c37 c32"></span></p><p class="c11"><span class="c67 c26 c61 c37 c32">optimizer = chainermn.create_multi_node_optimizer(optimizer, comm)</span></p><p class="c11"><span class="c67 c26 c61 c37 c32">optimizer.setup(w_model)</span></p></td></tr></tbody></table><p class="c7"><span class="c9"></span></p><h2 class="c35 c33" id="h.2jl4lfh90jqb"><span class="c67 c36 c77">Porting code that edits the computational graph</span></h2><h3 class="c51 c33" id="h.gbqjtjbzzzno"><span class="c21">Unchaining nodes </span></h3><p class="c8"><span class="c9">Explains differences of how variables can be unchained from the computational graph.</span></p><ul class="c30 lst-kix_5s83gilt2o7g-0 start"><li class="c8 c43"><span>Chainer: </span><span class="c40">Variable.{data,array}</span><span>&nbsp;or </span><span class="c40">Variable.unchain()</span><span class="c9">. </span></li><li class="c8 c43"><span>PyTorch: </span><span class="c31 c40"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/autograd.html%23torch.Tensor.detach&amp;sa=D&amp;ust=1575460960666000">Tensor.detach()</a></span><span>. This method returns a new </span><span class="c40">Tensor</span><span>&nbsp;unchained from the computational graph with </span><span class="c40">requires_grad</span><span>&nbsp;set to </span><span class="c40">False</span><span>. This is not an in-place operation in contrast to </span><span class="c40">Variable.unchain()</span><span>&nbsp;and does not incur any side effects (although the new </span><span class="c40">Tensor</span><span>&nbsp;will share the same memory). An in-place variant is however provided as well </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/autograd.html%23torch.Tensor.detach_&amp;sa=D&amp;ust=1575460960667000">Tensor.detach_()</a></span><span class="c9">.</span></li><li class="c8 c43"><span>PyTorch: </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch.github.io/pull/31&amp;sa=D&amp;ust=1575460960667000">Tensor.data is discouraged</a></span><span class="c9">&nbsp;and it seems like it might even get deprecated in the future (based on comments in forums and on GitHub).</span></li><li class="c8 c43"><span>Chainer&rsquo;s </span><span class="c40">Variable.unchain_backward()</span><span>&nbsp;counterpart in PyTorch is not available?</span></li></ul><h3 class="c51 c33" id="h.mc69ie7hbl6j"><span class="c21">Backprop modes</span></h3><p class="c8"><span class="c9">Explains differences of how backprop modes are switched.</span></p><ul class="c30 lst-kix_g3mw20emt8ab-0 start"><li class="c8 c43"><span>Chainer: </span><span class="c40">no_backprop_mode</span><span>, </span><span class="c40">force_backprop_mode </span><span class="c9">correspond to the following in PyTorch.</span></li><li class="c8 c43"><span>PyTorch: </span><span class="c31 c40"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/autograd.html%23torch.autograd.no_grad&amp;sa=D&amp;ust=1575460960669000">torch.autograd.no_grad()</a></span><span>, </span><span class="c31 c40"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/autograd.html%23torch.autograd.enable_grad&amp;sa=D&amp;ust=1575460960670000">torch.autograd.enable_grad()</a></span><span class="c9">. </span></li><li class="c8 c43"><span class="c40">no_grad()</span><span>&nbsp;can also be used to allow writing data directly to an already allocated </span><span class="c40">Tensor</span><span class="c9">&nbsp;using [...].</span></li><li class="c8 c43"><span>In Chainer, this is also a configuration (</span><span class="c40">configuration.config.enable_backprop</span><span>), it is however not in PyTorch.</span></li><li class="c8 c43"><span class="c9">Both Chainer and PyTorch default to backprop mode being enabled.</span></li></ul><h3 class="c51 c33" id="h.bka3yqtw2rpy"><span class="c21">Train/Test modes</span></h3><p class="c8"><span class="c9">Explains differences of how train/test modes are switched. </span></p><ul class="c30 lst-kix_3sh9r2c1w16g-0 start"><li class="c8 c43"><span>Chainer: This mode is controlled via a configuration (</span><span class="c40">configuration.config.train</span><span class="c9">).</span></li><li class="c8 c43"><span>PyTorch: This mode is a module state and should be changed using </span><span class="c31 c40"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Module.train&amp;sa=D&amp;ust=1575460960672000">torch.nn.Module.train(mode)</a></span><span>, </span><span class="c31 c40"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Module.eval&amp;sa=D&amp;ust=1575460960672000">torch.nn.Module.eval()</a></span><span>. This also means that you must pass the &ldquo;train&rdquo; argument to functions calls such as </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.dropout&amp;sa=D&amp;ust=1575460960673000">torch.nn.functional.dropout</a></span><span>&nbsp;other otherwise use the </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Dropout&amp;sa=D&amp;ust=1575460960673000">torch.nn.Dropout module</a></span><span>&nbsp;which is stateful.</span></li><li class="c8 c43"><span class="c9">In both Chainer and PyTorch, train/test mode affects the behavior of certain functions/links/modules such as dropout and batch normalization. </span></li><li class="c8 c43"><span>Both Chainer and PyTorch default to train mode.</span></li></ul><h1 class="c82 c33" id="h.r8th8e47f02c"><span class="c101 c67 c36">Ecosystem</span></h1><p class="c8"><span class="c9">This section introduces some of the larger repositories under the PyTorch GitHub organization. It also refers to the official list of other ecosystem-libraries acknowledged by PyTorch.</span></p><h3 class="c51 c33" id="h.d863gr6235hf"><span class="c21">PyTorch</span></h3><p class="c8"><span class="c36">Summary:</span><span>&nbsp;</span><span class="c61 c32 c124">Tensors and Dynamic neural networks in Python with strong GPU acceleration</span></p><p class="c8"><span class="c36">GitHub:</span><span>&nbsp;</span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch&amp;sa=D&amp;ust=1575460960675000">https://github.com/pytorch/pytorch</a></span></p><ul class="c30 lst-kix_47504ojh0ba1-0 start"><li class="c8 c43"><span class="c36">Installation:</span><span>&nbsp;See </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/get-started/locally/&amp;sa=D&amp;ust=1575460960676000">Start Locally</a></span><span>&nbsp;for the instructions. Note that not all variants are hosted on PyPI; as of PyTorch 1.2.0, </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pypi.org/project/torch/&amp;sa=D&amp;ust=1575460960676000">torch</a></span><span>/</span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pypi.org/project/torchvision/&amp;sa=D&amp;ust=1575460960677000">torchvision</a></span><span class="c9">&nbsp;packages hosted on PyPI are for CUDA 10.0.</span></li><li class="c8 c43"><span class="c36">Nightly builds</span><span>: Nightly build is provided so you can try the pre-built binary with new merged feature next day. Each nightly build is tagged per each day so you can download nightly version locked pip wheel and prebuilt </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/cppdocs/installing.html&amp;sa=D&amp;ust=1575460960678000">libtorch</a></span><span>&nbsp;of specific build date. For pip wheel refer </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/get-started/locally/&amp;sa=D&amp;ust=1575460960678000">Start Locally</a></span><span>&nbsp;(</span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html&amp;sa=D&amp;ust=1575460960679000">CPU page</a></span><span>, </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html&amp;sa=D&amp;ust=1575460960679000">CUDA 9.2 page</a></span><span>, </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://download.pytorch.org/whl/nightly/cu100/torch_nightly.html&amp;sa=D&amp;ust=1575460960680000">CUDA 10.0 page</a></span><span>) to get optimal version.</span></li></ul><h3 class="c51 c33" id="h.w69092dw2rtl"><span class="c21">Ignite</span></h3><p class="c8"><span class="c36">Summary:</span><span class="c9">&nbsp;High level utilities such as training loop abstraction.</span></p><p class="c8"><span class="c36">GitHub:</span><span>&nbsp;</span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/ignite&amp;sa=D&amp;ust=1575460960682000">https://github.com/pytorch/ignite</a></span></p><h3 class="c51 c33" id="h.b2r58wgcvv09"><span class="c21">torchvision</span></h3><p class="c8"><span class="c36">Summary:</span><span class="c9">&nbsp;PyTorch for CV.</span></p><p class="c8"><span class="c36">GitHub: </span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/vision&amp;sa=D&amp;ust=1575460960683000">https://github.com/pytorch/vision</a></span></p><p class="c8"><span>Recommended by the official installation guide to install along with </span><span class="c40">pytorch</span><span class="c9">.</span></p><p class="c8"><span class="c9">Provides domain-agnostic (not limited to CV) data augmentation functionality.</span></p><p class="c8"><span>Provides loaders for video data. Slow due to ffmpeg but this might be improved in the future?</span></p><h3 class="c51 c33" id="h.ctcyjos25n6z"><span class="c21">torchtext</span></h3><p class="c8"><span class="c36">Summary:</span><span class="c9">&nbsp;PyTorch for NLP.</span></p><p class="c8"><span class="c36">GitHub:</span><span>&nbsp;</span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/text&amp;sa=D&amp;ust=1575460960686000">https://github.com/pytorch/text</a></span></p><h3 class="c51 c33" id="h.l9nxjlcurusl"><span class="c21">torchaudio </span></h3><p class="c8"><span class="c36">Summary:</span><span>&nbsp;PyTorch for audio data.</span></p><p class="c8"><span class="c36">GitHub:</span><span>&nbsp;</span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/audio&amp;sa=D&amp;ust=1575460960793000">https://github.com/pytorch/audio</a></span></p><h3 class="c51 c33" id="h.p90hj6w1ucn0"><span class="c21">Fairseq</span></h3><p class="c8"><span class="c36">Summary:</span><span class="c9">&nbsp;Seq2seq models.</span></p><p class="c8"><span class="c36">GitHub:</span><span>&nbsp;</span><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://github.com/pytorch/fairseq&amp;sa=D&amp;ust=1575460960794000">https://github.com/pytorch/fairseq</a></span></p><p class="c8"><span>Seq2seq models such as translation. Includes the Transformer and BERT-like models.</span></p><h3 class="c51 c33" id="h.eaofa6s7sf0k"><span class="c21">Other</span></h3><p class="c8"><span class="c9">There is an official list of libraries included in the PyTorch ecosystem (besides the domain specific libraries above), including e.g. Ignite.</span></p><p class="c8"><span class="c31"><a class="c4" href="https://www.google.com/url?q=https://pytorch.org/ecosystem&amp;sa=D&amp;ust=1575460960795000">https://pytorch.org/ecosystem</a></span></p></body></html>