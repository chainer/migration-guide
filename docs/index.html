<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url('https://themes.googleusercontent.com/fonts/css?kit=4mNYFHt_IKFsPe52toizH4jB0lxTqxuZ9MrNDVFkHCs');.lst-kix_ne2kodfi1kix-8>li:before{content:"\0025a0  "}.lst-kix_um8gcdc8t9m9-2>li:before{content:"-  "}.lst-kix_um8gcdc8t9m9-3>li:before{content:"-  "}.lst-kix_um8gcdc8t9m9-4>li:before{content:"-  "}.lst-kix_um8gcdc8t9m9-6>li:before{content:"-  "}ul.lst-kix_8d6owvwxykff-3{list-style-type:none}ul.lst-kix_8d6owvwxykff-2{list-style-type:none}.lst-kix_um8gcdc8t9m9-5>li:before{content:"-  "}.lst-kix_um8gcdc8t9m9-7>li:before{content:"-  "}ul.lst-kix_8d6owvwxykff-5{list-style-type:none}ul.lst-kix_8d6owvwxykff-4{list-style-type:none}ul.lst-kix_8d6owvwxykff-7{list-style-type:none}.lst-kix_dnm4ke3nhj1e-8>li:before{content:"\0025a0  "}ul.lst-kix_8d6owvwxykff-6{list-style-type:none}ul.lst-kix_8d6owvwxykff-8{list-style-type:none}.lst-kix_um8gcdc8t9m9-8>li:before{content:"-  "}ul.lst-kix_8d6owvwxykff-1{list-style-type:none}ul.lst-kix_8d6owvwxykff-0{list-style-type:none}ul.lst-kix_dnm4ke3nhj1e-5{list-style-type:none}ul.lst-kix_dnm4ke3nhj1e-6{list-style-type:none}ul.lst-kix_dnm4ke3nhj1e-7{list-style-type:none}ul.lst-kix_dnm4ke3nhj1e-8{list-style-type:none}ul.lst-kix_dnm4ke3nhj1e-0{list-style-type:none}ul.lst-kix_dnm4ke3nhj1e-1{list-style-type:none}ul.lst-kix_dnm4ke3nhj1e-2{list-style-type:none}ul.lst-kix_dnm4ke3nhj1e-3{list-style-type:none}ul.lst-kix_dnm4ke3nhj1e-4{list-style-type:none}ol.lst-kix_8dw3ycrgt362-3.start{counter-reset:lst-ctn-kix_8dw3ycrgt362-3 0}ul.lst-kix_p3wa2k83s8cn-1{list-style-type:none}ul.lst-kix_p3wa2k83s8cn-0{list-style-type:none}ul.lst-kix_p3wa2k83s8cn-3{list-style-type:none}.lst-kix_3z0hr7pzpec4-3>li:before{content:"\0025cf  "}.lst-kix_3z0hr7pzpec4-5>li:before{content:"\0025a0  "}ul.lst-kix_p3wa2k83s8cn-2{list-style-type:none}ul.lst-kix_p3wa2k83s8cn-5{list-style-type:none}ul.lst-kix_p3wa2k83s8cn-4{list-style-type:none}ul.lst-kix_p3wa2k83s8cn-7{list-style-type:none}ul.lst-kix_p3wa2k83s8cn-6{list-style-type:none}.lst-kix_ao97xhpq4hr9-7>li:before{content:"\0025cb  "}ul.lst-kix_p3wa2k83s8cn-8{list-style-type:none}.lst-kix_ao97xhpq4hr9-5>li:before{content:"\0025a0  "}ul.lst-kix_hm0ybxxbxp2l-5{list-style-type:none}ul.lst-kix_hm0ybxxbxp2l-6{list-style-type:none}ul.lst-kix_hm0ybxxbxp2l-7{list-style-type:none}ul.lst-kix_hm0ybxxbxp2l-8{list-style-type:none}ul.lst-kix_hm0ybxxbxp2l-1{list-style-type:none}ul.lst-kix_hm0ybxxbxp2l-2{list-style-type:none}ul.lst-kix_hm0ybxxbxp2l-3{list-style-type:none}ul.lst-kix_hm0ybxxbxp2l-4{list-style-type:none}.lst-kix_3z0hr7pzpec4-7>li:before{content:"\0025cb  "}.lst-kix_mfwegjdddisb-3>li:before{content:"\0025cf  "}.lst-kix_mfwegjdddisb-5>li:before{content:"\0025a0  "}.lst-kix_7n1btf6e2iyv-7>li:before{content:"\0025cb  "}.lst-kix_mfwegjdddisb-1>li:before{content:"\0025cb  "}.lst-kix_mfwegjdddisb-7>li:before{content:"\0025cb  "}ul.lst-kix_hm0ybxxbxp2l-0{list-style-type:none}.lst-kix_7n1btf6e2iyv-1>li:before{content:"\0025cb  "}.lst-kix_ao97xhpq4hr9-3>li:before{content:"\0025cf  "}.lst-kix_7n1btf6e2iyv-3>li:before{content:"\0025cf  "}ol.lst-kix_8dw3ycrgt362-8.start{counter-reset:lst-ctn-kix_8dw3ycrgt362-8 0}.lst-kix_ao97xhpq4hr9-1>li:before{content:"\0025cb  "}.lst-kix_7n1btf6e2iyv-5>li:before{content:"\0025a0  "}.lst-kix_7pcs9kbg0qhi-4>li{counter-increment:lst-ctn-kix_7pcs9kbg0qhi-4}.lst-kix_8dw3ycrgt362-0>li{counter-increment:lst-ctn-kix_8dw3ycrgt362-0}.lst-kix_dnm4ke3nhj1e-1>li:before{content:"\0025cb  "}.lst-kix_dnm4ke3nhj1e-5>li:before{content:"\0025a0  "}ol.lst-kix_7pcs9kbg0qhi-2.start{counter-reset:lst-ctn-kix_7pcs9kbg0qhi-2 0}.lst-kix_dnm4ke3nhj1e-7>li:before{content:"\0025cb  "}.lst-kix_7pcs9kbg0qhi-5>li{counter-increment:lst-ctn-kix_7pcs9kbg0qhi-5}.lst-kix_um8gcdc8t9m9-1>li:before{content:"-  "}.lst-kix_8dw3ycrgt362-7>li:before{content:"" counter(lst-ctn-kix_8dw3ycrgt362-7,lower-latin) ". "}.lst-kix_dnm4ke3nhj1e-3>li:before{content:"\0025cf  "}ul.lst-kix_3z0hr7pzpec4-5{list-style-type:none}ul.lst-kix_3z0hr7pzpec4-6{list-style-type:none}ul.lst-kix_3z0hr7pzpec4-7{list-style-type:none}.lst-kix_8dw3ycrgt362-1>li:before{content:"" counter(lst-ctn-kix_8dw3ycrgt362-1,lower-latin) ". "}.lst-kix_8dw3ycrgt362-3>li:before{content:"" counter(lst-ctn-kix_8dw3ycrgt362-3,decimal) ". "}ul.lst-kix_3z0hr7pzpec4-8{list-style-type:none}.lst-kix_5we8o0btcr67-7>li:before{content:"\0025cb  "}.lst-kix_8dw3ycrgt362-5>li:before{content:"" counter(lst-ctn-kix_8dw3ycrgt362-5,lower-roman) ". "}ul.lst-kix_3z0hr7pzpec4-0{list-style-type:none}ul.lst-kix_3z0hr7pzpec4-1{list-style-type:none}ul.lst-kix_3z0hr7pzpec4-2{list-style-type:none}ul.lst-kix_3z0hr7pzpec4-3{list-style-type:none}.lst-kix_ne2kodfi1kix-1>li:before{content:"\0025cb  "}ul.lst-kix_3z0hr7pzpec4-4{list-style-type:none}.lst-kix_5s83gilt2o7g-1>li:before{content:"\0025cb  "}.lst-kix_ne2kodfi1kix-3>li:before{content:"\0025cf  "}.lst-kix_ne2kodfi1kix-7>li:before{content:"\0025cb  "}.lst-kix_5s83gilt2o7g-3>li:before{content:"\0025cf  "}.lst-kix_5s83gilt2o7g-5>li:before{content:"\0025a0  "}.lst-kix_3z0hr7pzpec4-1>li:before{content:"\0025cb  "}.lst-kix_ne2kodfi1kix-5>li:before{content:"\0025a0  "}ul.lst-kix_5iyzxwlmxp1f-6{list-style-type:none}ul.lst-kix_5iyzxwlmxp1f-5{list-style-type:none}ul.lst-kix_5iyzxwlmxp1f-4{list-style-type:none}ul.lst-kix_5iyzxwlmxp1f-3{list-style-type:none}.lst-kix_5s83gilt2o7g-6>li:before{content:"\0025cf  "}ul.lst-kix_5iyzxwlmxp1f-2{list-style-type:none}ul.lst-kix_5iyzxwlmxp1f-1{list-style-type:none}ul.lst-kix_5iyzxwlmxp1f-0{list-style-type:none}ul.lst-kix_5iyzxwlmxp1f-8{list-style-type:none}ul.lst-kix_5iyzxwlmxp1f-7{list-style-type:none}ol.lst-kix_8dw3ycrgt362-7.start{counter-reset:lst-ctn-kix_8dw3ycrgt362-7 0}.lst-kix_5we8o0btcr67-3>li:before{content:"\0025cf  "}.lst-kix_hm0ybxxbxp2l-7>li:before{content:"\0025cb  "}.lst-kix_hm0ybxxbxp2l-6>li:before{content:"\0025cf  "}.lst-kix_8d6owvwxykff-0>li:before{content:"\0025cf  "}.lst-kix_5we8o0btcr67-2>li:before{content:"\0025a0  "}ul.lst-kix_msukp0gxz1c7-6{list-style-type:none}ol.lst-kix_7pcs9kbg0qhi-6.start{counter-reset:lst-ctn-kix_7pcs9kbg0qhi-6 0}ul.lst-kix_msukp0gxz1c7-5{list-style-type:none}ul.lst-kix_msukp0gxz1c7-8{list-style-type:none}.lst-kix_mvnr2hoa94kd-2>li:before{content:"\0025a0  "}ul.lst-kix_msukp0gxz1c7-7{list-style-type:none}ul.lst-kix_msukp0gxz1c7-2{list-style-type:none}.lst-kix_hm0ybxxbxp2l-2>li:before{content:"\0025a0  "}ul.lst-kix_msukp0gxz1c7-1{list-style-type:none}ul.lst-kix_msukp0gxz1c7-4{list-style-type:none}ul.lst-kix_msukp0gxz1c7-3{list-style-type:none}.lst-kix_9uzslqp6q29w-3>li:before{content:"\0025cf  "}ul.lst-kix_msukp0gxz1c7-0{list-style-type:none}.lst-kix_hm0ybxxbxp2l-3>li:before{content:"\0025cf  "}.lst-kix_9uzslqp6q29w-4>li:before{content:"\0025cb  "}.lst-kix_mvnr2hoa94kd-1>li:before{content:"\0025cb  "}.lst-kix_9uzslqp6q29w-0>li:before{content:"\0025cf  "}ul.lst-kix_hait203o5dqo-1{list-style-type:none}ul.lst-kix_hait203o5dqo-0{list-style-type:none}ul.lst-kix_hait203o5dqo-3{list-style-type:none}ul.lst-kix_hait203o5dqo-2{list-style-type:none}ul.lst-kix_hait203o5dqo-5{list-style-type:none}ul.lst-kix_hait203o5dqo-4{list-style-type:none}ul.lst-kix_hait203o5dqo-7{list-style-type:none}.lst-kix_8dw3ycrgt362-1>li{counter-increment:lst-ctn-kix_8dw3ycrgt362-1}ul.lst-kix_hait203o5dqo-6{list-style-type:none}ul.lst-kix_hait203o5dqo-8{list-style-type:none}.lst-kix_8d6owvwxykff-5>li:before{content:"\0025a0  "}.lst-kix_8d6owvwxykff-4>li:before{content:"\0025cb  "}.lst-kix_8d6owvwxykff-1>li:before{content:"\0025cb  "}.lst-kix_7pcs9kbg0qhi-3>li{counter-increment:lst-ctn-kix_7pcs9kbg0qhi-3}.lst-kix_msukp0gxz1c7-7>li:before{content:"\0025cb  "}.lst-kix_msukp0gxz1c7-6>li:before{content:"\0025cf  "}.lst-kix_msukp0gxz1c7-3>li:before{content:"\0025cf  "}.lst-kix_8d6owvwxykff-8>li:before{content:"\0025a0  "}.lst-kix_msukp0gxz1c7-2>li:before{content:"\0025a0  "}.lst-kix_6wlb53t5sfma-3>li:before{content:"\0025cf  "}.lst-kix_3z0hr7pzpec4-2>li:before{content:"\0025a0  "}.lst-kix_3z0hr7pzpec4-6>li:before{content:"\0025cf  "}.lst-kix_6wlb53t5sfma-7>li:before{content:"\0025cb  "}ol.lst-kix_7pcs9kbg0qhi-7.start{counter-reset:lst-ctn-kix_7pcs9kbg0qhi-7 0}.lst-kix_8dw3ycrgt362-8>li{counter-increment:lst-ctn-kix_8dw3ycrgt362-8}.lst-kix_ao97xhpq4hr9-8>li:before{content:"\0025a0  "}.lst-kix_7n1btf6e2iyv-2>li:before{content:"\0025a0  "}.lst-kix_mfwegjdddisb-6>li:before{content:"\0025cf  "}.lst-kix_e8kaqrotva4-6>li:before{content:"\0025cf  "}.lst-kix_ao97xhpq4hr9-4>li:before{content:"\0025cb  "}.lst-kix_ao97xhpq4hr9-0>li:before{content:"\0025cf  "}.lst-kix_7n1btf6e2iyv-6>li:before{content:"\0025cf  "}.lst-kix_mfwegjdddisb-2>li:before{content:"\0025a0  "}.lst-kix_w93gux8gcekz-1>li:before{content:"-  "}.lst-kix_dnm4ke3nhj1e-2>li:before{content:"\0025a0  "}.lst-kix_dnm4ke3nhj1e-6>li:before{content:"\0025cf  "}ul.lst-kix_38adif7m6rbx-0{list-style-type:none}ul.lst-kix_38adif7m6rbx-1{list-style-type:none}ul.lst-kix_38adif7m6rbx-2{list-style-type:none}ul.lst-kix_38adif7m6rbx-3{list-style-type:none}ul.lst-kix_owgllipbp8j5-0{list-style-type:none}.lst-kix_r60cdwx1dlic-2>li:before{content:"\0025a0  "}ul.lst-kix_owgllipbp8j5-1{list-style-type:none}ul.lst-kix_38adif7m6rbx-8{list-style-type:none}ul.lst-kix_owgllipbp8j5-2{list-style-type:none}.lst-kix_9uzslqp6q29w-7>li:before{content:"\0025cb  "}ul.lst-kix_owgllipbp8j5-3{list-style-type:none}ul.lst-kix_owgllipbp8j5-4{list-style-type:none}ul.lst-kix_owgllipbp8j5-5{list-style-type:none}ul.lst-kix_38adif7m6rbx-4{list-style-type:none}ul.lst-kix_owgllipbp8j5-6{list-style-type:none}ul.lst-kix_38adif7m6rbx-5{list-style-type:none}ul.lst-kix_owgllipbp8j5-7{list-style-type:none}ul.lst-kix_38adif7m6rbx-6{list-style-type:none}ul.lst-kix_owgllipbp8j5-8{list-style-type:none}ul.lst-kix_38adif7m6rbx-7{list-style-type:none}.lst-kix_w93gux8gcekz-5>li:before{content:"-  "}.lst-kix_um8gcdc8t9m9-0>li:before{content:"-  "}.lst-kix_e8kaqrotva4-2>li:before{content:"\0025a0  "}.lst-kix_8dw3ycrgt362-8>li:before{content:"" counter(lst-ctn-kix_8dw3ycrgt362-8,lower-roman) ". "}.lst-kix_mvnr2hoa94kd-5>li:before{content:"\0025a0  "}.lst-kix_5we8o0btcr67-6>li:before{content:"\0025cf  "}.lst-kix_ne2kodfi1kix-2>li:before{content:"\0025a0  "}.lst-kix_8dw3ycrgt362-4>li:before{content:"" counter(lst-ctn-kix_8dw3ycrgt362-4,lower-latin) ". "}.lst-kix_5s83gilt2o7g-2>li:before{content:"\0025a0  "}.lst-kix_ne2kodfi1kix-6>li:before{content:"\0025cf  "}.lst-kix_8dw3ycrgt362-0>li:before{content:"" counter(lst-ctn-kix_8dw3ycrgt362-0,decimal) ". "}.lst-kix_r60cdwx1dlic-6>li:before{content:"\0025cf  "}.lst-kix_7pcs9kbg0qhi-6>li:before{content:"" counter(lst-ctn-kix_7pcs9kbg0qhi-6,decimal) ". "}.lst-kix_7pcs9kbg0qhi-1>li:before{content:"" counter(lst-ctn-kix_7pcs9kbg0qhi-1,lower-latin) ". "}.lst-kix_7pcs9kbg0qhi-3>li:before{content:"" counter(lst-ctn-kix_7pcs9kbg0qhi-3,decimal) ". "}ul.lst-kix_rsr7bmzen4a7-0{list-style-type:none}ul.lst-kix_s4rut6kfjze3-2{list-style-type:none}ul.lst-kix_rsr7bmzen4a7-3{list-style-type:none}ul.lst-kix_s4rut6kfjze3-3{list-style-type:none}ul.lst-kix_rsr7bmzen4a7-4{list-style-type:none}ul.lst-kix_s4rut6kfjze3-4{list-style-type:none}ul.lst-kix_rsr7bmzen4a7-1{list-style-type:none}ul.lst-kix_s4rut6kfjze3-5{list-style-type:none}ul.lst-kix_rsr7bmzen4a7-2{list-style-type:none}ul.lst-kix_s4rut6kfjze3-6{list-style-type:none}ul.lst-kix_rsr7bmzen4a7-7{list-style-type:none}.lst-kix_7pcs9kbg0qhi-4>li:before{content:"" counter(lst-ctn-kix_7pcs9kbg0qhi-4,lower-latin) ". "}ul.lst-kix_s4rut6kfjze3-7{list-style-type:none}ul.lst-kix_rsr7bmzen4a7-8{list-style-type:none}ul.lst-kix_s4rut6kfjze3-8{list-style-type:none}ul.lst-kix_rsr7bmzen4a7-5{list-style-type:none}ul.lst-kix_rsr7bmzen4a7-6{list-style-type:none}ul.lst-kix_9sdxipg1h5wr-5{list-style-type:none}ul.lst-kix_9sdxipg1h5wr-4{list-style-type:none}ul.lst-kix_9sdxipg1h5wr-3{list-style-type:none}ul.lst-kix_9sdxipg1h5wr-2{list-style-type:none}ul.lst-kix_9sdxipg1h5wr-8{list-style-type:none}ul.lst-kix_s4rut6kfjze3-0{list-style-type:none}ul.lst-kix_9sdxipg1h5wr-7{list-style-type:none}ul.lst-kix_s4rut6kfjze3-1{list-style-type:none}ul.lst-kix_9sdxipg1h5wr-6{list-style-type:none}.lst-kix_9sdxipg1h5wr-8>li:before{content:"\0025a0  "}.lst-kix_8dw3ycrgt362-2>li{counter-increment:lst-ctn-kix_8dw3ycrgt362-2}.lst-kix_9sdxipg1h5wr-7>li:before{content:"\0025cb  "}ul.lst-kix_9sdxipg1h5wr-1{list-style-type:none}ul.lst-kix_9sdxipg1h5wr-0{list-style-type:none}.lst-kix_9sdxipg1h5wr-5>li:before{content:"\0025a0  "}.lst-kix_9sdxipg1h5wr-0>li:before{content:"\0025cf  "}.lst-kix_9sdxipg1h5wr-2>li:before{content:"\0025a0  "}.lst-kix_3bekfbfd6o8j-7>li:before{content:"\0025cb  "}.lst-kix_hait203o5dqo-4>li:before{content:"-  "}.lst-kix_hait203o5dqo-2>li:before{content:"-  "}.lst-kix_hait203o5dqo-1>li:before{content:"-  "}.lst-kix_2aliey961vrg-0>li:before{content:"\0025cf  "}.lst-kix_6wlb53t5sfma-2>li:before{content:"\0025a0  "}.lst-kix_2aliey961vrg-5>li:before{content:"\0025a0  "}.lst-kix_lqb82f5hzmh3-3>li:before{content:"\0025cf  "}.lst-kix_2aliey961vrg-3>li:before{content:"\0025cf  "}.lst-kix_6wlb53t5sfma-0>li:before{content:"\0025cf  "}.lst-kix_6wlb53t5sfma-8>li:before{content:"\0025a0  "}.lst-kix_38adif7m6rbx-6>li:before{content:"\0025cf  "}.lst-kix_lqb82f5hzmh3-1>li:before{content:"\0025cb  "}.lst-kix_38adif7m6rbx-8>li:before{content:"\0025a0  "}ul.lst-kix_w93gux8gcekz-8{list-style-type:none}.lst-kix_e8kaqrotva4-7>li:before{content:"\0025cb  "}.lst-kix_c4453ihcjob0-1>li:before{content:"\0025cb  "}.lst-kix_3bekfbfd6o8j-1>li:before{content:"\0025cb  "}.lst-kix_8dw3ycrgt362-6>li{counter-increment:lst-ctn-kix_8dw3ycrgt362-6}.lst-kix_r60cdwx1dlic-3>li:before{content:"\0025cf  "}.lst-kix_w93gux8gcekz-0>li:before{content:"-  "}.lst-kix_w93gux8gcekz-8>li:before{content:"-  "}.lst-kix_e8kaqrotva4-1>li:before{content:"\0025cb  "}.lst-kix_w93gux8gcekz-6>li:before{content:"-  "}ul.lst-kix_w93gux8gcekz-7{list-style-type:none}ul.lst-kix_w93gux8gcekz-6{list-style-type:none}.lst-kix_9i19e8txouig-4>li:before{content:"\0025cb  "}ul.lst-kix_w93gux8gcekz-5{list-style-type:none}ul.lst-kix_w93gux8gcekz-4{list-style-type:none}ul.lst-kix_w93gux8gcekz-3{list-style-type:none}.lst-kix_9uzslqp6q29w-8>li:before{content:"\0025a0  "}ul.lst-kix_w93gux8gcekz-2{list-style-type:none}.lst-kix_9i19e8txouig-2>li:before{content:"\0025a0  "}.lst-kix_c4453ihcjob0-7>li:before{content:"\0025cb  "}ul.lst-kix_w93gux8gcekz-1{list-style-type:none}ul.lst-kix_w93gux8gcekz-0{list-style-type:none}.lst-kix_6shy0i3drli2-6>li:before{content:"-  "}.lst-kix_38adif7m6rbx-0>li:before{content:"\0025cf  "}.lst-kix_r60cdwx1dlic-5>li:before{content:"\0025a0  "}.lst-kix_6shy0i3drli2-4>li:before{content:"-  "}.lst-kix_owgllipbp8j5-4>li:before{content:"\0025cb  "}.lst-kix_5s83gilt2o7g-7>li:before{content:"\0025cb  "}.lst-kix_g3mw20emt8ab-8>li:before{content:"\0025a0  "}.lst-kix_5we8o0btcr67-5>li:before{content:"\0025a0  "}ul.lst-kix_mfwegjdddisb-6{list-style-type:none}.lst-kix_5we8o0btcr67-0>li:before{content:"\0025cf  "}ul.lst-kix_mfwegjdddisb-5{list-style-type:none}ul.lst-kix_mfwegjdddisb-4{list-style-type:none}ul.lst-kix_mfwegjdddisb-3{list-style-type:none}.lst-kix_g3mw20emt8ab-5>li:before{content:"\0025a0  "}ul.lst-kix_mfwegjdddisb-8{list-style-type:none}ul.lst-kix_mfwegjdddisb-7{list-style-type:none}.lst-kix_hm0ybxxbxp2l-1>li:before{content:"\0025cb  "}.lst-kix_mvnr2hoa94kd-4>li:before{content:"\0025cb  "}.lst-kix_hm0ybxxbxp2l-4>li:before{content:"\0025cb  "}.lst-kix_9uzslqp6q29w-2>li:before{content:"\0025a0  "}ul.lst-kix_lqb82f5hzmh3-0{list-style-type:none}ul.lst-kix_5gii2tr4ae90-1{list-style-type:none}ul.lst-kix_5gii2tr4ae90-0{list-style-type:none}ul.lst-kix_5gii2tr4ae90-3{list-style-type:none}ul.lst-kix_5gii2tr4ae90-2{list-style-type:none}ul.lst-kix_5gii2tr4ae90-5{list-style-type:none}ul.lst-kix_5gii2tr4ae90-4{list-style-type:none}ul.lst-kix_5gii2tr4ae90-7{list-style-type:none}ul.lst-kix_5gii2tr4ae90-6{list-style-type:none}ul.lst-kix_5gii2tr4ae90-8{list-style-type:none}.lst-kix_7pcs9kbg0qhi-7>li{counter-increment:lst-ctn-kix_7pcs9kbg0qhi-7}ul.lst-kix_ne2kodfi1kix-3{list-style-type:none}ul.lst-kix_ne2kodfi1kix-2{list-style-type:none}.lst-kix_p3wa2k83s8cn-2>li:before{content:"\0025a0  "}ul.lst-kix_ne2kodfi1kix-1{list-style-type:none}ul.lst-kix_ne2kodfi1kix-0{list-style-type:none}ul.lst-kix_ne2kodfi1kix-7{list-style-type:none}ul.lst-kix_ne2kodfi1kix-6{list-style-type:none}ul.lst-kix_ne2kodfi1kix-5{list-style-type:none}ul.lst-kix_ne2kodfi1kix-4{list-style-type:none}.lst-kix_rsr7bmzen4a7-6>li:before{content:"\0025cf  "}ul.lst-kix_ne2kodfi1kix-8{list-style-type:none}.lst-kix_p3wa2k83s8cn-5>li:before{content:"\0025a0  "}.lst-kix_jbicnccaji3d-2>li:before{content:"\0025a0  "}ul.lst-kix_lqb82f5hzmh3-2{list-style-type:none}ul.lst-kix_lqb82f5hzmh3-1{list-style-type:none}ul.lst-kix_lqb82f5hzmh3-4{list-style-type:none}ul.lst-kix_lqb82f5hzmh3-3{list-style-type:none}ul.lst-kix_lqb82f5hzmh3-6{list-style-type:none}ul.lst-kix_lqb82f5hzmh3-5{list-style-type:none}ul.lst-kix_lqb82f5hzmh3-8{list-style-type:none}ul.lst-kix_lqb82f5hzmh3-7{list-style-type:none}.lst-kix_rop5sudr37z1-4>li:before{content:"\0025cb  "}.lst-kix_jbicnccaji3d-5>li:before{content:"\0025a0  "}.lst-kix_8d6owvwxykff-6>li:before{content:"\0025cf  "}ul.lst-kix_mfwegjdddisb-2{list-style-type:none}.lst-kix_msukp0gxz1c7-1>li:before{content:"\0025cb  "}ul.lst-kix_mfwegjdddisb-1{list-style-type:none}.lst-kix_rop5sudr37z1-7>li:before{content:"\0025cb  "}ul.lst-kix_mfwegjdddisb-0{list-style-type:none}.lst-kix_7pcs9kbg0qhi-0>li{counter-increment:lst-ctn-kix_7pcs9kbg0qhi-0}.lst-kix_3sh9r2c1w16g-4>li:before{content:"\0025cb  "}.lst-kix_8d6owvwxykff-3>li:before{content:"\0025cf  "}.lst-kix_g3mw20emt8ab-0>li:before{content:"\0025cf  "}.lst-kix_3sh9r2c1w16g-1>li:before{content:"\0025cb  "}.lst-kix_msukp0gxz1c7-4>li:before{content:"\0025cb  "}.lst-kix_rsr7bmzen4a7-1>li:before{content:"\0025cb  "}.lst-kix_6wlb53t5sfma-5>li:before{content:"\0025a0  "}.lst-kix_lqb82f5hzmh3-6>li:before{content:"\0025cf  "}ul.lst-kix_um8gcdc8t9m9-1{list-style-type:none}ul.lst-kix_um8gcdc8t9m9-2{list-style-type:none}ul.lst-kix_um8gcdc8t9m9-0{list-style-type:none}.lst-kix_3z0hr7pzpec4-4>li:before{content:"\0025cb  "}ul.lst-kix_um8gcdc8t9m9-5{list-style-type:none}ul.lst-kix_um8gcdc8t9m9-6{list-style-type:none}.lst-kix_38adif7m6rbx-3>li:before{content:"\0025cf  "}ul.lst-kix_um8gcdc8t9m9-3{list-style-type:none}ul.lst-kix_um8gcdc8t9m9-4{list-style-type:none}ul.lst-kix_6shy0i3drli2-7{list-style-type:none}ul.lst-kix_6shy0i3drli2-6{list-style-type:none}ul.lst-kix_um8gcdc8t9m9-7{list-style-type:none}ul.lst-kix_um8gcdc8t9m9-8{list-style-type:none}ul.lst-kix_6shy0i3drli2-8{list-style-type:none}.lst-kix_2aliey961vrg-8>li:before{content:"\0025a0  "}.lst-kix_s4rut6kfjze3-2>li:before{content:"\0025a0  "}.lst-kix_47504ojh0ba1-8>li:before{content:"\0025a0  "}.lst-kix_hait203o5dqo-7>li:before{content:"-  "}ul.lst-kix_6shy0i3drli2-3{list-style-type:none}.lst-kix_5gii2tr4ae90-7>li:before{content:"\0025cb  "}.lst-kix_mfwegjdddisb-0>li:before{content:"\0025cf  "}ul.lst-kix_6shy0i3drli2-2{list-style-type:none}.lst-kix_mfwegjdddisb-8>li:before{content:"\0025a0  "}ul.lst-kix_6shy0i3drli2-5{list-style-type:none}ul.lst-kix_6shy0i3drli2-4{list-style-type:none}.lst-kix_9i19e8txouig-7>li:before{content:"\0025cb  "}ul.lst-kix_6shy0i3drli2-1{list-style-type:none}ul.lst-kix_6shy0i3drli2-0{list-style-type:none}.lst-kix_3bekfbfd6o8j-4>li:before{content:"\0025cb  "}.lst-kix_7n1btf6e2iyv-4>li:before{content:"\0025cb  "}.lst-kix_ao97xhpq4hr9-2>li:before{content:"\0025a0  "}.lst-kix_9reixuath9e3-5>li:before{content:"\0025a0  "}ul.lst-kix_g3mw20emt8ab-8{list-style-type:none}.lst-kix_w93gux8gcekz-3>li:before{content:"-  "}.lst-kix_rj34zh1l62l0-8>li:before{content:"\0025a0  "}.lst-kix_r60cdwx1dlic-0>li:before{content:"\0025cf  "}.lst-kix_vd8i8whhh56x-1>li:before{content:"-  "}ul.lst-kix_g3mw20emt8ab-0{list-style-type:none}ul.lst-kix_g3mw20emt8ab-1{list-style-type:none}ul.lst-kix_g3mw20emt8ab-2{list-style-type:none}.lst-kix_dnm4ke3nhj1e-0>li:before{content:"\0025cf  "}ul.lst-kix_g3mw20emt8ab-3{list-style-type:none}ul.lst-kix_g3mw20emt8ab-4{list-style-type:none}.lst-kix_c4453ihcjob0-4>li:before{content:"\0025cb  "}ul.lst-kix_g3mw20emt8ab-5{list-style-type:none}ul.lst-kix_g3mw20emt8ab-6{list-style-type:none}ul.lst-kix_g3mw20emt8ab-7{list-style-type:none}.lst-kix_rj34zh1l62l0-0>li:before{content:"\0025cf  "}.lst-kix_9uzslqp6q29w-5>li:before{content:"\0025a0  "}.lst-kix_e8kaqrotva4-4>li:before{content:"\0025cb  "}.lst-kix_5iyzxwlmxp1f-5>li:before{content:"\0025a0  "}.lst-kix_47504ojh0ba1-0>li:before{content:"\0025cf  "}.lst-kix_6shy0i3drli2-1>li:before{content:"-  "}.lst-kix_8dw3ycrgt362-6>li:before{content:"" counter(lst-ctn-kix_8dw3ycrgt362-6,decimal) ". "}.lst-kix_mvnr2hoa94kd-7>li:before{content:"\0025cb  "}.lst-kix_ne2kodfi1kix-0>li:before{content:"\0025cf  "}ul.lst-kix_rc9zyflo7924-8{list-style-type:none}ul.lst-kix_rc9zyflo7924-7{list-style-type:none}ul.lst-kix_rj34zh1l62l0-7{list-style-type:none}ul.lst-kix_rc9zyflo7924-4{list-style-type:none}ul.lst-kix_rj34zh1l62l0-8{list-style-type:none}ul.lst-kix_rc9zyflo7924-3{list-style-type:none}ul.lst-kix_rc9zyflo7924-6{list-style-type:none}.lst-kix_r60cdwx1dlic-8>li:before{content:"\0025a0  "}ul.lst-kix_rc9zyflo7924-5{list-style-type:none}.lst-kix_5we8o0btcr67-8>li:before{content:"\0025a0  "}.lst-kix_5s83gilt2o7g-4>li:before{content:"\0025cb  "}ul.lst-kix_rj34zh1l62l0-3{list-style-type:none}ul.lst-kix_rc9zyflo7924-0{list-style-type:none}ul.lst-kix_rj34zh1l62l0-4{list-style-type:none}.lst-kix_owgllipbp8j5-1>li:before{content:"\0025cb  "}ul.lst-kix_rj34zh1l62l0-5{list-style-type:none}ul.lst-kix_rc9zyflo7924-2{list-style-type:none}ul.lst-kix_rj34zh1l62l0-6{list-style-type:none}ul.lst-kix_rc9zyflo7924-1{list-style-type:none}ul.lst-kix_rj34zh1l62l0-0{list-style-type:none}ul.lst-kix_rj34zh1l62l0-1{list-style-type:none}ul.lst-kix_rj34zh1l62l0-2{list-style-type:none}.lst-kix_rc9zyflo7924-0>li:before{content:"\0025cf  "}.lst-kix_rc9zyflo7924-2>li:before{content:"\0025a0  "}.lst-kix_rc9zyflo7924-3>li:before{content:"\0025cf  "}.lst-kix_rc9zyflo7924-1>li:before{content:"\0025cb  "}.lst-kix_8dw3ycrgt362-4>li{counter-increment:lst-ctn-kix_8dw3ycrgt362-4}ul.lst-kix_5s83gilt2o7g-0{list-style-type:none}ul.lst-kix_47504ojh0ba1-8{list-style-type:none}ul.lst-kix_5s83gilt2o7g-4{list-style-type:none}ul.lst-kix_5s83gilt2o7g-3{list-style-type:none}ul.lst-kix_5s83gilt2o7g-2{list-style-type:none}ul.lst-kix_5s83gilt2o7g-1{list-style-type:none}ul.lst-kix_5s83gilt2o7g-8{list-style-type:none}ul.lst-kix_5s83gilt2o7g-7{list-style-type:none}ul.lst-kix_5s83gilt2o7g-6{list-style-type:none}ul.lst-kix_5s83gilt2o7g-5{list-style-type:none}ul.lst-kix_47504ojh0ba1-2{list-style-type:none}ul.lst-kix_47504ojh0ba1-3{list-style-type:none}ul.lst-kix_47504ojh0ba1-0{list-style-type:none}ul.lst-kix_47504ojh0ba1-1{list-style-type:none}ul.lst-kix_47504ojh0ba1-6{list-style-type:none}ul.lst-kix_47504ojh0ba1-7{list-style-type:none}ul.lst-kix_47504ojh0ba1-4{list-style-type:none}ul.lst-kix_47504ojh0ba1-5{list-style-type:none}.lst-kix_rc9zyflo7924-8>li:before{content:"\0025a0  "}ol.lst-kix_7pcs9kbg0qhi-4.start{counter-reset:lst-ctn-kix_7pcs9kbg0qhi-4 0}.lst-kix_rc9zyflo7924-7>li:before{content:"\0025cb  "}.lst-kix_rc9zyflo7924-4>li:before{content:"\0025cb  "}.lst-kix_rc9zyflo7924-6>li:before{content:"\0025cf  "}.lst-kix_rc9zyflo7924-5>li:before{content:"\0025a0  "}.lst-kix_9reixuath9e3-6>li:before{content:"\0025cf  "}ol.lst-kix_8dw3ycrgt362-5{list-style-type:none}ol.lst-kix_8dw3ycrgt362-6{list-style-type:none}ol.lst-kix_8dw3ycrgt362-7{list-style-type:none}ol.lst-kix_8dw3ycrgt362-8{list-style-type:none}.lst-kix_9reixuath9e3-2>li:before{content:"\0025a0  "}.lst-kix_9reixuath9e3-8>li:before{content:"\0025a0  "}.lst-kix_9reixuath9e3-0>li:before{content:"\0025cf  "}.lst-kix_s4rut6kfjze3-7>li:before{content:"\0025cb  "}ul.lst-kix_6wlb53t5sfma-1{list-style-type:none}ul.lst-kix_6wlb53t5sfma-0{list-style-type:none}ul.lst-kix_6wlb53t5sfma-3{list-style-type:none}ul.lst-kix_6wlb53t5sfma-2{list-style-type:none}ol.lst-kix_7pcs9kbg0qhi-7{list-style-type:none}.lst-kix_47504ojh0ba1-5>li:before{content:"\0025a0  "}ol.lst-kix_7pcs9kbg0qhi-8{list-style-type:none}ul.lst-kix_6wlb53t5sfma-8{list-style-type:none}ol.lst-kix_7pcs9kbg0qhi-5{list-style-type:none}ol.lst-kix_7pcs9kbg0qhi-6{list-style-type:none}ul.lst-kix_6wlb53t5sfma-5{list-style-type:none}.lst-kix_47504ojh0ba1-3>li:before{content:"\0025cf  "}.lst-kix_47504ojh0ba1-7>li:before{content:"\0025cb  "}ul.lst-kix_6wlb53t5sfma-4{list-style-type:none}ul.lst-kix_6wlb53t5sfma-7{list-style-type:none}ul.lst-kix_3sh9r2c1w16g-8{list-style-type:none}.lst-kix_s4rut6kfjze3-3>li:before{content:"\0025cf  "}ul.lst-kix_6wlb53t5sfma-6{list-style-type:none}ul.lst-kix_3sh9r2c1w16g-7{list-style-type:none}.lst-kix_5gii2tr4ae90-8>li:before{content:"\0025a0  "}.lst-kix_47504ojh0ba1-1>li:before{content:"\0025cb  "}ol.lst-kix_8dw3ycrgt362-5.start{counter-reset:lst-ctn-kix_8dw3ycrgt362-5 0}.lst-kix_s4rut6kfjze3-5>li:before{content:"\0025a0  "}ol.lst-kix_8dw3ycrgt362-1{list-style-type:none}ul.lst-kix_3sh9r2c1w16g-6{list-style-type:none}ol.lst-kix_8dw3ycrgt362-2{list-style-type:none}ul.lst-kix_3sh9r2c1w16g-5{list-style-type:none}ol.lst-kix_8dw3ycrgt362-3{list-style-type:none}ul.lst-kix_3sh9r2c1w16g-4{list-style-type:none}ol.lst-kix_8dw3ycrgt362-4{list-style-type:none}.lst-kix_9reixuath9e3-4>li:before{content:"\0025cb  "}ul.lst-kix_3sh9r2c1w16g-3{list-style-type:none}ul.lst-kix_3sh9r2c1w16g-2{list-style-type:none}ul.lst-kix_3sh9r2c1w16g-1{list-style-type:none}ul.lst-kix_3sh9r2c1w16g-0{list-style-type:none}ol.lst-kix_8dw3ycrgt362-0{list-style-type:none}.lst-kix_s4rut6kfjze3-1>li:before{content:"\0025cb  "}.lst-kix_vd8i8whhh56x-2>li:before{content:"-  "}.lst-kix_vd8i8whhh56x-4>li:before{content:"-  "}ul.lst-kix_c4453ihcjob0-1{list-style-type:none}ul.lst-kix_c4453ihcjob0-2{list-style-type:none}ul.lst-kix_c4453ihcjob0-0{list-style-type:none}.lst-kix_rj34zh1l62l0-5>li:before{content:"\0025a0  "}ul.lst-kix_c4453ihcjob0-5{list-style-type:none}ul.lst-kix_c4453ihcjob0-6{list-style-type:none}ul.lst-kix_9reixuath9e3-0{list-style-type:none}ul.lst-kix_c4453ihcjob0-3{list-style-type:none}.lst-kix_5gii2tr4ae90-0>li:before{content:"\0025cf  "}ul.lst-kix_c4453ihcjob0-4{list-style-type:none}.lst-kix_vd8i8whhh56x-0>li:before{content:"-  "}.lst-kix_vd8i8whhh56x-6>li:before{content:"-  "}.lst-kix_vd8i8whhh56x-8>li:before{content:"-  "}ul.lst-kix_9reixuath9e3-2{list-style-type:none}ul.lst-kix_9reixuath9e3-1{list-style-type:none}ul.lst-kix_9reixuath9e3-4{list-style-type:none}ul.lst-kix_c4453ihcjob0-7{list-style-type:none}ul.lst-kix_9reixuath9e3-3{list-style-type:none}ul.lst-kix_c4453ihcjob0-8{list-style-type:none}.lst-kix_rj34zh1l62l0-7>li:before{content:"\0025cb  "}ul.lst-kix_9reixuath9e3-6{list-style-type:none}ul.lst-kix_9reixuath9e3-5{list-style-type:none}ul.lst-kix_9reixuath9e3-8{list-style-type:none}ul.lst-kix_9reixuath9e3-7{list-style-type:none}.lst-kix_5gii2tr4ae90-2>li:before{content:"\0025a0  "}.lst-kix_5gii2tr4ae90-4>li:before{content:"\0025cb  "}.lst-kix_5iyzxwlmxp1f-8>li:before{content:"\0025a0  "}.lst-kix_rj34zh1l62l0-1>li:before{content:"\0025cb  "}ol.lst-kix_7pcs9kbg0qhi-0{list-style-type:none}.lst-kix_5gii2tr4ae90-6>li:before{content:"\0025cf  "}.lst-kix_5iyzxwlmxp1f-6>li:before{content:"\0025cf  "}ol.lst-kix_7pcs9kbg0qhi-3{list-style-type:none}ol.lst-kix_7pcs9kbg0qhi-4{list-style-type:none}ol.lst-kix_7pcs9kbg0qhi-1{list-style-type:none}ol.lst-kix_7pcs9kbg0qhi-2{list-style-type:none}.lst-kix_rj34zh1l62l0-3>li:before{content:"\0025cf  "}.lst-kix_5iyzxwlmxp1f-0>li:before{content:"\0025cf  "}.lst-kix_5iyzxwlmxp1f-2>li:before{content:"\0025a0  "}.lst-kix_5iyzxwlmxp1f-4>li:before{content:"\0025cb  "}ul.lst-kix_rop5sudr37z1-0{list-style-type:none}ul.lst-kix_rop5sudr37z1-1{list-style-type:none}ul.lst-kix_rop5sudr37z1-2{list-style-type:none}ul.lst-kix_rop5sudr37z1-3{list-style-type:none}.lst-kix_8dw3ycrgt362-3>li{counter-increment:lst-ctn-kix_8dw3ycrgt362-3}.lst-kix_g3mw20emt8ab-6>li:before{content:"\0025cf  "}.lst-kix_owgllipbp8j5-0>li:before{content:"\0025cf  "}.lst-kix_g3mw20emt8ab-7>li:before{content:"\0025cb  "}.lst-kix_owgllipbp8j5-6>li:before{content:"\0025cf  "}.lst-kix_owgllipbp8j5-7>li:before{content:"\0025cb  "}.lst-kix_g3mw20emt8ab-2>li:before{content:"\0025a0  "}.lst-kix_g3mw20emt8ab-3>li:before{content:"\0025cf  "}ul.lst-kix_rop5sudr37z1-8{list-style-type:none}ul.lst-kix_rop5sudr37z1-4{list-style-type:none}ul.lst-kix_rop5sudr37z1-5{list-style-type:none}ul.lst-kix_rop5sudr37z1-6{list-style-type:none}ul.lst-kix_rop5sudr37z1-7{list-style-type:none}.lst-kix_8dw3ycrgt362-5>li{counter-increment:lst-ctn-kix_8dw3ycrgt362-5}.lst-kix_rop5sudr37z1-2>li:before{content:"\0025a0  "}.lst-kix_rop5sudr37z1-1>li:before{content:"\0025cb  "}.lst-kix_p3wa2k83s8cn-0>li:before{content:"\0025cf  "}.lst-kix_p3wa2k83s8cn-3>li:before{content:"\0025cf  "}.lst-kix_jbicnccaji3d-3>li:before{content:"\0025cf  "}.lst-kix_jbicnccaji3d-0>li:before{content:"\0025cf  "}.lst-kix_jbicnccaji3d-4>li:before{content:"\0025cb  "}.lst-kix_rsr7bmzen4a7-7>li:before{content:"\0025cb  "}ul.lst-kix_7n1btf6e2iyv-3{list-style-type:none}.lst-kix_rsr7bmzen4a7-4>li:before{content:"\0025cb  "}ul.lst-kix_7n1btf6e2iyv-2{list-style-type:none}.lst-kix_p3wa2k83s8cn-4>li:before{content:"\0025cb  "}ul.lst-kix_7n1btf6e2iyv-1{list-style-type:none}ul.lst-kix_7n1btf6e2iyv-0{list-style-type:none}.lst-kix_jbicnccaji3d-8>li:before{content:"\0025a0  "}.lst-kix_jbicnccaji3d-7>li:before{content:"\0025cb  "}.lst-kix_p3wa2k83s8cn-7>li:before{content:"\0025cb  "}ol.lst-kix_7pcs9kbg0qhi-5.start{counter-reset:lst-ctn-kix_7pcs9kbg0qhi-5 0}.lst-kix_3sh9r2c1w16g-6>li:before{content:"\0025cf  "}.lst-kix_rop5sudr37z1-6>li:before{content:"\0025cf  "}.lst-kix_rsr7bmzen4a7-8>li:before{content:"\0025a0  "}.lst-kix_3sh9r2c1w16g-7>li:before{content:"\0025cb  "}.lst-kix_p3wa2k83s8cn-8>li:before{content:"\0025a0  "}.lst-kix_rop5sudr37z1-5>li:before{content:"\0025a0  "}.lst-kix_3sh9r2c1w16g-3>li:before{content:"\0025cf  "}.lst-kix_3sh9r2c1w16g-2>li:before{content:"\0025a0  "}.lst-kix_rsr7bmzen4a7-3>li:before{content:"\0025cf  "}.lst-kix_rsr7bmzen4a7-0>li:before{content:"\0025cf  "}ul.lst-kix_r60cdwx1dlic-8{list-style-type:none}.lst-kix_2aliey961vrg-6>li:before{content:"\0025cf  "}.lst-kix_lqb82f5hzmh3-4>li:before{content:"\0025cb  "}ul.lst-kix_r60cdwx1dlic-5{list-style-type:none}ul.lst-kix_r60cdwx1dlic-4{list-style-type:none}ul.lst-kix_r60cdwx1dlic-7{list-style-type:none}.lst-kix_7pcs9kbg0qhi-1>li{counter-increment:lst-ctn-kix_7pcs9kbg0qhi-1}.lst-kix_9reixuath9e3-3>li:before{content:"\0025cf  "}.lst-kix_9reixuath9e3-7>li:before{content:"\0025cb  "}ul.lst-kix_r60cdwx1dlic-6{list-style-type:none}ul.lst-kix_r60cdwx1dlic-1{list-style-type:none}ul.lst-kix_r60cdwx1dlic-0{list-style-type:none}.lst-kix_2aliey961vrg-2>li:before{content:"\0025a0  "}ul.lst-kix_r60cdwx1dlic-3{list-style-type:none}ul.lst-kix_r60cdwx1dlic-2{list-style-type:none}.lst-kix_s4rut6kfjze3-8>li:before{content:"\0025a0  "}.lst-kix_38adif7m6rbx-5>li:before{content:"\0025a0  "}.lst-kix_lqb82f5hzmh3-0>li:before{content:"\0025cf  "}.lst-kix_s4rut6kfjze3-0>li:before{content:"\0025cf  "}ul.lst-kix_9i19e8txouig-8{list-style-type:none}ul.lst-kix_5we8o0btcr67-0{list-style-type:none}ul.lst-kix_9i19e8txouig-6{list-style-type:none}ul.lst-kix_9i19e8txouig-7{list-style-type:none}ul.lst-kix_9i19e8txouig-4{list-style-type:none}ul.lst-kix_5we8o0btcr67-3{list-style-type:none}.lst-kix_9i19e8txouig-5>li:before{content:"\0025a0  "}ul.lst-kix_9i19e8txouig-5{list-style-type:none}ul.lst-kix_5we8o0btcr67-4{list-style-type:none}ul.lst-kix_9i19e8txouig-2{list-style-type:none}ul.lst-kix_5we8o0btcr67-1{list-style-type:none}ul.lst-kix_9i19e8txouig-3{list-style-type:none}ul.lst-kix_5we8o0btcr67-2{list-style-type:none}.lst-kix_s4rut6kfjze3-4>li:before{content:"\0025cb  "}ul.lst-kix_9i19e8txouig-0{list-style-type:none}ul.lst-kix_5we8o0btcr67-7{list-style-type:none}ul.lst-kix_9i19e8txouig-1{list-style-type:none}ul.lst-kix_5we8o0btcr67-8{list-style-type:none}ul.lst-kix_5we8o0btcr67-5{list-style-type:none}.lst-kix_47504ojh0ba1-2>li:before{content:"\0025a0  "}ul.lst-kix_5we8o0btcr67-6{list-style-type:none}ul.lst-kix_7n1btf6e2iyv-7{list-style-type:none}ul.lst-kix_jbicnccaji3d-0{list-style-type:none}ul.lst-kix_7n1btf6e2iyv-6{list-style-type:none}ul.lst-kix_jbicnccaji3d-1{list-style-type:none}ul.lst-kix_7n1btf6e2iyv-5{list-style-type:none}ul.lst-kix_jbicnccaji3d-2{list-style-type:none}ul.lst-kix_7n1btf6e2iyv-4{list-style-type:none}ul.lst-kix_jbicnccaji3d-3{list-style-type:none}ul.lst-kix_7n1btf6e2iyv-8{list-style-type:none}ul.lst-kix_jbicnccaji3d-8{list-style-type:none}.lst-kix_3bekfbfd6o8j-2>li:before{content:"\0025a0  "}ul.lst-kix_jbicnccaji3d-4{list-style-type:none}.lst-kix_lqb82f5hzmh3-8>li:before{content:"\0025a0  "}ul.lst-kix_jbicnccaji3d-5{list-style-type:none}ul.lst-kix_jbicnccaji3d-6{list-style-type:none}.lst-kix_47504ojh0ba1-6>li:before{content:"\0025cf  "}ul.lst-kix_jbicnccaji3d-7{list-style-type:none}.lst-kix_c4453ihcjob0-6>li:before{content:"\0025cf  "}.lst-kix_c4453ihcjob0-2>li:before{content:"\0025a0  "}.lst-kix_rj34zh1l62l0-6>li:before{content:"\0025cf  "}.lst-kix_5gii2tr4ae90-1>li:before{content:"\0025cb  "}.lst-kix_vd8i8whhh56x-7>li:before{content:"-  "}.lst-kix_9i19e8txouig-1>li:before{content:"\0025cb  "}.lst-kix_rj34zh1l62l0-2>li:before{content:"\0025a0  "}ol.lst-kix_7pcs9kbg0qhi-8.start{counter-reset:lst-ctn-kix_7pcs9kbg0qhi-8 0}.lst-kix_5gii2tr4ae90-5>li:before{content:"\0025a0  "}.lst-kix_5iyzxwlmxp1f-7>li:before{content:"\0025cb  "}.lst-kix_6shy0i3drli2-3>li:before{content:"-  "}.lst-kix_6shy0i3drli2-7>li:before{content:"-  "}.lst-kix_7pcs9kbg0qhi-8>li{counter-increment:lst-ctn-kix_7pcs9kbg0qhi-8}.lst-kix_5iyzxwlmxp1f-3>li:before{content:"\0025cf  "}.lst-kix_38adif7m6rbx-1>li:before{content:"\0025cb  "}.lst-kix_owgllipbp8j5-3>li:before{content:"\0025cf  "}.lst-kix_vd8i8whhh56x-3>li:before{content:"-  "}ol.lst-kix_8dw3ycrgt362-4.start{counter-reset:lst-ctn-kix_8dw3ycrgt362-4 0}.lst-kix_7pcs9kbg0qhi-7>li:before{content:"" counter(lst-ctn-kix_7pcs9kbg0qhi-7,lower-latin) ". "}.lst-kix_7pcs9kbg0qhi-8>li:before{content:"" counter(lst-ctn-kix_7pcs9kbg0qhi-8,lower-roman) ". "}.lst-kix_7pcs9kbg0qhi-2>li:before{content:"" counter(lst-ctn-kix_7pcs9kbg0qhi-2,lower-roman) ". "}ol.lst-kix_7pcs9kbg0qhi-3.start{counter-reset:lst-ctn-kix_7pcs9kbg0qhi-3 0}.lst-kix_7pcs9kbg0qhi-5>li:before{content:"" counter(lst-ctn-kix_7pcs9kbg0qhi-5,lower-roman) ". "}.lst-kix_9sdxipg1h5wr-6>li:before{content:"\0025cf  "}.lst-kix_9sdxipg1h5wr-3>li:before{content:"\0025cf  "}.lst-kix_9sdxipg1h5wr-4>li:before{content:"\0025cb  "}.lst-kix_9sdxipg1h5wr-1>li:before{content:"\0025cb  "}.lst-kix_3bekfbfd6o8j-6>li:before{content:"\0025cf  "}.lst-kix_3bekfbfd6o8j-8>li:before{content:"\0025a0  "}.lst-kix_hait203o5dqo-5>li:before{content:"-  "}.lst-kix_hait203o5dqo-3>li:before{content:"-  "}.lst-kix_7pcs9kbg0qhi-6>li{counter-increment:lst-ctn-kix_7pcs9kbg0qhi-6}.lst-kix_hait203o5dqo-0>li:before{content:"-  "}.lst-kix_7pcs9kbg0qhi-0>li:before{content:"" counter(lst-ctn-kix_7pcs9kbg0qhi-0,decimal) ". "}.lst-kix_2aliey961vrg-1>li:before{content:"\0025cb  "}.lst-kix_2aliey961vrg-7>li:before{content:"\0025cb  "}.lst-kix_6wlb53t5sfma-4>li:before{content:"\0025cb  "}.lst-kix_6wlb53t5sfma-6>li:before{content:"\0025cf  "}.lst-kix_lqb82f5hzmh3-5>li:before{content:"\0025a0  "}.lst-kix_38adif7m6rbx-4>li:before{content:"\0025cb  "}.lst-kix_9i19e8txouig-8>li:before{content:"\0025a0  "}.lst-kix_hait203o5dqo-6>li:before{content:"-  "}.lst-kix_e8kaqrotva4-5>li:before{content:"\0025a0  "}.lst-kix_hait203o5dqo-8>li:before{content:"-  "}.lst-kix_9i19e8txouig-6>li:before{content:"\0025cf  "}.lst-kix_3bekfbfd6o8j-5>li:before{content:"\0025a0  "}.lst-kix_lqb82f5hzmh3-7>li:before{content:"\0025cb  "}.lst-kix_3bekfbfd6o8j-3>li:before{content:"\0025cf  "}.lst-kix_w93gux8gcekz-2>li:before{content:"-  "}.lst-kix_c4453ihcjob0-5>li:before{content:"\0025a0  "}.lst-kix_r60cdwx1dlic-1>li:before{content:"\0025cb  "}.lst-kix_c4453ihcjob0-3>li:before{content:"\0025cf  "}.lst-kix_9uzslqp6q29w-6>li:before{content:"\0025cf  "}.lst-kix_9i19e8txouig-0>li:before{content:"\0025cf  "}.lst-kix_mvnr2hoa94kd-6>li:before{content:"\0025cf  "}.lst-kix_w93gux8gcekz-4>li:before{content:"-  "}.lst-kix_e8kaqrotva4-3>li:before{content:"\0025cf  "}ol.lst-kix_7pcs9kbg0qhi-1.start{counter-reset:lst-ctn-kix_7pcs9kbg0qhi-1 0}.lst-kix_6shy0i3drli2-2>li:before{content:"-  "}.lst-kix_mvnr2hoa94kd-8>li:before{content:"\0025a0  "}.lst-kix_6shy0i3drli2-8>li:before{content:"-  "}.lst-kix_6shy0i3drli2-0>li:before{content:"-  "}.lst-kix_38adif7m6rbx-2>li:before{content:"\0025a0  "}ol.lst-kix_8dw3ycrgt362-6.start{counter-reset:lst-ctn-kix_8dw3ycrgt362-6 0}.lst-kix_r60cdwx1dlic-7>li:before{content:"\0025cb  "}.lst-kix_owgllipbp8j5-2>li:before{content:"\0025a0  "}.lst-kix_5s83gilt2o7g-8>li:before{content:"\0025a0  "}ol.lst-kix_7pcs9kbg0qhi-0.start{counter-reset:lst-ctn-kix_7pcs9kbg0qhi-0 0}.lst-kix_owgllipbp8j5-5>li:before{content:"\0025a0  "}.lst-kix_owgllipbp8j5-8>li:before{content:"\0025a0  "}.lst-kix_5we8o0btcr67-4>li:before{content:"\0025cb  "}.lst-kix_hm0ybxxbxp2l-8>li:before{content:"\0025a0  "}.lst-kix_msukp0gxz1c7-8>li:before{content:"\0025a0  "}.lst-kix_g3mw20emt8ab-1>li:before{content:"\0025cb  "}.lst-kix_5we8o0btcr67-1>li:before{content:"\0025cb  "}.lst-kix_g3mw20emt8ab-4>li:before{content:"\0025cb  "}ul.lst-kix_9uzslqp6q29w-0{list-style-type:none}.lst-kix_hm0ybxxbxp2l-0>li:before{content:"\0025cf  "}ul.lst-kix_9uzslqp6q29w-1{list-style-type:none}.lst-kix_9uzslqp6q29w-1>li:before{content:"\0025cb  "}.lst-kix_mvnr2hoa94kd-3>li:before{content:"\0025cf  "}.lst-kix_mvnr2hoa94kd-0>li:before{content:"\0025cf  "}.lst-kix_hm0ybxxbxp2l-5>li:before{content:"\0025a0  "}.lst-kix_rop5sudr37z1-0>li:before{content:"\0025cf  "}ol.lst-kix_8dw3ycrgt362-1.start{counter-reset:lst-ctn-kix_8dw3ycrgt362-1 0}ul.lst-kix_e8kaqrotva4-7{list-style-type:none}ul.lst-kix_e8kaqrotva4-8{list-style-type:none}ul.lst-kix_e8kaqrotva4-5{list-style-type:none}ul.lst-kix_e8kaqrotva4-6{list-style-type:none}ul.lst-kix_e8kaqrotva4-3{list-style-type:none}ul.lst-kix_e8kaqrotva4-4{list-style-type:none}ul.lst-kix_e8kaqrotva4-1{list-style-type:none}ul.lst-kix_e8kaqrotva4-2{list-style-type:none}.lst-kix_p3wa2k83s8cn-1>li:before{content:"\0025cb  "}ul.lst-kix_e8kaqrotva4-0{list-style-type:none}.lst-kix_jbicnccaji3d-1>li:before{content:"\0025cb  "}.lst-kix_p3wa2k83s8cn-6>li:before{content:"\0025cf  "}.lst-kix_rsr7bmzen4a7-5>li:before{content:"\0025a0  "}.lst-kix_8dw3ycrgt362-7>li{counter-increment:lst-ctn-kix_8dw3ycrgt362-7}.lst-kix_rop5sudr37z1-3>li:before{content:"\0025cf  "}ul.lst-kix_9uzslqp6q29w-8{list-style-type:none}ol.lst-kix_8dw3ycrgt362-2.start{counter-reset:lst-ctn-kix_8dw3ycrgt362-2 0}ul.lst-kix_9uzslqp6q29w-6{list-style-type:none}ul.lst-kix_9uzslqp6q29w-7{list-style-type:none}ul.lst-kix_9uzslqp6q29w-4{list-style-type:none}ul.lst-kix_9uzslqp6q29w-5{list-style-type:none}ul.lst-kix_9uzslqp6q29w-2{list-style-type:none}.lst-kix_jbicnccaji3d-6>li:before{content:"\0025cf  "}ul.lst-kix_9uzslqp6q29w-3{list-style-type:none}.lst-kix_rop5sudr37z1-8>li:before{content:"\0025a0  "}ul.lst-kix_vd8i8whhh56x-7{list-style-type:none}ul.lst-kix_vd8i8whhh56x-6{list-style-type:none}.lst-kix_msukp0gxz1c7-0>li:before{content:"\0025cf  "}ul.lst-kix_vd8i8whhh56x-5{list-style-type:none}ul.lst-kix_vd8i8whhh56x-4{list-style-type:none}ul.lst-kix_vd8i8whhh56x-8{list-style-type:none}.lst-kix_3sh9r2c1w16g-5>li:before{content:"\0025a0  "}.lst-kix_8d6owvwxykff-2>li:before{content:"\0025a0  "}.lst-kix_rsr7bmzen4a7-2>li:before{content:"\0025a0  "}ul.lst-kix_2aliey961vrg-7{list-style-type:none}ul.lst-kix_2aliey961vrg-6{list-style-type:none}.lst-kix_3sh9r2c1w16g-0>li:before{content:"\0025cf  "}ul.lst-kix_2aliey961vrg-8{list-style-type:none}.lst-kix_msukp0gxz1c7-5>li:before{content:"\0025a0  "}ul.lst-kix_2aliey961vrg-3{list-style-type:none}ul.lst-kix_2aliey961vrg-2{list-style-type:none}ul.lst-kix_2aliey961vrg-5{list-style-type:none}ul.lst-kix_2aliey961vrg-4{list-style-type:none}ul.lst-kix_2aliey961vrg-1{list-style-type:none}ul.lst-kix_2aliey961vrg-0{list-style-type:none}.lst-kix_8d6owvwxykff-7>li:before{content:"\0025cb  "}ul.lst-kix_vd8i8whhh56x-3{list-style-type:none}ul.lst-kix_vd8i8whhh56x-2{list-style-type:none}ul.lst-kix_vd8i8whhh56x-1{list-style-type:none}ul.lst-kix_vd8i8whhh56x-0{list-style-type:none}.lst-kix_lqb82f5hzmh3-2>li:before{content:"\0025a0  "}.lst-kix_6wlb53t5sfma-1>li:before{content:"\0025cb  "}ul.lst-kix_mvnr2hoa94kd-8{list-style-type:none}.lst-kix_ao97xhpq4hr9-6>li:before{content:"\0025cf  "}.lst-kix_2aliey961vrg-4>li:before{content:"\0025cb  "}.lst-kix_9reixuath9e3-1>li:before{content:"\0025cb  "}.lst-kix_7n1btf6e2iyv-0>li:before{content:"\0025cf  "}ul.lst-kix_mvnr2hoa94kd-0{list-style-type:none}ul.lst-kix_mvnr2hoa94kd-1{list-style-type:none}ul.lst-kix_mvnr2hoa94kd-2{list-style-type:none}.lst-kix_7pcs9kbg0qhi-2>li{counter-increment:lst-ctn-kix_7pcs9kbg0qhi-2}ul.lst-kix_mvnr2hoa94kd-3{list-style-type:none}ul.lst-kix_mvnr2hoa94kd-4{list-style-type:none}ul.lst-kix_mvnr2hoa94kd-5{list-style-type:none}ul.lst-kix_mvnr2hoa94kd-6{list-style-type:none}ul.lst-kix_mvnr2hoa94kd-7{list-style-type:none}.lst-kix_38adif7m6rbx-7>li:before{content:"\0025cb  "}.lst-kix_3z0hr7pzpec4-8>li:before{content:"\0025a0  "}.lst-kix_7n1btf6e2iyv-8>li:before{content:"\0025a0  "}.lst-kix_mfwegjdddisb-4>li:before{content:"\0025cb  "}.lst-kix_3sh9r2c1w16g-8>li:before{content:"\0025a0  "}.lst-kix_3bekfbfd6o8j-0>li:before{content:"\0025cf  "}.lst-kix_e8kaqrotva4-8>li:before{content:"\0025a0  "}.lst-kix_47504ojh0ba1-4>li:before{content:"\0025cb  "}.lst-kix_s4rut6kfjze3-6>li:before{content:"\0025cf  "}.lst-kix_c4453ihcjob0-0>li:before{content:"\0025cf  "}ul.lst-kix_3bekfbfd6o8j-7{list-style-type:none}ul.lst-kix_3bekfbfd6o8j-8{list-style-type:none}ul.lst-kix_3bekfbfd6o8j-5{list-style-type:none}ul.lst-kix_3bekfbfd6o8j-6{list-style-type:none}ul.lst-kix_3bekfbfd6o8j-3{list-style-type:none}.lst-kix_dnm4ke3nhj1e-4>li:before{content:"\0025cb  "}ul.lst-kix_3bekfbfd6o8j-4{list-style-type:none}ul.lst-kix_3bekfbfd6o8j-1{list-style-type:none}ul.lst-kix_3bekfbfd6o8j-2{list-style-type:none}ul.lst-kix_ao97xhpq4hr9-0{list-style-type:none}.lst-kix_r60cdwx1dlic-4>li:before{content:"\0025cb  "}ul.lst-kix_3bekfbfd6o8j-0{list-style-type:none}.lst-kix_vd8i8whhh56x-5>li:before{content:"-  "}ul.lst-kix_ao97xhpq4hr9-2{list-style-type:none}ul.lst-kix_ao97xhpq4hr9-1{list-style-type:none}ul.lst-kix_ao97xhpq4hr9-4{list-style-type:none}.lst-kix_w93gux8gcekz-7>li:before{content:"-  "}ul.lst-kix_ao97xhpq4hr9-3{list-style-type:none}ul.lst-kix_ao97xhpq4hr9-6{list-style-type:none}ul.lst-kix_ao97xhpq4hr9-5{list-style-type:none}ul.lst-kix_ao97xhpq4hr9-8{list-style-type:none}ul.lst-kix_ao97xhpq4hr9-7{list-style-type:none}.lst-kix_e8kaqrotva4-0>li:before{content:"\0025cf  "}.lst-kix_5gii2tr4ae90-3>li:before{content:"\0025cf  "}.lst-kix_rj34zh1l62l0-4>li:before{content:"\0025cb  "}.lst-kix_9i19e8txouig-3>li:before{content:"\0025cf  "}.lst-kix_c4453ihcjob0-8>li:before{content:"\0025a0  "}.lst-kix_6shy0i3drli2-5>li:before{content:"-  "}.lst-kix_8dw3ycrgt362-2>li:before{content:"" counter(lst-ctn-kix_8dw3ycrgt362-2,lower-roman) ". "}.lst-kix_5iyzxwlmxp1f-1>li:before{content:"\0025cb  "}.lst-kix_5s83gilt2o7g-0>li:before{content:"\0025cf  "}.lst-kix_ne2kodfi1kix-4>li:before{content:"\0025cb  "}ol.lst-kix_8dw3ycrgt362-0.start{counter-reset:lst-ctn-kix_8dw3ycrgt362-0 0}.lst-kix_3z0hr7pzpec4-0>li:before{content:"\0025cf  "}ol{margin:0;padding:0}table td,table th{padding:0}.c78{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#cfe2f3;border-left-style:solid;border-bottom-width:1pt;width:105.8pt;border-top-color:#000000;border-bottom-style:solid}.c82{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#cfe2f3;border-left-style:solid;border-bottom-width:1pt;width:122.2pt;border-top-color:#000000;border-bottom-style:solid}.c8{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:128.2pt;border-top-color:#000000;border-bottom-style:solid}.c70{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:161.2pt;border-top-color:#000000;border-bottom-style:solid}.c115{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:135pt;border-top-color:#000000;border-bottom-style:solid}.c21{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:105.8pt;border-top-color:#000000;border-bottom-style:solid}.c11{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:276pt;border-top-color:#000000;border-bottom-style:solid}.c95{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:239.2pt;border-top-color:#000000;border-bottom-style:solid}.c74{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#ffffff;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:170.1pt;border-top-color:#000000;border-bottom-style:solid}.c25{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:239.2pt;border-top-color:#000000;border-bottom-style:solid}.c110{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:128.2pt;border-top-color:#000000;border-bottom-style:solid}.c57{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:98.2pt;border-top-color:#000000;border-bottom-style:solid}.c17{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:149.2pt;border-top-color:#000000;border-bottom-style:solid}.c108{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:239.2pt;border-top-color:#000000;border-bottom-style:solid}.c100{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:170.1pt;border-top-color:#ffffff;border-bottom-style:solid}.c107{border-right-style:solid;padding:8.5pt 8.5pt 8.5pt 8.5pt;border-bottom-color:#d9d9d9;border-top-width:1pt;border-right-width:1pt;border-left-color:#d9d9d9;vertical-align:top;border-right-color:#d9d9d9;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:330pt;border-top-color:#d9d9d9;border-bottom-style:solid}.c14{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:122.2pt;border-top-color:#000000;border-bottom-style:solid}.c109{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:276pt;border-top-color:#000000;border-bottom-style:solid}.c63{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:170.1pt;border-top-color:#000000;border-bottom-style:solid}.c92{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:161.2pt;border-top-color:#000000;border-bottom-style:solid}.c105{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:149.2pt;border-top-color:#000000;border-bottom-style:solid}.c106{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:510.8pt;border-top-color:#000000;border-bottom-style:solid}.c93{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:213pt;border-top-color:#000000;border-bottom-style:solid}.c47{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:114pt;border-top-color:#000000;border-bottom-style:solid}.c54{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:135pt;border-top-color:#000000;border-bottom-style:solid}.c28{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:510.2pt;border-top-color:#000000;border-bottom-style:solid}.c37{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:213pt;border-top-color:#000000;border-bottom-style:solid}.c19{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:510pt;border-top-color:#000000;border-bottom-style:solid}.c59{padding-top:6pt;border-top-width:1pt;border-bottom-color:#0b5394;padding-bottom:6pt;line-height:1.0;border-top-style:solid;background-color:#e7f3fd;text-indent:10.1pt;border-bottom-width:1pt;border-top-color:#0b5394;border-bottom-style:solid;text-align:left}.c27{-webkit-text-decoration-skip:none;color:#1155cc;font-weight:400;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:10pt;font-family:"Arial";font-style:normal}.c48{-webkit-text-decoration-skip:none;color:#666666;font-weight:400;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:12pt;font-family:"Trebuchet MS";font-style:normal}.c1{margin-left:36pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c31{padding-top:8pt;border-bottom-color:#3c78d8;border-bottom-width:1pt;padding-bottom:0pt;line-height:1.0;border-bottom-style:solid;page-break-after:avoid;text-align:left}.c9{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Inconsolata";font-style:normal}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c86{color:#666666;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Georgia";font-style:italic}.c22{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Consolas";font-style:normal}.c7{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c6{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c12{color:#24292e;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Inconsolata";font-style:normal}.c42{color:#45818e;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Trebuchet MS";font-style:normal}.c67{color:#3c78d8;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Trebuchet MS";font-style:normal}.c26{background-color:#ffffff;color:#0000ff;text-decoration:none;vertical-align:baseline;font-size:10pt;font-style:normal}.c97{color:#1c4587;text-decoration:none;vertical-align:baseline;font-size:30pt;font-family:"Trebuchet MS";font-style:normal}.c33{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c3{text-decoration-skip-ink:none;font-size:9pt;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c40{color:#0000ff;text-decoration:none;vertical-align:baseline;font-size:10pt;font-style:normal}.c23{padding-top:6pt;padding-bottom:3pt;line-height:1.0;page-break-after:avoid;text-align:left}.c41{color:#000000;text-decoration:none;vertical-align:baseline;font-size:8pt;font-style:normal}.c94{text-decoration:none;vertical-align:baseline;font-size:18pt;font-family:"Trebuchet MS";font-style:normal}.c55{background-color:#ffffff;color:#24292e;text-decoration:none;vertical-align:baseline;font-style:normal}.c24{margin-left:18pt;padding-top:3pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c72{color:#0000ff;text-decoration:none;vertical-align:baseline;font-size:11pt;font-style:normal}.c46{margin-left:36pt;padding-top:3pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c60{margin-left:54pt;padding-top:3pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c83{color:#ff0000;text-decoration:none;vertical-align:baseline;font-size:11pt;font-style:normal}.c102{margin-left:36pt;padding-top:3pt;padding-bottom:4pt;line-height:1.0;text-align:left}.c32{color:#24292e;text-decoration:none;vertical-align:baseline;font-size:10pt;font-style:normal}.c64{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:center}.c30{border-spacing:0;border-collapse:collapse;margin-right:auto}.c34{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:center}.c91{color:#000000;text-decoration:none;vertical-align:baseline;font-style:italic}.c16{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c53{color:#000000;text-decoration:none;vertical-align:baseline;font-style:normal}.c50{font-weight:400;vertical-align:baseline;font-family:"Arial";font-style:normal}.c4{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c75{padding-top:4pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c38{padding-top:0pt;padding-bottom:0pt;line-height:1.4285714285714286;text-align:left}.c84{padding-top:10pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c111{margin-left:auto;border-spacing:0;border-collapse:collapse;margin-right:auto}.c43{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c79{margin-left:-1.5pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c76{background-color:#ecf0f3;font-style:italic;color:#222222}.c44{background-color:#ffffff;max-width:510.2pt;padding:21.3pt 42.5pt 21.3pt 42.5pt}.c52{background-color:#ffffff;font-style:italic;color:#3e4349}.c114{color:#ff0000;vertical-align:baseline;font-family:"Georgia"}.c35{font-weight:400;font-family:"Consolas"}.c10{orphans:2;widows:2}.c39{font-size:10pt;color:#24292e}.c2{color:inherit;text-decoration:inherit}.c18{padding:0;margin:0}.c66{font-weight:400;font-family:"Arial"}.c56{font-weight:400;font-family:"Courier New"}.c71{margin-left:72pt;padding-left:0pt}.c98{text-decoration:none;font-size:11pt}.c81{margin-left:108pt;padding-left:0pt}.c13{font-weight:400;font-family:"Inconsolata"}.c58{background-color:#ffffff}.c89{height:22pt}.c99{color:#032f62}.c112{font-size:12pt}.c103{height:19pt}.c5{height:0pt}.c90{color:#d73a49}.c36{font-weight:700}.c29{height:11pt}.c69{height:33pt}.c45{font-size:10pt}.c68{height:54pt}.c101{font-style:italic}.c104{background-color:#d9d9d9}.c49{page-break-after:avoid}.c85{height:21pt}.c20{height:15pt}.c77{color:#24292e}.c88{background-color:#cfe2f3}.c65{height:16pt}.c51{height:24pt}.c80{height:44pt}.c15{font-size:9pt}.c87{height:26pt}.c62{color:#1155cc}.c73{color:#0000ff}.c96{height:12pt}.c113{height:116.2pt}.c61{height:14pt}.title{padding-top:0pt;color:#1c4587;font-weight:700;font-size:30pt;padding-bottom:0pt;font-family:"Trebuchet MS";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:11pt;padding-bottom:0pt;font-family:"Georgia";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:6pt;color:#1155cc;border-top-width:1pt;border-bottom-color:#0b5394;font-weight:700;font-size:18pt;padding-bottom:6pt;line-height:1.0;page-break-after:avoid;border-top-style:solid;background-color:#e7f3fd;border-bottom-width:1pt;border-top-color:#0b5394;font-family:"Trebuchet MS";border-bottom-style:solid;orphans:2;widows:2;text-align:left}h2{padding-top:8pt;color:#3c78d8;border-bottom-color:#3c78d8;font-weight:700;font-size:16pt;padding-bottom:0pt;line-height:1.0;page-break-after:avoid;border-bottom-width:1pt;font-family:"Trebuchet MS";border-bottom-style:solid;orphans:2;widows:2;text-align:left}h3{padding-top:6pt;color:#45818e;font-weight:700;font-size:14pt;padding-bottom:3pt;font-family:"Trebuchet MS";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:6pt;-webkit-text-decoration-skip:none;color:#666666;text-decoration:underline;font-size:12pt;padding-bottom:3pt;line-height:1.0;page-break-after:avoid;text-decoration-skip-ink:none;font-family:"Trebuchet MS";orphans:2;widows:2;text-align:left}h5{padding-top:6pt;color:#777777;font-weight:700;font-size:11pt;padding-bottom:3pt;font-family:"Trebuchet MS";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:6pt;color:#666666;font-size:11pt;padding-bottom:3pt;font-family:"Trebuchet MS";line-height:1.0;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c44"><p class="c4 c10 c49 title" id="h.tc504ybtnf8q"><span class="c36 c97">Framework Migration Guide</span></p><p class="c4 c10 c49 subtitle" id="h.4pdauswx7nci"><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://chainer.github.io/migration-guide/&amp;sa=D&amp;ust=1578461385067000">https://chainer.github.io/migration-guide/</a></span></p><p class="c4 c10 c49 subtitle" id="h.4ooc9p4a0bty"><span>Authors: Chainer Team</span></p><p class="c4 c10 c29"><span class="c6"></span></p><a id="t.b6c3151b065c41d1a077ec06541d8e5348b9d199"></a><a id="t.0"></a><table class="c30"><tbody><tr class="c5"><td class="c107" colspan="1" rowspan="1"><p class="c16 c29"><span class="c53 c66 c45"></span></p><p class="c10 c75"><span class="c27"><a class="c2" href="#h.6qt1ntczqwrx">General Information</a></span></p><p class="c24 c10"><span class="c27"><a class="c2" href="#h.r2o0yn30s8tq">Concepts and components in both frameworks</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.ms7vvkoz6vru">Array Library</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.8z53kzu8pby0">Core Framework and Training Loop</a></span></p><p class="c24 c10"><span class="c27"><a class="c2" href="#h.y7ovx8en8cp7">Migration scenarios</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.e88d7eicrcd0">I want to port my Chainer script to PyTorch, step by step</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.8w1snpmhh4kj">I want to let my Chainer code train a PyTorch model</a></span></p><p class="c10 c24"><span class="c27"><a class="c2" href="#h.9wc1iaeyqb2c">Migration tools (cpm)</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.im0z6zf5ujzw">cpm.TorchModule</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.pflkcrjo8y89">cpm.ChainerParameter</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.46et3pwf65s">cpm.LinkAsTorchModel</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.49ptm66ugzcy">cpm.ignite.add_trainer_extension</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.207juqqyebo8">cpm.use_torch_in_cupy_malloc</a></span></p><p class="c10 c84"><span class="c27"><a class="c2" href="#h.9eib52bt6ke5">Porting Guides</a></span></p><p class="c24 c10"><span class="c27"><a class="c2" href="#h.7u4t6laltff5">Dataset and data pre/post-processing</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.tw9winyigiz6">Negative strides</a></span></p><p class="c46 c10"><span class="c43 c45"><a class="c2" href="#h.iu5zwqbulp2u">Rewriting Custom Converter Functions to collate_fn</a></span></p><p class="c46 c10"><span class="c43 c45"><a class="c2" href="#h.5zvn9j4xwu6j">NumPy bridge</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.84jg73vglm0b">CuPy bridge</a></span></p><p class="c46 c10"><span class="c43 c45"><a class="c2" href="#h.uohx43j9p18u">Difference between PyTorch and NumPy/CuPy</a></span></p><p class="c60 c10"><span class="c43 c45"><a class="c2" href="#h.6qe1h751g6oj">Division Behavior</a></span></p><p class="c60 c10"><span class="c43 c45"><a class="c2" href="#h.br8vew20r7k">Feature Mapping</a></span></p><p class="c24 c10"><span class="c27"><a class="c2" href="#h.h1ei3avajrbn">Training loop</a></span></p><p class="c24 c10"><span class="c27"><a class="c2" href="#h.3b2g5rapv9ec">Evaluation loop</a></span></p><p class="c24 c10"><span class="c27"><a class="c2" href="#h.wanb8rb4d6lo">Training and evaluation using Ignite</a></span></p><p class="c24 c10"><span class="c27"><a class="c2" href="#h.m8sz4mg7ioxl">Using Chainer extensions with Ignite</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.ojt9418jpkms">Snapshots</a></span></p><p class="c24 c10"><span class="c27"><a class="c2" href="#h.s8lyt5panb7">Porting custom updater using Ignite</a></span></p><p class="c24 c10"><span class="c27"><a class="c2" href="#h.xmsyb5asd2c9">Rewriting existing Chainer model</a></span></p><p class="c24 c10"><span class="c27"><a class="c2" href="#h.mkuuagm60br0">Functions and Links</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.e17stx2v9ds3">Functions</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.ryz2089jygqa">Links</a></span></p><p class="c24 c10"><span class="c27"><a class="c2" href="#h.hb9kqa7i3enr">Configuration</a></span></p><p class="c24 c10"><span class="c27"><a class="c2" href="#h.rxt9pteccajv">Hooks</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.gsgtoxixjcm4">Function Hooks</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.rvlhszhkp1bw">Link Hooks</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.5a204an0cllk">Optimizer Hooks</a></span></p><p class="c24 c10"><span class="c27"><a class="c2" href="#h.79n4spowwnun">Training PyTorch model using Chainer</a></span></p><p class="c24 c10"><span class="c27"><a class="c2" href="#h.33jrfcvcf9zh">Distributed training</a></span></p><p class="c10 c46"><span class="c27"><a class="c2" href="#h.iyhfmfndl13j">Pytorch model using torch.distributed</a></span></p><p class="c60 c10"><span class="c27"><a class="c2" href="#h.moliknyk6ru3">Invocation</a></span></p><p class="c60 c10"><span class="c27"><a class="c2" href="#h.7r5y5xoqrywb">Initialization</a></span></p><p class="c60 c10"><span class="c27"><a class="c2" href="#h.nzh1eoy3bny9">Dataset scattering</a></span></p><p class="c60 c10"><span class="c27"><a class="c2" href="#h.kyzvorr2x2ij">Data transfer to devices</a></span></p><p class="c60 c10"><span class="c27"><a class="c2" href="#h.s0hd5ycxwpdh">Optimizer wrapping</a></span></p><p class="c60 c10"><span class="c27"><a class="c2" href="#h.d1nulkakooh">Initial values broadcast</a></span></p><p class="c60 c10"><span class="c27"><a class="c2" href="#h.x5dny5mqq9px">Metrics average and reductions</a></span></p><p class="c60 c10"><span class="c27"><a class="c2" href="#h.5t9pfndndqnr">https://pytorch.org/docs/stable/distributed.html#multi-gpu-collective-functions</a></span></p><p class="c60 c10"><span class="c27"><a class="c2" href="#h.3lb7ncfjheoo">Synchronization</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.dis62849w9cz">PyTorch model using Horovod</a></span></p><p class="c60 c10"><span class="c27"><a class="c2" href="#h.tje6mmfdx3pf">Horovod initialization</a></span></p><p class="c60 c10"><span class="c27"><a class="c2" href="#h.37g288q2db5i">Dataset scattering</a></span></p><p class="c60 c10"><span class="c27"><a class="c2" href="#h.z7g1nmbbb3uh">Optimizer wrapping</a></span></p><p class="c60 c10"><span class="c27"><a class="c2" href="#h.gq621f9b16zf">Initial values broadcast</a></span></p><p class="c60 c10"><span class="c27"><a class="c2" href="#h.9t9k4lfat6t2">Metrics average and reductions</a></span></p><p class="c10 c60"><span class="c27"><a class="c2" href="#h.bfpbumwh7xzs">Horovod code structure</a></span></p><p class="c60 c10"><span class="c27"><a class="c2" href="#h.apxtaciyccdc">Obtaining Horovod traces to measure performance</a></span></p><p class="c60 c10"><span class="c27"><a class="c2" href="#h.9jn0jqinrgx3">Tuning Horovod performance</a></span></p><p class="c60 c10"><span class="c27"><a class="c2" href="#h.wuax6jpon8sy">Using Horovod with apex</a></span></p><p class="c60 c10"><span class="c43 c45"><a class="c2" href="#h.pdah33gpi4li">Multi-Node Batch Normalization in Horovod</a></span></p><p class="c60 c10"><span class="c43 c45"><a class="c2" href="#h.eqj7dzgbr9y7">Gathering arbitrary objects using Horovod and mpi4py</a></span></p><p class="c60 c10"><span class="c27"><a class="c2" href="#h.y8eom3uzrv56">Alternatives to Horovod</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.qfxp9de828j4">Chainer model using Horovod</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.vlwpxcx5nw9c">PyTorch model using ChainerMN</a></span></p><p class="c24 c10"><span class="c27"><a class="c2" href="#h.2jl4lfh90jqb">Porting code that edits the computational graph</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.gbqjtjbzzzno">Unchaining nodes</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.mc69ie7hbl6j">Backprop modes</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.bka3yqtw2rpy">Train/Test modes</a></span></p><p class="c84 c10"><span class="c27"><a class="c2" href="#h.r8th8e47f02c">Ecosystem</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.d863gr6235hf">PyTorch</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.w69092dw2rtl">Ignite</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.b2r58wgcvv09">torchvision</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.ctcyjos25n6z">torchtext</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.l9nxjlcurusl">torchaudio</a></span></p><p class="c46 c10"><span class="c27"><a class="c2" href="#h.p90hj6w1ucn0">Fairseq</a></span></p><p class="c10 c102"><span class="c27"><a class="c2" href="#h.eaofa6s7sf0k">Other</a></span></p><p class="c16 c29"><span class="c53 c66 c45"></span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span class="c6">This document provides technical information for migration from Chainer to PyTorch.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><h1 class="c59 c10 c49" id="h.6qt1ntczqwrx"><span class="c36 c62 c94">General Information</span></h1><h2 class="c31 c10" id="h.r2o0yn30s8tq"><span class="c67 c36">Concepts and components in both frameworks</span></h2><h3 class="c23 c10" id="h.ms7vvkoz6vru"><span class="c42 c36">Array Library</span></h3><p class="c4 c10"><span>Chainer uses NumPy/CuPy (</span><span class="c35">xp.ndarray</span><span>) as an array library, and wraps them as </span><span class="c35">chainer.Variable</span><span>&nbsp;to support autograd. Similarly, PyTorch uses </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/cppdocs/%23aten&amp;sa=D&amp;ust=1578461385090000">ATen</a></span><span>&nbsp;(</span><span class="c35">at::Tensor</span><span>&nbsp;(C++)) as an array library (&quot;tensor library&quot; in PyTorch terms), and wraps it as </span><span class="c35">torch::Tensor</span><span>&nbsp;(C++ API) / </span><span class="c35">torch.Tensor</span><span>&nbsp;(Python API) to support autograd. </span><span class="c35">torch.*</span><span>&nbsp;provides API similar to (but not compatible with) NumPy, e.g. </span><span class="c35">torch.dot, torch.float32</span><span class="c6">, etc.</span></p><h3 class="c23 c10" id="h.8z53kzu8pby0"><span class="c42 c36">Core Framework and Training Loop</span></h3><p class="c4 c10"><span class="c6">As both frameworks share the same concept, define-by-run, the look-and-feel of code written in PyTorch is pretty similar to Chainer. Here is the high-level mapping of features:</span></p><p class="c4 c10 c29"><span class="c6"></span></p><a id="t.e6a46275bcd72c5ee54dae665a0d891476f5e165"></a><a id="t.1"></a><table class="c30"><tbody><tr class="c5"><td class="c63 c88" colspan="1" rowspan="1"><p class="c34"><span class="c7">Chainer</span></p></td><td class="c63 c88" colspan="1" rowspan="1"><p class="c34"><span class="c7">PyTorch</span></p></td><td class="c63 c88" colspan="1" rowspan="1"><p class="c34"><span class="c7">Notes</span></p></td></tr><tr class="c5"><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c7">Variable</span></p><p class="c16"><span class="c6">chainer.Variable</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c7">Tensor</span></p><p class="c16"><span class="c6">torch.Tensor</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c16 c29"><span class="c6"></span></p></td></tr><tr class="c5"><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c7">Function</span></p><p class="c16"><span class="c6">chainer.FunctionNode</span></p><p class="c16"><span class="c6">(chainer.functions.*)</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c7">Function</span></p><p class="c16"><span class="c6">torch.autograd.Function</span></p><p class="c16"><span class="c6">(torch.nn.functional.*)</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c6">`torch.*` also provides NumPy-like (but not compatible) operations.</span></p></td></tr><tr class="c5"><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c7">Link / Chain</span></p><p class="c16"><span class="c6">chainer.{Link, Chain}</span></p><p class="c16"><span class="c6">(chainer.links.*)</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c7">Module</span></p><p class="c16"><span class="c6">torch.nn.Module</span></p><p class="c16"><span class="c6">(torch.nn.*)</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c16 c29"><span class="c6"></span></p></td></tr><tr class="c5"><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c7">Sequential</span></p><p class="c16"><span class="c6">chainer.Sequential</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c7">Sequential</span></p><p class="c16"><span class="c6">torch.nn.Sequential</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c6">You can use function modules as member (e.g., torch.nn.ReLU instead of torch.nn.functional.relu).</span></p></td></tr><tr class="c5"><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c7">Dataset</span></p><p class="c16"><span class="c6">chainer.dataset.DatasetMixin</span></p><p class="c16"><span class="c6">(chainer.datasets.*)</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c7">Dataset</span></p><p class="c16"><span class="c6">torch.utils.data.Dataset</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c16"><span>There are no TransformDataset in PyTorch (there is one in CPM as cpm.TransformDataset); </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torchvision/datasets.html&amp;sa=D&amp;ust=1578461385098000">datasets conventionally accepts</a></span><span class="c6">&nbsp;`transforms` argument that perform per-example preprocessing.</span></p></td></tr><tr class="c5"><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c7">Iterator</span></p><p class="c16"><span class="c6">chainer.iterators.*</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c36">DataLoader</span></p><p class="c16"><span class="c6">torch.utils.data.DataLoader</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c16"><span>Unlike Chainer&#39;s Iterator, DataLoader automatically collates all samples into one Tensor by default; use </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/data.html%23working-with-collate-fn&amp;sa=D&amp;ust=1578461385100000">collate_fn</a></span><span class="c6">&nbsp;to customize this behavior.</span></p><p class="c16"><span class="c6">DataLoader itself supports multi-process iteration (using num_workers option).</span></p></td></tr><tr class="c5"><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c7">Optimizer</span></p><p class="c16"><span class="c6">chainer.Optimizer</span></p><p class="c16"><span>(</span><span class="c6">chainer.optimizers.*)</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c7">Optimizer</span></p><p class="c16"><span class="c6">torch.optim.Optimizer</span></p><p class="c16"><span>(</span><span class="c6">torch.optim.*)</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c16 c29"><span class="c6"></span></p></td></tr><tr class="c85"><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c7">Trainer</span></p><p class="c16"><span class="c6">chainer.training.Trainer</span></p></td><td class="c74" colspan="1" rowspan="3"><p class="c16"><span class="c7">Engine</span></p><p class="c16"><span class="c6">ignite.Engine</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c6">ignite.engine.create_supervised_trainer()</span></p></td></tr><tr class="c85"><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c36">Updater</span><span class="c6">&nbsp;(with converter)</span></p><p class="c16"><span class="c6">chainer.training.Updater</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c6">As noted above, Iterator concatenates examples by default. Transfer to device is handled by Engine (or custom loop code if you don&#39;t use Ignite)</span></p></td></tr><tr class="c85"><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c7">Evaluator</span></p><p class="c16"><span class="c6">chainer.training.extensions.Evaluator</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c6">ignite.engine.create_supervised_evaluator()</span></p></td></tr><tr class="c5"><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c7">Extension</span></p><p class="c16"><span class="c6">chainer.training.Extension</span></p><p class="c16"><span class="c6">(chainer.training.extensions.*)</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c16"><span class="c7">Handler</span></p><p class="c16"><span class="c6">(ignite.handlers.*, ignite.contrib.handlers.*)</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c16 c29"><span class="c6"></span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span>Refer to the </span><span class="c43"><a class="c2" href="#h.9eib52bt6ke5">Porting Guide</a></span><span class="c6">&nbsp;section for the details of the difference of each component.</span></p><h2 class="c31 c10" id="h.y7ovx8en8cp7"><span class="c67 c36">Migration scenarios</span></h2><h3 class="c23 c10" id="h.e88d7eicrcd0"><span class="c42 c36">I want to port my Chainer script to PyTorch, step by step</span></h3><p class="c4 c10"><span class="c6">Arguably the model is the hardest part to port without affecting the outcome of the training.</span></p><p class="c4 c10"><span class="c6">It might be easier to port in this order:</span></p><ol class="c18 lst-kix_7pcs9kbg0qhi-0 start" start="1"><li class="c1"><span class="c6">Training script (optimizer / updater / evaluator / ...)</span></li></ol><ul class="c18 lst-kix_3bekfbfd6o8j-0 start"><li class="c4 c10 c71"><span>In order to use PyTorch optimizer to train a Chainer model, you will need </span><span class="c43 c13"><a class="c2" href="#h.46et3pwf65s">cpm.LinkAsTorchModel</a></span><span class="c6">.</span></li></ul><ol class="c18 lst-kix_7pcs9kbg0qhi-0" start="2"><li class="c1"><span class="c6">Dataset / preprocessing</span></li></ol><ul class="c18 lst-kix_rj34zh1l62l0-0 start"><li class="c4 c10 c71"><span class="c6">Dataset is in general compatible between Chainer and PyTorch. This part can be delayed but also should be easy to do.</span></li></ul><ol class="c18 lst-kix_7pcs9kbg0qhi-0" start="3"><li class="c1"><span class="c6">Model</span></li></ol><ul class="c18 lst-kix_e8kaqrotva4-0 start"><li class="c4 c10 c71"><span class="c6">See the mapping of functions/modules below in this document.</span></li></ul><h3 class="c23 c10" id="h.8w1snpmhh4kj"><span class="c42 c36">I want to let my Chainer code train a PyTorch model</span></h3><p class="c4 c10"><span>You can use </span><span class="c43 c13"><a class="c2" href="#h.im0z6zf5ujzw">cpm.TorchModule</a></span><span class="c6">&nbsp;to wrap a PyTorch module as a Chainer model.</span></p><h2 class="c31 c10" id="h.9wc1iaeyqb2c"><span class="c67 c36">Migration tools (cpm)</span></h2><p class="c4 c10"><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://github.com/chainer/chainer-pytorch-migration&amp;sa=D&amp;ust=1578461385108000">chainer-pytorch-migration</a></span><span class="c6">&nbsp;Python module (called &quot;cpm&quot; in this document) provides various utilities to help migration from Chainer to PyTorch.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span class="c6">Example code assumes that cpm is imported as follows:</span></p><a id="t.b6d4e8a49de865470ffee8db15d9b8ba2e23ba94"></a><a id="t.2"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c16"><span class="c53 c13 c45">import chainer_pytorch_migration as cpm</span></p><p class="c16"><span class="c13 c45">import chainer_pytorch_migration.ignite</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><h3 class="c23 c10" id="h.im0z6zf5ujzw"><span class="c42 c36">cpm.TorchModule</span></h3><p class="c4 c10"><span class="c6">This class wraps a PyTorch module as a Chainer link. It allows training PyTorch models in Chainer training scripts. The graph (forward/backward) must be constructed and traversed in PyTorch.</span></p><a id="t.a38bfd190b7eeeae684f9cee2c1f0d3585c106d8"></a><a id="t.3"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c16"><span class="c53 c13 c45">model = torchvision.models.resnet50()</span></p><p class="c16"><span class="c53 c13 c45">model.cuda()</span></p><p class="c16"><span class="c53 c13 c45">w_model = cpm.TorchModule(model)</span></p><p class="c16"><span class="c13 c45">w_model.to_gpu(device) </span><span class="c40 c13"># Just synchronizes the metadata, does not transfer data</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><h3 class="c23 c10" id="h.pflkcrjo8y89"><span class="c42 c36">cpm.ChainerParameter</span></h3><p class="c4 c10"><span>This class wraps a Chainer parameter as a PyTorch parameter. It allows training of Chainer models (</span><span class="c13">chainer.Link</span><span>) in PyTorch training scripts (with </span><span class="c13">torch.optim.Optimizer</span><span>). The graph (forward/backward) must be constructed and traversed in Chainer. </span><span class="c35">cpm.LinkAsTorchModel</span><span class="c6">&nbsp;internally uses it.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><a id="t.629215085eff3b976e0bfd5a36f2220c2566c72f"></a><a id="t.4"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c16"><span class="c40 c13"># initialized parameter</span></p><p class="c16"><span class="c53 c13 c45">arr = numpy.full(shape, 17, &#39;float32&#39;)</span></p><p class="c16"><span class="c53 c13 c45">chainer_param = chainer.Parameter(arr)</span></p><p class="c16"><span class="c13 c45">torch_param = cpm.ChainerParameter(chainer_param)</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><h3 class="c23 c10" id="h.46et3pwf65s"><span class="c42 c36">cpm.LinkAsTorchModel</span></h3><p class="c4 c10"><span>This class automatically creates all the </span><span class="c13">cpm.ChainerParameter</span><span>&nbsp;objects for a given chainer link and provides methods such as </span><span class="c13">parameters()</span><span>, </span><span class="c13">named_parameters()</span><span>&nbsp;or </span><span class="c13">state_dict() </span><span class="c6">required by pytorch optimizers or tools such as horovod.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><a id="t.7c4d4e63fadd2ec7a99e994e6797d2ceef166dfb"></a><a id="t.5"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c16"><span class="c9">model = ChainerModel()</span></p><p class="c16"><span class="c9">model.to_device(ch_device)</span></p><p class="c16"><span class="c72 c13"># Initialize parameters before converting to `ChainerParameter`s.</span></p><p class="c16"><span class="c9">model(ch_device.xp.zeros((1, 784)).astype(&#39;f&#39;))</span></p><p class="c16"><span class="c72 c13"># Convert parameters to `ChainerParameter`s to share memory with PyTorch.</span></p><p class="c16"><span class="c9">torched_model = cpm.LinkAsTorchModel(model)</span></p><p class="c16"><span class="c13">optimizer = optim.SGD(torched_model.parameters(), lr=args.lr)</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><h3 class="c23 c10" id="h.49ptm66ugzcy"><span class="c42 c36">cpm.ignite.add_trainer_extension</span></h3><p class="c4 c10"><span class="c6">This function registers a chainer trainer extension to be used with ignite.</span></p><p class="c4 c10"><span class="c6">Function call requires the ignite trainer, torch optimizer and the chainer extension as the parameters</span></p><a id="t.03de8277e29c4d3c8e35d4343afc863ae26c47ed"></a><a id="t.6"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c4 c10"><span class="c53 c13 c45">optimizer.target = model</span></p><p class="c4 c10"><span class="c53 c13 c45">trainer.out = &#39;path to store extension results&#39;</span></p><p class="c4 c10"><span class="c13 c45">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.ExponentialShift(&#39;lr&#39;, 0.9, 1.0, 0.1))</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c53 c13 c45"></span></p><h3 class="c23 c10" id="h.207juqqyebo8"><span class="c42 c36">cpm.use_torch_in_cupy_malloc</span></h3><p class="c4 c10"><span class="c6">This function makes CuPy use memory pool from PyTorch. You need to call it before any operations using CuPy.</span></p><a id="t.323ff2b7fb46ab05a4231bb4bff727f544cebb91"></a><a id="t.7"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c16"><span class="c53 c13 c45"># Enable using PyTorch memory allocator in CuPy.</span></p><p class="c16"><span class="c53 c13 c45">cpm.use_torch_in_cupy_malloc()</span></p><p class="c16 c29"><span class="c53 c13 c45"></span></p><p class="c16"><span class="c53 c13 c45"># Revert back to CuPy&#39;s default memory pool.</span></p><p class="c16"><span class="c13 c45">cpm.</span><span class="c13 c45">use_mempool_in_cupy_malloc</span><span class="c53 c13 c45">()</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><h1 class="c59 c10 c49" id="h.9eib52bt6ke5"><span class="c94 c36 c62">Porting Guides</span></h1><h2 class="c31 c10" id="h.7u4t6laltff5"><span class="c67 c36">Dataset and data pre/post-processing</span></h2><p class="c4 c10"><span>PyTorch datasets (</span><span class="c13">pytorch.utils.data.Dataset</span><span class="c6">) are basically compatible with Chainer&rsquo;s. In most cases they are interchangeable in both directions.</span></p><h3 class="c23 c10" id="h.tw9winyigiz6"><span class="c42 c36">Negative strides</span></h3><p class="c4 c10"><span>As of PyTorch 1.2.0, PyTorch cannot handle data arrays with negative strides (can result from </span><span class="c13">numpy.flip</span><span>&nbsp;or </span><span class="c13">chainercv.transforms.flip</span><span class="c6">, for example).</span></p><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span>Perhaps the easiest way to circumvent this problem is to wrap the dataset with </span><span class="c13">numpy.ascontiguousarray</span><span class="c6">.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><a id="t.941bd69b434ad04726fb40c437dd8753bdd82a23"></a><a id="t.8"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c4 c10"><span class="c9">def avoid_negative_strides(in_data):</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; data, label = in_data</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; data = numpy.ascontiguousarray(data)</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; return data, label</span></p><p class="c4 c10 c29"><span class="c9"></span></p><p class="c4 c10"><span class="c9">dataset = cpm.TransformDataset(dataset, avoid_negative_strides)</span></p><p class="c4 c10"><span class="c13">data_loader = torch.utils.data.DataLoader(dataset, ...)</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span>Another way is to customize the collation function with </span><span class="c13">collate_fn</span><span>&nbsp;argument in </span><span class="c13">torch.utils.data.DataLoader</span><span class="c6">.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><a id="t.a749c5add683a394ba81c8606178ef82a83ebc58"></a><a id="t.9"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c4 c10"><span class="c9">def collate(batch):</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; data = numpy.stack([d for d, l in batch])</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; label = numpy.stack([l for d, l in batch])</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; data_tensor = torch.from_numpy(data)</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; label_tensor = torch.from_numpy(label)</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; return data_tensor, label_tensor</span></p><p class="c4 c10 c29"><span class="c9"></span></p><p class="c4 c10"><span class="c13">data_loader = torch.utils.data.DataLoader(dataset, ..., collate_fn=collate)</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><h3 class="c23 c10" id="h.iu5zwqbulp2u"><span>Rewriting Custom Converter Functions to </span><span class="c42 c36">collate_fn</span></h3><p class="c4 c10"><span>In Chainer, it&rsquo;s possible to specify custom converters for each batch via `</span><span class="c35">training.updaters.StandardUpdater(train_iter, optimizer, device=device, converter=_converter)</span><span>`. In PyTorch, similar functionality can be achieved via the data loader: `</span><span class="c35">DataLoader(..., collate_fn=_converter)</span><span class="c6">`.</span></p><p class="c4 c10"><span class="c6">There is, however, an important difference when used in conjunction with multiprocessing. In Chainer, `_converter` will be run in the main process, so it&rsquo;s safe to access CUDA in the function when using multiprocessing&rsquo;s `fork` mode. In PyTorch, however, `_converter` will be run inside each forker worker processes of the data loader. This means that we cannot access CUDA without getting a CUDA init error. It seems like in PyTorch, the correct usage is instead to only do CPU-related operations inside `_convert`, and only send the resulting tensors to the GPU *after* retrieving them from the data loader. The following is an example of correct PyTorch usage:</span></p><a id="t.da2a07b197e87147cdca50be1b609a1e175438f1"></a><a id="t.10"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c16"><span class="c9">it = DataLoader(..., collate_fn=_converter)</span></p><p class="c16"><span class="c9">for img, label, metadata in it:</span></p><p class="c16"><span class="c9">&nbsp; &nbsp; &nbsp;img = img.cuda()</span></p><p class="c16"><span class="c9">&nbsp; &nbsp; &nbsp;label = label.cuda()</span></p><p class="c16"><span class="c9">&nbsp; &nbsp; &nbsp;# metadata is still on CPU</span></p><p class="c16"><span class="c9">&nbsp; &nbsp; &nbsp;...</span></p></td></tr></tbody></table><p class="c4 c10"><span class="c6">Note that the above scenario is different from what we expect in Chainer, where the `_converter` is called in the main process, which is why Chainer code might have CUDA-related operations inside the `_converter`.</span></p><p class="c4 c10"><span>Note that in the above use case, _convert should also use `pin_memory` in order to speed up the transfer of `(img, label)` from CPU to GPU: </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/when-to-set-pin-memory-to-true/19723&amp;sa=D&amp;ust=1578461385126000">https://discuss.pytorch.org/t/when-to-set-pin-memory-to-true/19723</a></span></p><h3 class="c23 c10" id="h.5zvn9j4xwu6j"><span class="c42 c36">NumPy bridge</span></h3><p class="c4 c10"><span class="c13">torch.DataLoader</span><span>&nbsp;automatically converts NumPy arrays to PyTorch tensors, but if you want to do that manually, refer to </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/tutorials/beginner/former_torchies/tensor_tutorial.html%23numpy-bridge&amp;sa=D&amp;ust=1578461385127000">NumPy Bridge</a></span><span>.</span></p><h3 class="c23 c10" id="h.84jg73vglm0b"><span class="c42 c36">CuPy bridge</span></h3><p class="c4 c10"><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://docs-cupy.chainer.org/en/stable/reference/interoperability.html%23dlpack&amp;sa=D&amp;ust=1578461385128000">DLPack</a></span><span>&nbsp;can be used to bridge between CuPy and </span><span class="c13">torch.Tensor</span><span>. Note that DLPack does not handle ownership, so you have to make sure the original buffer (the original </span><span class="c35">cupy.ndarray</span><span>&nbsp;object or dltensor capsule object returned by </span><span class="c35">toDlpack()</span><span class="c6">) survives while the converted tensor/array is in use.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span>To fully convert CuPy/PyTorch including shared ownership, use </span><span class="c13">cpm.asarray</span><span>&nbsp;and </span><span class="c13">cpm.astensor</span><span class="c6">.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span>It is also recommended to call </span><span class="c43"><a class="c2" href="#h.207juqqyebo8">cpm.use_torch_in_cupy_malloc</a></span><span class="c6">&nbsp;before using CuPy to let it share the allocator with PyTorch.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span>Note: As of PyTorch 1.3.0, </span><span class="c13">__cuda_array_interface__</span><span>&nbsp;is broken (</span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/pull/24947&amp;sa=D&amp;ust=1578461385129000">pytorch/pytorch/#24947</a></span><span>). After fixing this issue, you will be able to convert between them just using </span><span class="c13">cupy.asarray</span><span>&nbsp;and </span><span class="c13">torch.as_tensor</span><span class="c6">&nbsp;instead of cpm counterparts.</span></p><h3 class="c23 c10" id="h.uohx43j9p18u"><span class="c42 c36">Difference between PyTorch and NumPy/CuPy</span></h3><h4 class="c23 c10" id="h.6qe1h751g6oj"><span class="c48">Division Behavior</span></h4><p class="c4 c10"><span>The behavior is different from NumPy/CuPy, which respects Python 3 division rules. You need to explicitly cast to float in PyTorch (</span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/issues/5411&amp;sa=D&amp;ust=1578461385130000">discussion</a></span><span class="c6">).</span></p><a id="t.e6393095a79238ebe833bf96db1ca9890627bbc4"></a><a id="t.11"></a><table class="c30"><tbody><tr class="c113"><td class="c28" colspan="1" rowspan="1"><p class="c4 c10"><span class="c9">&gt;&gt;&gt; x = numpy.arange(5)</span></p><p class="c4 c10"><span class="c9">&gt;&gt;&gt; x</span></p><p class="c4 c10"><span class="c9">array([0, 1, 2, 3, 4])</span></p><p class="c4 c10"><span class="c83 c13">&gt;&gt;&gt; x / 5</span></p><p class="c4 c10"><span class="c83 c13">array([0. , 0.2, 0.4, 0.6, 0.8])</span></p><p class="c4 c10"><span class="c13 c83">&gt;&gt;&gt; torch.from_numpy(x) / 5</span></p><p class="c4 c10"><span class="c83 c13">tensor([0, 0, 0, 0, 0])</span></p><p class="c4 c10"><span class="c9">&gt;&gt;&gt; torch.from_numpy(x).float() / 5</span></p><p class="c4 c10"><span class="c9">tensor([0.0000, 0.2000, 0.4000, 0.6000, 0.8000])</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><h4 class="c23 c10" id="h.br8vew20r7k"><span class="c48">Feature Mapping</span></h4><p class="c4 c10"><span>See </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://github.com/wkentaro/pytorch-for-numpy-users&amp;sa=D&amp;ust=1578461385132000">PyTorch for Numpy users</a></span><span>&nbsp;for the comparison table.</span></p><h2 class="c31 c10" id="h.h1ei3avajrbn"><span class="c67 c36">Training loop</span></h2><p class="c4 c10"><span>This is an example code of training loop. Note </span><span class="c13">model.train()</span><span class="c6">.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10 c29"><span class="c6"></span></p><a id="t.df4d8e7b83e3847f40cedf4a49147baac0a37f94"></a><a id="t.12"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c4 c10"><span class="c9">device = torch.device(&#39;cuda:0&#39;)</span></p><p class="c4 c10"><span class="c9">for i_epoch in range(args.epoch):</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; train_loss = 0</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; train_correct = 0</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; model.train()</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; for x, t in data_loader:</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; x = x.to(device)</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; t = t.to(device).long()</span></p><p class="c4 c10 c29"><span class="c9"></span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; optimizer.zero_grad()</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; y = model(x)</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; loss = F.nll_loss(y, t)</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; loss.backward()</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; optimizer.step()</span></p><p class="c4 c10 c29"><span class="c9"></span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; train_loss += loss.sum().item()</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; _, pred = torch.max(y, 1)</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; train_correct += (pred == t).sum().item()</span></p><p class="c4 c10 c29"><span class="c9"></span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; train_loss /= len(data_loader.dataset)</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; train_accuracy = train_correct / len(data_loader.dataset)</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; print(&#39;Train average loss: {:.03f}&#39;.format(train_loss))</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; print(&#39;Train accuracy : {:.03f} %&#39;.format(train_accuracy * 100))</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><h2 class="c31 c10" id="h.3b2g5rapv9ec"><span class="c67 c36">Evaluation loop</span></h2><p class="c4 c10"><span>This is an example code of evaluation loop. Note </span><span class="c13">model.eval() </span><span>and </span><span class="c13">with torch.no_grad()</span><span>.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><a id="t.11fc8eb3ce1b6cb26c10953d413254d7b7fbaa04"></a><a id="t.13"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c4 c10"><span class="c9">device = torch.device(&#39;cuda:0&#39;)</span></p><p class="c4 c10"><span class="c9">total_loss = 0</span></p><p class="c4 c10"><span class="c9">total_correct = 0</span></p><p class="c4 c10"><span class="c9">model.eval()</span></p><p class="c4 c10"><span class="c9">with torch.no_grad():</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; for x, t in data_loader:</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; x = x.to(device)</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; t = t.to(device).long()</span></p><p class="c4 c10 c29"><span class="c9"></span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; y = model(x)</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; total_loss += F.nll_loss(y, t, reduction=&#39;sum&#39;).item()</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; _, pred = torch.max(y, 1)</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; total_correct += (pred == t).sum().item()</span></p><p class="c4 c10 c29"><span class="c9"></span></p><p class="c4 c10"><span class="c9">average_loss = total_loss / len(loader.dataset)</span></p><p class="c4 c10"><span class="c9">accuracy = total_correct / len(loader.dataset)</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><h2 class="c31 c10" id="h.wanb8rb4d6lo"><span class="c67 c36">Training and evaluation using Ignite</span></h2><p class="c4 c10"><span>Ignite is something corresponding to </span><span class="c13">chainer.training.Trainer</span><span class="c6">&nbsp;in Chainer.</span></p><p class="c4 c10"><span>This Chainer code:</span></p><p class="c4 c10 c29"><span class="c9"></span></p><p class="c4 c10 c29"><span class="c9"></span></p><p class="c4 c10 c29"><span class="c6"></span></p><a id="t.06fe944358155c5c1c1720ada7a200c56fa902b2"></a><a id="t.14"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c4 c10"><span class="c9">updater = chainer.training.StandardUpdater(</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; train_iter,</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; optimizer,</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; device=device)</span></p><p class="c4 c10"><span class="c9">trainer = chainer.training.Trainer(updater, (100, &lsquo;epoch&rsquo;))</span></p><p class="c4 c10"><span class="c9">trainer.extend(</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; extensions.Evaluator(</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; val_iter,</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; model,</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; device=device),</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; trigger=(1, &lsquo;epoch&rsquo;))</span></p><p class="c4 c10"><span class="c9">trainer.run()</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span>can be written in PyTorch using Ignite:</span></p><p class="c4 c10 c29"><span class="c6"></span></p><a id="t.26f609c9f19badd14a1ca750000df5cbc6d342ee"></a><a id="t.15"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c4 c10"><span class="c9">trainer = ignite.engine.create_supervised_trainer(</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; model,</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; optimizer,</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; F.nll_loss,</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; device=device)</span></p><p class="c4 c10"><span class="c9">evaluator = ignite.engine.create_supervised_evaluator(</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; model,</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; metrics={</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; &#39;accuracy&#39;: ignite.metrics.Accuracy(),</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; &#39;loss&#39;: ignite.metrics.Loss(F.nll_loss),</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; },</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; device=device)</span></p><p class="c4 c10 c29"><span class="c9"></span></p><p class="c4 c10"><span class="c9">@trainer.on(ignite.engine.Events.EPOCH_COMPLETED)</span></p><p class="c4 c10"><span class="c9">def validation(engine):</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; evaluator.run(val_loader)</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; average_accuracy = evaluator.state.metrics[&lsquo;accuracy&rsquo;]</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; average_loss = evaluator.state.metrics[&lsquo;loss&rsquo;]</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; print(average_accuracy, average_loss)</span></p><p class="c4 c10 c29"><span class="c9"></span></p><p class="c4 c10"><span class="c9">trainer.run(train_loader, max_epochs=100)</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span>For a list of supported metrics, see </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/ignite/metrics.html&amp;sa=D&amp;ust=1578461385145000">https://pytorch.org/ignite/metrics.html</a></span><span class="c6">.</span></p><h2 class="c31 c10" id="h.m8sz4mg7ioxl"><span class="c67 c36">Using Chainer extensions with Ignite</span></h2><p class="c4 c10"><span>Using </span><span class="c43"><a class="c2" href="#h.49ptm66ugzcy">cpm.ignite.add_trainer_extension</a></span><span class="c6">&nbsp;it is possible to register a chainer extension to be called within the ignite training loop.</span></p><p class="c4 c10"><span class="c6">A list of the supported extensions follows:</span></p><p class="c4 c10 c29"><span class="c6"></span></p><a id="t.d4eff46624142b2b1a44288ca2ae5657d3d651eb"></a><a id="t.16"></a><table class="c79"><tbody><tr class="c5"><td class="c47 c104" colspan="1" rowspan="1"><p class="c34"><span class="c53 c45 c66">Works</span></p></td><td class="c57 c104" colspan="1" rowspan="1"><p class="c34"><span class="c53 c66 c45">Doesn&rsquo;t work</span></p></td></tr><tr class="c5"><td class="c47" colspan="1" rowspan="1"><p class="c34"><span class="c41 c13">ExponentialShift</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c34"><span class="c41 c13">DumpGraph</span></p></td></tr><tr class="c5"><td class="c47" colspan="1" rowspan="1"><p class="c34"><span class="c41 c13">FailOnNonNumber</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c34"><span class="c41 c13">Evaluator</span></p></td></tr><tr class="c103"><td class="c47" colspan="1" rowspan="1"><p class="c34"><span class="c41 c13">InverseShift</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c34"><span class="c41 c13">unchain_variables</span></p></td></tr><tr class="c5"><td class="c47" colspan="1" rowspan="1"><p class="c34"><span class="c41 c13">LinearShift</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c34 c29"><span class="c41 c13"></span></p></td></tr><tr class="c5"><td class="c47" colspan="1" rowspan="1"><p class="c34"><span class="c41 c13">LogReport</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c34 c29"><span class="c41 c13"></span></p></td></tr><tr class="c5"><td class="c47" colspan="1" rowspan="1"><p class="c34"><span class="c41 c13">MicroAverage</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c34 c29"><span class="c41 c13"></span></p></td></tr><tr class="c5"><td class="c47" colspan="1" rowspan="1"><p class="c34"><span class="c41 c13">MultistepShift</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c34 c29"><span class="c41 c13"></span></p></td></tr><tr class="c5"><td class="c47" colspan="1" rowspan="1"><p class="c34"><span class="c41 c13">ParameterStatistics</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c34 c29"><span class="c41 c13"></span></p></td></tr><tr class="c5"><td class="c47" colspan="1" rowspan="1"><p class="c34"><span class="c41 c13">PlotReport</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c34 c29"><span class="c41 c13"></span></p></td></tr><tr class="c5"><td class="c47" colspan="1" rowspan="1"><p class="c34"><span class="c41 c13">PolynomialShift</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c34 c29"><span class="c41 c13"></span></p></td></tr><tr class="c5"><td class="c47" colspan="1" rowspan="1"><p class="c34"><span class="c41 c13">PrintReport</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c34 c29"><span class="c41 c13"></span></p></td></tr><tr class="c5"><td class="c47" colspan="1" rowspan="1"><p class="c34"><span class="c41 c13">ProgressBar</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c34 c29"><span class="c41 c13"></span></p></td></tr><tr class="c5"><td class="c47" colspan="1" rowspan="1"><p class="c34"><span class="c41 c13">snapshot(read docs)</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c34 c29"><span class="c41 c13"></span></p></td></tr><tr class="c5"><td class="c47" colspan="1" rowspan="1"><p class="c34"><span class="c41 c13">StepShift</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c34 c29"><span class="c13 c41"></span></p></td></tr><tr class="c5"><td class="c47" colspan="1" rowspan="1"><p class="c34"><span class="c41 c13">observe_lr</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c34 c29"><span class="c41 c13"></span></p></td></tr><tr class="c5"><td class="c47" colspan="1" rowspan="1"><p class="c34"><span class="c41 c13">VariableStatisticsPlot</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c34 c29"><span class="c41 c13"></span></p></td></tr><tr class="c5"><td class="c47" colspan="1" rowspan="1"><p class="c34"><span class="c41 c13">WarmupShift</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c34 c29"><span class="c41 c13"></span></p></td></tr></tbody></table><p class="c4 c10"><span class="c6">Some drawbacks rely on that metrics associated to the model or links might not accessible by default.</span></p><p class="c4 c10"><span class="c6">For example the user will need to report the loss or accuracy per iteration by using an ignite callback as this was done inside the chainer model.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span class="c6">Also for some extensions to work it is necessary for the user to assign the torch or chainer model to the optimizer target attribute and the output directory path for the LogReport, plotters and snapshot extensions</span></p><a id="t.d3bbb7d0330927644916c6808491d67b611bb39a"></a><a id="t.17"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c16"><span class="c53 c13 c45">from chainer import reporter<br>@trainer.on(Events.ITERATION_COMPLETED)</span></p><p class="c16"><span class="c53 c13 c45">def report_loss(engine):</span></p><p class="c16"><span class="c53 c13 c45">&nbsp; &nbsp; reporter.report({&#39;loss&#39;:engine.state.output})</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span class="c6">An example of how to register multiple extensions:</span></p><a id="t.8bbf20fa9e631df5f36bd1501c7e922ff7c73524"></a><a id="t.18"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c16"><span class="c13 c45 c73"># Torch optimizer</span><span class="c53 c13 c45"><br>optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)</span></p><p class="c16"><span class="c40 c13"># Ignite trainer</span></p><p class="c16"><span class="c53 c13 c45">trainer = create_supervised_trainer(model, optimizer, F.nll_loss, device=device)</span></p><p class="c16"><span class="c13 c45"><br></span><span class="c40 c13"># Add the model to the target attribute of the optimizer</span></p><p class="c16"><span class="c53 c13 c45">optimizer.target = model</span></p><p class="c16 c29"><span class="c53 c13 c45"></span></p><p class="c16"><span class="c13 c45 c73"># Set the output dir for some of the extensions</span></p><p class="c16"><span class="c53 c13 c45">trainer.out = &#39;result&#39;</span></p><p class="c16 c29"><span class="c53 c13 c45"></span></p><p class="c16"><span class="c13 c40"># Restore the snapshot</span></p><p class="c16"><span class="c53 c13 c45">cpm.ignite.load_chainer_snapshot(trainer, optimizer, &#39;result/snapshot_iter_4691&#39;)</span></p><p class="c16 c29"><span class="c53 c13 c45"></span></p><p class="c16"><span class="c40 c13"># Add a bunch of extensions</span></p><p class="c16"><span class="c53 c13 c45">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.ProgressBar())</span></p><p class="c16"><span class="c53 c13 c45">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.observe_lr())</span></p><p class="c16"><span class="c53 c13 c45">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.MicroAverage(&#39;loss&#39;,&#39;lr&#39;,&#39;mav&#39;,(1, &#39;iteration&#39;)))</span></p><p class="c16"><span class="c53 c13 c45">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.LogReport())</span></p><p class="c16"><span class="c53 c13 c45">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.FailOnNonNumber())</span></p><p class="c16"><span class="c53 c13 c45">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.ExponentialShift(&#39;lr&#39;, 0.9, 1.0, 0.1))</span></p><p class="c16"><span class="c53 c13 c45">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.ParameterStatistics(model, prefix=&#39;model&#39;))</span></p><p class="c16"><span class="c53 c13 c45">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.VariableStatisticsPlot(model))</span></p><p class="c16"><span class="c53 c13 c45">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.PrintReport(</span></p><p class="c16"><span class="c13 c45 c53">&nbsp; &nbsp; [&#39;epoch&#39;, &#39;iteration&#39;, &#39;loss&#39;, &#39;lr&#39;, &#39;mav&#39;, &#39;model/fc2/weight/grad/percentile/1&#39;]))</span></p><p class="c16"><span class="c53 c13 c45">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.PlotReport([&#39;loss&#39;],</span></p><p class="c16"><span class="c53 c13 c45">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;epoch&#39;, filename=&#39;loss.png&#39;))</span></p><p class="c16"><span class="c13 c45">cpm.ignite.add_trainer_extension(trainer, optimizer, extensions.snapshot(writer=</span><span class="c13 c45">writer)</span><span class="c13 c45">, trigger=(1, &#39;epoch&#39;)) &nbsp;# writer is a SimpleWriter</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><h3 class="c23 c10" id="h.ojt9418jpkms"><span class="c42 c36">Snapshots</span></h3><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span class="c6">When using the snapshot extension with an ignite trainer, the pytorch objects are saved to an additional &ldquo;snapshot-torch&rdquo; file in the output folder. This allows to keep using these snapshots once the migration is finished and directly load pytorch models or the optimizer state from these files.</span></p><p class="c4 c10"><span class="c6">Additionally, if you are mixing chainer models or optimizers with ignite and pytorch, these objects will be saved in the chainer snapshot file.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span>The correct way to restore a snapshot is by using </span><span class="c13">cpm.ignite.load_chainer_snapshot(engine, optimizer, snapshot_path) </span><span class="c6">with the Chainer snapshot path.</span></p><p class="c4 c10"><span class="c83 c66">Note that previously taken Chainer snapshots are not compatible.</span></p><h2 class="c31 c10" id="h.s8lyt5panb7"><span class="c67 c36">Porting custom updater using Ignite</span></h2><p class="c4 c10"><span class="c6">You can pass a step function to an Ignite engine.</span></p><ul class="c18 lst-kix_ne2kodfi1kix-0 start"><li class="c1"><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/ignite/blob/55cb30b06330a1fd7bf1c7e0d23cba89b10f75bf/examples/gan/dcgan.py%23L308&amp;sa=D&amp;ust=1578461385164000">DCGAN example</a></span></li></ul><h2 class="c31 c10" id="h.xmsyb5asd2c9"><span class="c67 c36">Rewriting existing Chainer model</span></h2><p class="c4 c10"><span>Use </span><span class="c43"><a class="c2" href="#h.mkuuagm60br0">Mapping of functions and links</a></span><span class="c6">&nbsp;to find and replace with the corresponding feature in PyTorch. You can also find existing model implementations in:</span></p><ul class="c18 lst-kix_mfwegjdddisb-0 start"><li class="c1"><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/examples&amp;sa=D&amp;ust=1578461385165000">PyTorch Examples</a></span></li><li class="c1"><span class="c35">torchvision.models</span><span>&nbsp;module (CV models) (</span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torchvision/models.html&amp;sa=D&amp;ust=1578461385165000">API Reference</a></span><span class="c6">)</span></li><li class="c1"><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/hub&amp;sa=D&amp;ust=1578461385166000">PyTorch Hub</a></span><span>&nbsp;(models from community) (</span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/master/hub.html&amp;sa=D&amp;ust=1578461385166000">API Reference</a></span><span class="c6">)</span></li></ul><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span class="c6">Common pitfalls:</span></p><ul class="c18 lst-kix_r60cdwx1dlic-0 start"><li class="c1"><span class="c6">Image format: RGB or BGR</span></li><li class="c1"><span class="c6">Image normalization: [0,1] or [0,255]</span></li><li class="c1"><span>Some old PyTorch examples and community projects are using </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/autograd.html%23variable-deprecated&amp;sa=D&amp;ust=1578461385166000">torch.autograd.Variable</a></span><span class="c6">, which is a deprecated interface.</span></li><li class="c1"><span>Some well-known models such as resnet might have different behavior in ChainerCV and torchvision. For example, </span><span class="c35">chainercv.links.ResNet50</span><span>&nbsp;applies softmax to the output while </span><span class="c35">torchvision.models.resnet50</span><span class="c6">&nbsp;does not.</span></li></ul><h2 class="c31 c10" id="h.mkuuagm60br0"><span class="c67 c36">Functions and Links</span></h2><p class="c4 c10"><span class="c6">You can find the PyTorch equivalent of Chainer&#39;s functions and links in tables below.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span class="c6">Notes:</span></p><ul class="c18 lst-kix_c4453ihcjob0-0 start"><li class="c1"><span>Unlike NumPy/CuPy, PyTorch Tensor itself supports gradient computation (you can safely use </span><span class="c35">torch.*</span><span>&nbsp;or </span><span class="c35">torch.nn.functional.*</span><span>&nbsp;on </span><span class="c35">torch.Tensor</span><span class="c6">)</span></li><li class="c1"><span>Conventions of keyword arguments: </span><span class="c35">dim</span><span>&nbsp;and </span><span class="c35">keepdim</span><span>&nbsp;is used in PyTorch instead of </span><span class="c35">axis</span><span>&nbsp;and </span><span class="c35">keepdims</span><span class="c6">&nbsp;in Chainer/NumPy.</span></li><li class="c1"><span>Unlike Chainer, PyTorch provides the Module version of each function (e.g., </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.ReLU&amp;sa=D&amp;ust=1578461385168000">nn.ReLU</a></span><span>&nbsp;for </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.relu&amp;sa=D&amp;ust=1578461385168000">F.relu</a></span><span>), so you can use the Module version when defining model using functions in </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23sequential&amp;sa=D&amp;ust=1578461385169000">Sequential</a></span><span class="c6">&nbsp;container.</span></li></ul><h3 class="c23 c10" id="h.e17stx2v9ds3"><span class="c42 c36">Functions</span></h3><p class="c4 c10"><span class="c35">F</span><span>&nbsp;refers to </span><span class="c35">chainer.functions</span><span>&nbsp;(Chainer) / </span><span class="c35">torch.nn.functional</span><span>&nbsp;(PyTorch).</span></p><p class="c4 c10 c29"><span class="c6"></span></p><a id="t.d5e9a871d64310c4ccb321a177a4ed6d43046541"></a><a id="t.19"></a><table class="c30"><tbody><tr class="c51"><td class="c88 c110" colspan="1" rowspan="1"><p class="c64 c10"><span class="c36 c15">Chainer</span></p></td><td class="c78" colspan="1" rowspan="1"><p class="c64 c10"><span class="c36 c15">PyTorch</span></p></td><td class="c88 c109" colspan="1" rowspan="1"><p class="c10 c64"><span class="c36 c15">Notes</span></p></td></tr><tr class="c20"><td class="c19" colspan="3" rowspan="1"><p class="c4 c10"><span class="c36 c15">Arithmetic functions</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.add.html%23chainer.functions.add&amp;sa=D&amp;ust=1578461385172000">F.add</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.add&amp;sa=D&amp;ust=1578461385173000">torch.add</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Batched addition (accumulating multiple tensors in a single call) is not supported.</span></p></td></tr><tr class="c20"><td class="c19" colspan="3" rowspan="1"><p class="c4 c10"><span class="c36 c15">Activation functions</span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.clipped_relu.html%23chainer.functions.clipped_relu&amp;sa=D&amp;ust=1578461385175000">F.clipped_relu</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Rewrite as:</span></p><p class="c4 c10"><span class="c35 c15">x.</span><span class="c3 c35"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/tensors.html%23torch.Tensor.clamp&amp;sa=D&amp;ust=1578461385176000">clamp</a></span><span class="c53 c35 c15">(0, z)</span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.crelu.html%23chainer.functions.crelu&amp;sa=D&amp;ust=1578461385176000">F.crelu</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Rewrite as:</span></p><p class="c4 c10"><span class="c3 c35"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.cat&amp;sa=D&amp;ust=1578461385177000">torch.cat</a></span><span class="c53 c35 c15">((F.relu(x), F.relu(-x)))</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.elu.html%23chainer.functions.elu&amp;sa=D&amp;ust=1578461385178000">F.elu</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.elu&amp;sa=D&amp;ust=1578461385179000">F.elu</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.hard_sigmoid.html%23chainer.functions.hard_sigmoid&amp;sa=D&amp;ust=1578461385180000">F.hard_sigmoid</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Rewrite as:</span></p><p class="c4 c10"><span class="c3 c35"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.clamp&amp;sa=D&amp;ust=1578461385181000">torch.clamp</a></span><span class="c53 c35 c15">(x * 0.2 + 0.5, 0, 1)</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.leaky_relu.html%23chainer.functions.leaky_relu&amp;sa=D&amp;ust=1578461385181000">F.leaky_relu</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.leaky_relu&amp;sa=D&amp;ust=1578461385182000">F.leaky_relu</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">The default slope value is different.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.log_softmax.html%23chainer.functions.log_softmax&amp;sa=D&amp;ust=1578461385183000">F.log_softmax</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.log_softmax&amp;sa=D&amp;ust=1578461385183000">F.log_softmax</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.lstm.html%23chainer.functions.lstm&amp;sa=D&amp;ust=1578461385184000">F.lstm</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">See L.LSTM.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.maxout.html%23chainer.functions.maxout&amp;sa=D&amp;ust=1578461385186000">F.maxout</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">Need to implement manually; see </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/issues/805&amp;sa=D&amp;ust=1578461385187000">https://github.com/pytorch/pytorch/issues/805</a></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.prelu.html%23chainer.functions.prelu&amp;sa=D&amp;ust=1578461385188000">F.prelu</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.prelu&amp;sa=D&amp;ust=1578461385188000">F.prelu</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.rrelu.html%23chainer.functions.rrelu&amp;sa=D&amp;ust=1578461385190000">F.rrelu</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.rrelu&amp;sa=D&amp;ust=1578461385190000">F.rrelu</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">`training` option must be explicitly specified instead of `train` config in Chainer.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.relu.html%23chainer.functions.relu&amp;sa=D&amp;ust=1578461385191000">F.relu</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.relu&amp;sa=D&amp;ust=1578461385192000">F.relu</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.relu6.html%23chainer.functions.relu6&amp;sa=D&amp;ust=1578461385193000">F.relu6</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.relu6&amp;sa=D&amp;ust=1578461385193000">F.relu6</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.selu.html%23chainer.functions.selu&amp;sa=D&amp;ust=1578461385194000">F.selu</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.selu&amp;sa=D&amp;ust=1578461385195000">F.selu</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.sigmoid.html%23chainer.functions.sigmoid&amp;sa=D&amp;ust=1578461385196000">F.sigmoid</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.sigmoid&amp;sa=D&amp;ust=1578461385196000">F.sigmoid</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.slstm.html%23chainer.functions.slstm&amp;sa=D&amp;ust=1578461385197000">F.slstm</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">Some OSS implementations are available (e.g., </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/reachtarunhere/S-LSTM-PyTorch&amp;sa=D&amp;ust=1578461385198000">https://github.com/reachtarunhere/S-LSTM-PyTorch</a></span><span class="c0">)</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.softmax.html%23chainer.functions.softmax&amp;sa=D&amp;ust=1578461385198000">F.softmax</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.softmax&amp;sa=D&amp;ust=1578461385199000">F.softmax</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.softplus.html%23chainer.functions.softplus&amp;sa=D&amp;ust=1578461385200000">F.softplus</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.softplus&amp;sa=D&amp;ust=1578461385200000">F.softplus</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">PyTorch falls back to linear function by default; threshold option must be explicitly given.</span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.swish.html%23chainer.functions.swish&amp;sa=D&amp;ust=1578461385201000">F.swish</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Rewrite as:</span></p><p class="c4 c10"><span class="c35 c15">x * </span><span class="c3 c35"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.sigmoid&amp;sa=D&amp;ust=1578461385202000">F.sigmoid</a></span><span class="c53 c35 c15">(beta * x)</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.tanh.html%23chainer.functions.tanh&amp;sa=D&amp;ust=1578461385203000">F.tanh</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.tanh&amp;sa=D&amp;ust=1578461385203000">F.tanh</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.tree_lstm.html%23chainer.functions.tree_lstm&amp;sa=D&amp;ust=1578461385204000">F.tree_lstm</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">Some OSS implementations are available (e.g., </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/dasguptar/treelstm.pytorch&amp;sa=D&amp;ust=1578461385205000">https://github.com/dasguptar/treelstm.pytorch</a></span><span class="c0">)</span></p></td></tr><tr class="c20"><td class="c19" colspan="3" rowspan="1"><p class="c4 c10"><span class="c36 c15">Array manipulations</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.as_strided.html%23chainer.functions.as_strided&amp;sa=D&amp;ust=1578461385207000">F.as_strided</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.as_strided&amp;sa=D&amp;ust=1578461385207000">torch.as_strided</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.broadcast.html%23chainer.functions.broadcast&amp;sa=D&amp;ust=1578461385208000">F.broadcast</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.broadcast_tensors&amp;sa=D&amp;ust=1578461385209000">torch.broadcast_tensors</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">PyTorch operations perform broadcast automatically like as in NumPy: </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/notes/broadcasting.html&amp;sa=D&amp;ust=1578461385209000">https://pytorch.org/docs/stable/notes/broadcasting.html</a></span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.broadcast_to.html%23chainer.functions.broadcast_to&amp;sa=D&amp;ust=1578461385210000">F.broadcast_to</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">N/A: </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/pull/17160&amp;sa=D&amp;ust=1578461385211000">https://github.com/pytorch/pytorch/pull/17160</a></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.cast.html%23chainer.functions.cast&amp;sa=D&amp;ust=1578461385212000">F.cast</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/tensors.html%23torch.Tensor.to&amp;sa=D&amp;ust=1578461385213000">Tensor.to</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.concat.html%23chainer.functions.concat&amp;sa=D&amp;ust=1578461385213000">F.concat</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.cat&amp;sa=D&amp;ust=1578461385214000">torch.cat</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.copy.html%23chainer.functions.copy&amp;sa=D&amp;ust=1578461385215000">F.copy</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/tensors.html%23torch.Tensor.to&amp;sa=D&amp;ust=1578461385215000">Tensor.to</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.depth2space.html%23chainer.functions.depth2space&amp;sa=D&amp;ust=1578461385216000">F.depth2space</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.pixel_shuffle&amp;sa=D&amp;ust=1578461385217000">F.pixel_shuffle</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.diagonal.html%23chainer.functions.diagonal&amp;sa=D&amp;ust=1578461385218000">F.diagonal</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.diagonal&amp;sa=D&amp;ust=1578461385218000">torch.diagonal</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.dstack.html%23chainer.functions.dstack&amp;sa=D&amp;ust=1578461385219000">F.dstack</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Rewrite as:</span></p><p class="c4 c10"><span class="c3 c35"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.cat&amp;sa=D&amp;ust=1578461385220000">torch.cat</a></span><span class="c53 c35 c15">([a,b],dim=2)</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.expand_dims.html%23chainer.functions.expand_dims&amp;sa=D&amp;ust=1578461385221000">F.expand_dims</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">Rewrite as:</span></p><p class="c4 c10"><span class="c3 c35"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.unsqueeze&amp;sa=D&amp;ust=1578461385222000">torch.unsqueeze</a></span><span class="c53 c35 c15">(a, dim)</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.flatten.html%23chainer.functions.flatten&amp;sa=D&amp;ust=1578461385223000">F.flatten</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.flatten&amp;sa=D&amp;ust=1578461385223000">torch.flatten</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.flip.html%23chainer.functions.flip&amp;sa=D&amp;ust=1578461385224000">F.flip</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.flip&amp;sa=D&amp;ust=1578461385224000">torch.flip</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.fliplr.html%23chainer.functions.fliplr&amp;sa=D&amp;ust=1578461385225000">F.fliplr</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.flip&amp;sa=D&amp;ust=1578461385226000">torch.flip</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Use dims=1</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.flipud.html%23chainer.functions.flipud&amp;sa=D&amp;ust=1578461385227000">F.flipud</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.flip&amp;sa=D&amp;ust=1578461385227000">torch.flip</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Use dims=0</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.get_item.html%23chainer.functions.get_item&amp;sa=D&amp;ust=1578461385228000">F.get_item</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Use direct indexing: `x[indexes]`. Negative strides are not supported.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.hstack.html%23chainer.functions.hstack&amp;sa=D&amp;ust=1578461385229000">F.hstack</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Rewrite as:</span></p><p class="c4 c10"><span class="c3 c35"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.cat&amp;sa=D&amp;ust=1578461385230000">torch.cat</a></span><span class="c53 c35 c15">([a,b],dim=1)</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.im2col.html%23chainer.functions.im2col&amp;sa=D&amp;ust=1578461385231000">F.im2col</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.unfold&amp;sa=D&amp;ust=1578461385231000">F.unfold</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">NCHW is only supported</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.moveaxis.html%23chainer.functions.moveaxis&amp;sa=D&amp;ust=1578461385232000">F.moveaxis</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23Tensor.permute&amp;sa=D&amp;ust=1578461385233000">Tensor.permute</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">See: </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/swap-axes-in-pytorch/970/2&amp;sa=D&amp;ust=1578461385233000">https://discuss.pytorch.org/t/swap-axes-in-pytorch/970/2</a></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.pad.html%23chainer.functions.pad&amp;sa=D&amp;ust=1578461385234000">F.pad</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.pad&amp;sa=D&amp;ust=1578461385234000">F.pad</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Replace `constant_values` argument with `value`. Modes other than `constant` are also available.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.pad_sequence.html%23chainer.functions.pad_sequence&amp;sa=D&amp;ust=1578461385235000">F.pad_sequence</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html?highlight%3Dpad_sequence%23torch.nn.utils.rnn.pad_sequence&amp;sa=D&amp;ust=1578461385236000">nn.utils.rnn.pad_squence</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">You cannot specify the length but the maximum length among the inputs is used.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.permutate.html%23chainer.functions.permutate&amp;sa=D&amp;ust=1578461385237000">F.permutate</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/tensors.html%23torch.Tensor.permute&amp;sa=D&amp;ust=1578461385237000">Tensor.permute</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.repeat.html%23chainer.functions.repeat&amp;sa=D&amp;ust=1578461385238000">F.repeat</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/tensors.html%23torch.Tensor.repeat&amp;sa=D&amp;ust=1578461385238000">Tensor.repeat</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Different behavior to F.repeat. F.tile is more similar.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.reshape.html%23chainer.functions.reshape&amp;sa=D&amp;ust=1578461385239000">F.reshape</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.reshape&amp;sa=D&amp;ust=1578461385240000">torch.reshape</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.resize_images.html%23chainer.functions.resize_images&amp;sa=D&amp;ust=1578461385241000">F.resize_images</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.interpolate&amp;sa=D&amp;ust=1578461385241000">F.interpolate</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.rollaxis.html%23chainer.functions.rollaxis&amp;sa=D&amp;ust=1578461385242000">F.rollaxis</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/tensors.html%23torch.Tensor.permute&amp;sa=D&amp;ust=1578461385242000">Tensor.premute</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">See </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/swap-axes-in-pytorch/970/2&amp;sa=D&amp;ust=1578461385243000">https://discuss.pytorch.org/t/swap-axes-in-pytorch/970/2</a></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.scatter_add.html%23chainer.functions.scatter_add&amp;sa=D&amp;ust=1578461385244000">F.scatter_add</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/tensors.html%23torch.Tensor.scatter_add&amp;sa=D&amp;ust=1578461385245000">Tensor.scatter_add</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.select_item.html%23chainer.functions.select_item&amp;sa=D&amp;ust=1578461385246000">F.select_item</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Rewrite as:</span></p><p class="c4 c10"><span class="c3 c35"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.gather&amp;sa=D&amp;ust=1578461385247000">torch.gather</a></span><span class="c53 c35 c15">(x, 1, t[:, None])[:, 0]</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.separate.html%23chainer.functions.separate&amp;sa=D&amp;ust=1578461385247000">F.separate</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.split&amp;sa=D&amp;ust=1578461385248000">torch.split</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Requires manual manipulation of the results to achieve some of the separate functionality.</span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.space2depth.html%23chainer.functions.space2depth&amp;sa=D&amp;ust=1578461385249000">F.space2depth</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">You need to implement it yourself. Ref:</span></p><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/is-there-any-layer-like-tensorflows-space-to-depth-function/3487/14&amp;sa=D&amp;ust=1578461385250000">https://discuss.pytorch.org/t/is-there-any-layer-like-tensorflows-space-to-depth-function/3487/14</a></span></p></td></tr><tr class="c68"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.spatial_transformer_grid.html%23chainer.functions.spatial_transformer_grid&amp;sa=D&amp;ust=1578461385251000">F.spatial_transformer_grid</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.affine_grid&amp;sa=D&amp;ust=1578461385251000">F.affine_grid</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">The second argument `size` takes `torch.Size` object that denotes the target output image size (N, C, H, W), while `F.spatial_transformer_grid` takes just a tuple of (H, W). The size of returned tensor is also different: (N x H x W x 2) is returned instead of (N x 2 x H x W). Also note the breaking change regarding align_corners in v1.3.0 (</span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/releases/tag/v1.3.0&amp;sa=D&amp;ust=1578461385252000">https://github.com/pytorch/pytorch/releases/tag/v1.3.0</a></span><span class="c0">)</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.spatial_transformer_sampler.html%23chainer.functions.spatial_transformer_sampler&amp;sa=D&amp;ust=1578461385252000">F.spatial_transformer_sampler</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.grid_sample&amp;sa=D&amp;ust=1578461385253000">F.grid_sample</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Grid shape is (N, 2, H, W) in Chainer while (N, H, W, 2) in PyTorch.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.split_axis.html%23chainer.functions.split_axis&amp;sa=D&amp;ust=1578461385254000">F.split_axis</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.split&amp;sa=D&amp;ust=1578461385255000">torch.split</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">No `force_tuple`.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.squeeze.html%23chainer.functions.squeeze&amp;sa=D&amp;ust=1578461385256000">F.squeeze</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.squeeze&amp;sa=D&amp;ust=1578461385256000">torch.squeeze</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.stack.html%23chainer.functions.stack&amp;sa=D&amp;ust=1578461385257000">F.stack</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.stack&amp;sa=D&amp;ust=1578461385257000">torch.stack</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">Use </span><span class="c3 c35"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.stack&amp;sa=D&amp;ust=1578461385258000">torch.stack</a></span><span class="c15">&nbsp;or </span><span class="c3 c35"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.cat&amp;sa=D&amp;ust=1578461385258000">torch.cat</a></span><span class="c53 c35 c15">([a,b],dim=axis)</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.swapaxes.html%23chainer.functions.swapaxes&amp;sa=D&amp;ust=1578461385259000">F.swapaxes</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">Use permute instead: </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/swap-axes-in-pytorch/970/7&amp;sa=D&amp;ust=1578461385260000">https://discuss.pytorch.org/t/swap-axes-in-pytorch/970/7</a></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.tile.html%23chainer.functions.tile&amp;sa=D&amp;ust=1578461385260000">F.tile</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.repeat&amp;sa=D&amp;ust=1578461385261000">F.repeat</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.transpose.html%23chainer.functions.transpose&amp;sa=D&amp;ust=1578461385262000">F.transpose</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.t&amp;sa=D&amp;ust=1578461385262000">torch.t</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">Use </span><span class="c3 c35"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.t%2520/%2520Tensor.permute&amp;sa=D&amp;ust=1578461385263000">Tensor.permute</a></span><span class="c15">&nbsp;or </span><span class="c3 c35"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.t&amp;sa=D&amp;ust=1578461385263000">torch.t</a></span><span class="c0">&nbsp;for no axes version</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.transpose_sequence.html%23chainer.functions.transpose_sequence&amp;sa=D&amp;ust=1578461385264000">F.transpose_sequence</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.vstack.html%23chainer.functions.vstack&amp;sa=D&amp;ust=1578461385266000">F.vstack</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Rewrite as:</span></p><p class="c4 c10"><span class="c3 c35"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.cat&amp;sa=D&amp;ust=1578461385267000">torch.cat</a></span><span class="c53 c35 c15">([a,b],dim=0)</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.where.html%23chainer.functions.where&amp;sa=D&amp;ust=1578461385268000">F.where</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.where&amp;sa=D&amp;ust=1578461385268000">torch.where</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c65"><td class="c19" colspan="3" rowspan="1"><p class="c4 c10"><span class="c36 c15">Neural network connections</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.bilinear.html%23chainer.functions.bilinear&amp;sa=D&amp;ust=1578461385270000">F.bilinear</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.bilinear&amp;sa=D&amp;ust=1578461385271000">F.bilinear</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.convolution_1d.html%23chainer.functions.convolution_1d&amp;sa=D&amp;ust=1578461385272000">F.convolution_1d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.conv1d&amp;sa=D&amp;ust=1578461385272000">F.conv1d</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">No `cover_all`.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.convolution_2d.html%23chainer.functions.convolution_2d&amp;sa=D&amp;ust=1578461385273000">F.convolution_2d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.conv2d&amp;sa=D&amp;ust=1578461385274000">F.conv2d</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">No `cover_all`.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.convolution_3d.html%23chainer.functions.convolution_3d&amp;sa=D&amp;ust=1578461385274000">F.convolution_3d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.conv3d&amp;sa=D&amp;ust=1578461385275000">F.conv3d</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">No `cover_all`.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.convolution_nd.html%23chainer.functions.convolution_nd&amp;sa=D&amp;ust=1578461385276000">F.convolution_nd</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">See </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/is-there-a-way-to-realize-4d-convolution-using-the-convnd-function/5999&amp;sa=D&amp;ust=1578461385277000">https://discuss.pytorch.org/t/is-there-a-way-to-realize-4d-convolution-using-the-convnd-function/5999</a></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.deconvolution_1d.html%23chainer.functions.deconvolution_1d&amp;sa=D&amp;ust=1578461385277000">F.deconvolution_1d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.conv_transpose1d&amp;sa=D&amp;ust=1578461385278000">F.conv_transpose1d</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.deconvolution_2d.html%23chainer.functions.deconvolution_2d&amp;sa=D&amp;ust=1578461385279000">F.deconvolution_2d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.conv_transpose2d&amp;sa=D&amp;ust=1578461385280000">F.conv_transpose2d</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.deconvolution_3d.html%23chainer.functions.deconvolution_3d&amp;sa=D&amp;ust=1578461385281000">F.deconvolution_3d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.conv_transpose3d&amp;sa=D&amp;ust=1578461385281000">F.conv_transpose3d</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.deconvolution_nd.html%23chainer.functions.deconvolution_nd&amp;sa=D&amp;ust=1578461385282000">F.deconvolution_nd</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">N/A, see </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/is-there-a-way-to-realize-4d-convolution-using-the-convnd-function/5999&amp;sa=D&amp;ust=1578461385283000">https://discuss.pytorch.org/t/is-there-a-way-to-realize-4d-convolution-using-the-convnd-function/5999</a></span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.depthwise_convolution_2d.html%23chainer.functions.depthwise_convolution_2d&amp;sa=D&amp;ust=1578461385283000">F.depthwise_convolution_2d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.conv2d&amp;sa=D&amp;ust=1578461385284000">F.conv2d</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">Use `groups` argument; see </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/depthwise-and-separable-convolutions-in-pytorch/7315/2&amp;sa=D&amp;ust=1578461385284000">https://discuss.pytorch.org/t/depthwise-and-separable-convolutions-in-pytorch/7315/2</a></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.deformable_convolution_2d_sampler.html%23chainer.functions.deformable_convolution_2d_sampler&amp;sa=D&amp;ust=1578461385285000">F.deformable_convolution_2d_sampler</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">Not implemented: </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/issues/2260&amp;sa=D&amp;ust=1578461385286000">https://github.com/pytorch/pytorch/issues/2260</a></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.dilated_convolution_2d.html%23chainer.functions.dilated_convolution_2d&amp;sa=D&amp;ust=1578461385286000">F.dilated_convolution_2d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.conv2d&amp;sa=D&amp;ust=1578461385287000">F.conv2d</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Use `dilation` argument.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.embed_id.html%23chainer.functions.embed_id&amp;sa=D&amp;ust=1578461385288000">F.embed_id</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.embedding&amp;sa=D&amp;ust=1578461385288000">F.embedding</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.linear.html%23chainer.functions.linear&amp;sa=D&amp;ust=1578461385289000">F.linear</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.linear&amp;sa=D&amp;ust=1578461385290000">F.linear</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">There is no option for `n_batch_axes`.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.local_convolution_2d.html%23chainer.functions.local_convolution_2d&amp;sa=D&amp;ust=1578461385291000">F.local_convolution_2d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">See </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/pull/1583&amp;sa=D&amp;ust=1578461385292000">https://github.com/pytorch/pytorch/pull/1583</a></span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.n_step_bigru.html%23chainer.functions.n_step_bigru&amp;sa=D&amp;ust=1578461385292000">F.n_step_bigru</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">Undocumented _C._VariableFunctions function torch.gru? The &quot;link&quot; is available </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.GRU&amp;sa=D&amp;ust=1578461385293000">https://pytorch.org/docs/stable/nn.html#torch.nn.GRU</a></span><span class="c0">&nbsp;and this is probably the expected usage.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.n_step_bilstm.html%23chainer.functions.n_step_bilstm&amp;sa=D&amp;ust=1578461385294000">F.n_step_bilstm</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">See L.NStepBiLSTM.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.n_step_birnn.html%23chainer.functions.n_step_birnn&amp;sa=D&amp;ust=1578461385295000">F.n_step_birnn</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">See L.NStepBiRNNTanh or L.NStepBiRNNReLU.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.n_step_gru.html%23chainer.functions.n_step_gru&amp;sa=D&amp;ust=1578461385296000">F.n_step_gru</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">See L.NStepBiGRU.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.n_step_lstm.html%23chainer.functions.n_step_lstm&amp;sa=D&amp;ust=1578461385297000">F.n_step_lstm</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">See L.NStepLSTM.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.n_step_rnn.html%23chainer.functions.n_step_rnn&amp;sa=D&amp;ust=1578461385299000">F.n_step_rnn</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">See L.NStepRNNTanh or L.NStepRNNReLU.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.shift.html%23chainer.functions.shift&amp;sa=D&amp;ust=1578461385300000">F.shift</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">See </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/issues/16408&amp;sa=D&amp;ust=1578461385301000">https://github.com/pytorch/pytorch/issues/16408</a></span></p></td></tr><tr class="c20"><td class="c19" colspan="3" rowspan="1"><p class="c4 c10"><span class="c36 c15">Evaluation functions</span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.accuracy.html%23chainer.functions.accuracy&amp;sa=D&amp;ust=1578461385302000">F.accuracy</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">N/A, Ignite has an implementation: </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/ignite/metrics.html%23ignite.metrics.Accuracy&amp;sa=D&amp;ust=1578461385303000">https://pytorch.org/ignite/metrics.html#ignite.metrics.Accuracy</a></span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.binary_accuracy.html%23chainer.functions.binary_accuracy&amp;sa=D&amp;ust=1578461385304000">F.binary_accuracy</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">N/A, Ignite has an implementation: </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/ignite/metrics.html%23ignite.metrics.Accuracy&amp;sa=D&amp;ust=1578461385305000">https://pytorch.org/ignite/metrics.html#ignite.metrics.Accuracy</a></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.classification_summary.html%23chainer.functions.classification_summary&amp;sa=D&amp;ust=1578461385305000">F.classification_summary</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.f1_score.html%23chainer.functions.f1_score&amp;sa=D&amp;ust=1578461385307000">F.f1_score</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">See </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/calculating-precision-recall-and-f1-score-in-case-of-multi-label-classification/28265/1&amp;sa=D&amp;ust=1578461385307000">https://discuss.pytorch.org/t/calculating-precision-recall-and-f1-score-in-case-of-multi-label-classification/28265/1</a></span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.precision.html%23chainer.functions.precision&amp;sa=D&amp;ust=1578461385308000">F.precision</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">N/A, Ignite has an implementation: </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/ignite/metrics.html%23ignite.metrics.Precision&amp;sa=D&amp;ust=1578461385309000">https://pytorch.org/ignite/metrics.html#ignite.metrics.Precision</a></span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.r2_score.html%23chainer.functions.r2_score&amp;sa=D&amp;ust=1578461385310000">F.r2_score</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">Not available. It&#39;s an evaluation metric that&#39;s not differentiable. It&#39;s implemented in Ignite though and could be used (as a reference) </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/ignite/pull/496&amp;sa=D&amp;ust=1578461385310000">https://github.com/pytorch/ignite/pull/496</a></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.recall.html%23chainer.functions.recall&amp;sa=D&amp;ust=1578461385311000">F.recall</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">N/A, Ignite has an implementation: </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/ignite/metrics.html%23ignite.metrics.Recall&amp;sa=D&amp;ust=1578461385312000">https://pytorch.org/ignite/metrics.html#ignite.metrics.Recall</a></span></p></td></tr><tr class="c20"><td class="c19" colspan="3" rowspan="1"><p class="c4 c10"><span class="c36 c15">Loss functions</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.absolute_error.html%23chainer.functions.absolute_error&amp;sa=D&amp;ust=1578461385313000">F.absolute_error</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.bernoulli_nll.html%23chainer.functions.bernoulli_nll&amp;sa=D&amp;ust=1578461385314000">F.bernoulli_nll</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Possibly: -torch.distributions.Bernoulli(y).log_prob(x).sum()</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.black_out.html%23chainer.functions.black_out&amp;sa=D&amp;ust=1578461385315000">F.black_out</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.connectionist_temporal_classification.html%23chainer.functions.connectionist_temporal_classification&amp;sa=D&amp;ust=1578461385316000">F.connectionist_temporal_classification</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.ctc_loss&amp;sa=D&amp;ust=1578461385317000">F.ctc_loss</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.contrastive.html%23chainer.functions.contrastive&amp;sa=D&amp;ust=1578461385318000">F.contrastive</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">See </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/adambielski/siamese-triplet&amp;sa=D&amp;ust=1578461385319000">https://github.com/adambielski/siamese-triplet</a></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.crf1d.html%23chainer.functions.crf1d&amp;sa=D&amp;ust=1578461385319000">F.crf1d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">Not available: </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/issues/11134&amp;sa=D&amp;ust=1578461385320000">https://github.com/pytorch/pytorch/issues/11134</a></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.argmax_crf1d.html%23chainer.functions.argmax_crf1d&amp;sa=D&amp;ust=1578461385321000">F.argmax_crf1d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">Not available: </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/issues/11134&amp;sa=D&amp;ust=1578461385322000">https://github.com/pytorch/pytorch/issues/11134</a></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.cross_covariance.html%23chainer.functions.cross_covariance&amp;sa=D&amp;ust=1578461385322000">F.cross_covariance</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.decov.html%23chainer.functions.decov&amp;sa=D&amp;ust=1578461385323000">F.decov</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.discriminative_margin_based_clustering_loss.html%23chainer.functions.discriminative_margin_based_clustering_loss&amp;sa=D&amp;ust=1578461385325000">F.discriminative_margin_based_clustering_loss</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">Not available. See </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/Wizaron/instance-segmentation-pytorch&amp;sa=D&amp;ust=1578461385325000">https://github.com/Wizaron/instance-segmentation-pytorch</a></span><span class="c0">&nbsp;for a reproducing work.</span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.gaussian_kl_divergence.html%23chainer.functions.gaussian_kl_divergence&amp;sa=D&amp;ust=1578461385326000">F.gaussian_kl_divergence</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.gaussian_nll.html%23chainer.functions.gaussian_nll&amp;sa=D&amp;ust=1578461385327000">F.gaussian_nll</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.hinge.html%23chainer.functions.hinge&amp;sa=D&amp;ust=1578461385328000">F.hinge</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23hinge-embedding-loss&amp;sa=D&amp;ust=1578461385329000">F.hinge_embedding_loss</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.huber_loss.html%23chainer.functions.huber_loss&amp;sa=D&amp;ust=1578461385330000">F.huber_loss</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.smooth_l1_loss&amp;sa=D&amp;ust=1578461385330000">F.smooth_l1_loss</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Use reduction=&#39;sum&#39; to keep reduction method</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.mean_absolute_error.html%23chainer.functions.mean_absolute_error&amp;sa=D&amp;ust=1578461385331000">F.mean_absolute_error</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.l1_loss&amp;sa=D&amp;ust=1578461385332000">F.l1_loss</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">See also: ignite.metrics.MeanAbsoluteError</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.mean_squared_error.html%23chainer.functions.mean_squared_error&amp;sa=D&amp;ust=1578461385333000">F.mean_squared_error</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.mse_loss&amp;sa=D&amp;ust=1578461385334000">F.mse_loss</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.negative_sampling.html%23chainer.functions.negative_sampling&amp;sa=D&amp;ust=1578461385335000">F.negative_sampling</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">See </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/kefirski/pytorch_NEG_loss&amp;sa=D&amp;ust=1578461385336000">https://github.com/kefirski/pytorch_NEG_loss</a></span><span class="c15">, </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/theeluwin/pytorch-sgns&amp;sa=D&amp;ust=1578461385336000">https://github.com/theeluwin/pytorch-sgns</a></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.sigmoid_cross_entropy.html%23chainer.functions.sigmoid_cross_entropy&amp;sa=D&amp;ust=1578461385337000">F.sigmoid_cross_entropy</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.binary_cross_entropy_with_logits&amp;sa=D&amp;ust=1578461385337000">F.binary_cross_entropy_with_logits</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.softmax_cross_entropy.html%23chainer.functions.softmax_cross_entropy&amp;sa=D&amp;ust=1578461385338000">F.softmax_cross_entropy</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.CrossEntropyLoss&amp;sa=D&amp;ust=1578461385339000">nn.CrossEntropyLoss</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.squared_error.html%23chainer.functions.squared_error&amp;sa=D&amp;ust=1578461385340000">F.squared_error</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.triplet.html%23chainer.functions.triplet&amp;sa=D&amp;ust=1578461385341000">F.triplet</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.triplet_margin_loss&amp;sa=D&amp;ust=1578461385343000">F.triplet_margin_loss</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c19" colspan="3" rowspan="1"><p class="c4 c10"><span class="c36 c15">Mathematical functions</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.absolute.html%23chainer.functions.absolute&amp;sa=D&amp;ust=1578461385345000">F.absolute</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.abs&amp;sa=D&amp;ust=1578461385345000">torch.abs</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.arccos.html%23chainer.functions.arccos&amp;sa=D&amp;ust=1578461385346000">F.arccos</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.acos&amp;sa=D&amp;ust=1578461385347000">torch.acos</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.arcsin.html%23chainer.functions.arcsin&amp;sa=D&amp;ust=1578461385348000">F.arcsin</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.asin&amp;sa=D&amp;ust=1578461385348000">torch.asin</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.arctan.html%23chainer.functions.arctan&amp;sa=D&amp;ust=1578461385349000">F.arctan</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.atan&amp;sa=D&amp;ust=1578461385350000">torch.atan</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.arctan2.html%23chainer.functions.arctan2&amp;sa=D&amp;ust=1578461385350000">F.arctan2</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.atan2&amp;sa=D&amp;ust=1578461385351000">torch.atan2</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.arctanh.html%23chainer.functions.arctanh&amp;sa=D&amp;ust=1578461385352000">F.arctanh</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">N/A: </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/issues/10324&amp;sa=D&amp;ust=1578461385353000">https://github.com/pytorch/pytorch/issues/10324</a></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.argmax.html%23chainer.functions.argmax&amp;sa=D&amp;ust=1578461385353000">F.argmax</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.argmax&amp;sa=D&amp;ust=1578461385354000">torch.argmax</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.argmin.html%23chainer.functions.argmin&amp;sa=D&amp;ust=1578461385355000">F.argmin</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.argmin&amp;sa=D&amp;ust=1578461385355000">torch.argmin</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.average.html%23chainer.functions.average&amp;sa=D&amp;ust=1578461385356000">F.average</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">See F.mean.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.batch_inv.html%23chainer.functions.batch_inv&amp;sa=D&amp;ust=1578461385358000">F.batch_inv</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.inverse&amp;sa=D&amp;ust=1578461385359000">torch.inverse</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">linalg ops batch is on progress, inverse is already merged</span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.batch_l2_norm_squared.html%23chainer.functions.batch_l2_norm_squared&amp;sa=D&amp;ust=1578461385360000">F.batch_l2_norm_squared</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Rewrite as:</span></p><p class="c4 c10"><span class="c53 c35 c15">x.reshape(len(x), -1).norm(dim=1) ** 2</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.batch_matmul.html%23chainer.functions.batch_matmul&amp;sa=D&amp;ust=1578461385362000">F.batch_matmul</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.matmul&amp;sa=D&amp;ust=1578461385362000">torch.matmul</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.bias.html%23chainer.functions.bias&amp;sa=D&amp;ust=1578461385363000">F.bias</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Rewrite as</span></p><p class="c4 c10"><span class="c53 c35 c15">x + y[(...,) + (None,) * (x.ndim - y.ndim - axis)]</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.ceil.html%23chainer.functions.ceil&amp;sa=D&amp;ust=1578461385365000">F.ceil</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.ceil&amp;sa=D&amp;ust=1578461385365000">torch.ceil</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.clip.html%23chainer.functions.clip&amp;sa=D&amp;ust=1578461385367000">F.clip</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.clamp&amp;sa=D&amp;ust=1578461385367000">torch.clamp</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.cos.html%23chainer.functions.cos&amp;sa=D&amp;ust=1578461385368000">F.cos</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.cos&amp;sa=D&amp;ust=1578461385369000">torch.cos</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.cosh.html%23chainer.functions.cosh&amp;sa=D&amp;ust=1578461385370000">F.cosh</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.cosh&amp;sa=D&amp;ust=1578461385371000">torch.cosh</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.cumprod.html%23chainer.functions.cumprod&amp;sa=D&amp;ust=1578461385372000">F.cumprod</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.cumprod&amp;sa=D&amp;ust=1578461385373000">torch.cumprod</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.cumsum.html%23chainer.functions.cumsum&amp;sa=D&amp;ust=1578461385373000">F.cumsum</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.cumsum&amp;sa=D&amp;ust=1578461385374000">torch.cumsum</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.det.html%23chainer.functions.det&amp;sa=D&amp;ust=1578461385375000">F.det</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.det&amp;sa=D&amp;ust=1578461385375000">torch.det</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.batch_det.html%23chainer.functions.batch_det&amp;sa=D&amp;ust=1578461385376000">F.batch_det</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.det&amp;sa=D&amp;ust=1578461385377000">torch.det</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Arbitrary number of batch axes are supported.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.digamma.html%23chainer.functions.digamma&amp;sa=D&amp;ust=1578461385378000">F.digamma</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.digamma&amp;sa=D&amp;ust=1578461385378000">torch.digamma</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.einsum.html%23chainer.functions.einsum&amp;sa=D&amp;ust=1578461385379000">F.einsum</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.einsum&amp;sa=D&amp;ust=1578461385380000">torch.einsum</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.erf.html%23chainer.functions.erf&amp;sa=D&amp;ust=1578461385381000">F.erf</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.erf&amp;sa=D&amp;ust=1578461385382000">torch.erf</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.erfc.html%23chainer.functions.erfc&amp;sa=D&amp;ust=1578461385383000">F.erfc</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.erfc&amp;sa=D&amp;ust=1578461385383000">torch.erfc</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.erfcinv.html%23chainer.functions.erfcinv&amp;sa=D&amp;ust=1578461385384000">F.erfcinv</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">Not available. Implement it similar to erf, erfinv? </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/pull/2799&amp;sa=D&amp;ust=1578461385385000">https://github.com/pytorch/pytorch/pull/2799</a></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.erfcx.html%23chainer.functions.erfcx&amp;sa=D&amp;ust=1578461385386000">F.erfcx</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.erfinv.html%23chainer.functions.erfinv&amp;sa=D&amp;ust=1578461385387000">F.erfinv</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.erfinv&amp;sa=D&amp;ust=1578461385387000">torch.erfinv</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.exp.html%23chainer.functions.exp&amp;sa=D&amp;ust=1578461385388000">F.exp</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.exp&amp;sa=D&amp;ust=1578461385389000">torch.exp</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.expm1.html%23chainer.functions.expm1&amp;sa=D&amp;ust=1578461385390000">F.expm1</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.expm1&amp;sa=D&amp;ust=1578461385390000">torch.expm1</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.fft.html%23chainer.functions.fft&amp;sa=D&amp;ust=1578461385391000">F.fft</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.fft&amp;sa=D&amp;ust=1578461385392000">torch.fft</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Interface is quite different.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.fix.html%23chainer.functions.fix&amp;sa=D&amp;ust=1578461385392000">F.fix</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.fmod.html%23chainer.functions.fmod&amp;sa=D&amp;ust=1578461385394000">F.fmod</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.fmod&amp;sa=D&amp;ust=1578461385394000">torch.fmod</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.floor.html%23chainer.functions.floor&amp;sa=D&amp;ust=1578461385395000">F.floor</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.floor&amp;sa=D&amp;ust=1578461385395000">torch.floor</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.identity.html%23chainer.functions.identity&amp;sa=D&amp;ust=1578461385396000">F.identity</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Identity&amp;sa=D&amp;ust=1578461385397000">nn.Identity</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.ifft.html%23chainer.functions.ifft&amp;sa=D&amp;ust=1578461385398000">F.ifft</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.ifft&amp;sa=D&amp;ust=1578461385398000">torch.ifft</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.inv.html%23chainer.functions.inv&amp;sa=D&amp;ust=1578461385399000">F.inv</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.inverse&amp;sa=D&amp;ust=1578461385400000">torch.inverse</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.lgamma.html%23chainer.functions.lgamma&amp;sa=D&amp;ust=1578461385401000">F.lgamma</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/cppdocs/api/function_namespaceat_1ae80021c749d42d0625e90973b18a00bc.html%23_CPPv4N2at6lgammaERK6Tensor&amp;sa=D&amp;ust=1578461385401000">torch.lgamma</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">Currently undocumented: </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/pull/27812&amp;sa=D&amp;ust=1578461385402000">https://github.com/pytorch/pytorch/pull/27812</a></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.linear_interpolate.html%23chainer.functions.linear_interpolate&amp;sa=D&amp;ust=1578461385403000">F.linear_interpolate</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Normal math should suffice.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.log.html%23chainer.functions.log&amp;sa=D&amp;ust=1578461385404000">F.log</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.log&amp;sa=D&amp;ust=1578461385405000">torch.log</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.log10.html%23chainer.functions.log10&amp;sa=D&amp;ust=1578461385406000">F.log10</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.log10&amp;sa=D&amp;ust=1578461385407000">torch.log10</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.log1p.html%23chainer.functions.log1p&amp;sa=D&amp;ust=1578461385409000">F.log1p</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.log1p&amp;sa=D&amp;ust=1578461385410000">torch.log1p</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.log2.html%23chainer.functions.log2&amp;sa=D&amp;ust=1578461385411000">F.log2</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.log2&amp;sa=D&amp;ust=1578461385412000">torch.log2</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.log_ndtr.html%23chainer.functions.log_ndtr&amp;sa=D&amp;ust=1578461385414000">F.log_ndtr</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.logsumexp.html%23chainer.functions.logsumexp&amp;sa=D&amp;ust=1578461385416000">F.logsumexp</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.logsumexp&amp;sa=D&amp;ust=1578461385417000">torch.logsumexp</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.matmul.html%23chainer.functions.matmul&amp;sa=D&amp;ust=1578461385419000">F.matmul</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.matmul&amp;sa=D&amp;ust=1578461385420000">torch.matmul</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.max.html%23chainer.functions.max&amp;sa=D&amp;ust=1578461385421000">F.max</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.max&amp;sa=D&amp;ust=1578461385421000">torch.max</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.maximum.html%23chainer.functions.maximum&amp;sa=D&amp;ust=1578461385422000">F.maximum</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.max&amp;sa=D&amp;ust=1578461385423000">torch.max</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.mean.html%23chainer.functions.mean&amp;sa=D&amp;ust=1578461385425000">F.mean</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.mean&amp;sa=D&amp;ust=1578461385426000">torch.mean</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Weighted average is not supported; rewrite as (without keepdims):</span></p><p class="c4 c10"><span class="c3 c35"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.tensordot&amp;sa=D&amp;ust=1578461385427000">torch.tensordot</a></span><span class="c53 c35 c15">(x, weights / weights.sum(), ([axis], [0]))</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.min.html%23chainer.functions.min&amp;sa=D&amp;ust=1578461385428000">F.min</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.min&amp;sa=D&amp;ust=1578461385428000">torch.min</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.minimum.html%23chainer.functions.minimum&amp;sa=D&amp;ust=1578461385430000">F.minimum</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.min&amp;sa=D&amp;ust=1578461385430000">torch.min</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.ndtr.html%23chainer.functions.ndtr&amp;sa=D&amp;ust=1578461385431000">F.ndtr</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23gelu&amp;sa=D&amp;ust=1578461385432000">F.gelu</a></span><span class="c0">(x) is corresponding to x * F.ndtr(x).</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.ndtri.html%23chainer.functions.ndtri&amp;sa=D&amp;ust=1578461385433000">F.ndtri</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.prod.html%23chainer.functions.prod&amp;sa=D&amp;ust=1578461385434000">F.prod</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.prod&amp;sa=D&amp;ust=1578461385435000">torch.prod</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c80"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.polygamma.html%23chainer.functions.polygamma&amp;sa=D&amp;ust=1578461385436000">F.polygamma</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/cppdocs/api/function_namespaceat_1a98080f784a3c761958a42f273ac5cfd2.html&amp;sa=D&amp;ust=1578461385436000">torch.polygamma</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">Not documented: </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/issues/25347&amp;sa=D&amp;ust=1578461385437000">https://github.com/pytorch/pytorch/issues/25347</a></span></p><p class="c4 c10"><span class="c15">n&gt;=2 not supported: </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/blob/1a92b225db8519ab4697954a5559674f58e91aa7/aten/src/ATen/native/cpu/UnaryOpsKernel.cpp%23L187&amp;sa=D&amp;ust=1578461385437000">https://github.com/pytorch/pytorch/blob/1a92b225db8519ab4697954a5559674f58e91aa7/aten/src/ATen/native/cpu/UnaryOpsKernel.cpp#L187</a></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.rsqrt.html%23chainer.functions.rsqrt&amp;sa=D&amp;ust=1578461385438000">F.rsqrt</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.rsqrt&amp;sa=D&amp;ust=1578461385439000">torch.rsqrt</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">-</span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.scale.html%23chainer.functions.scale&amp;sa=D&amp;ust=1578461385439000">F.scale</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Rewrite as:</span></p><p class="c4 c10"><span class="c53 c35 c15">x * y[(...,) + (None,) * (x.ndim - y.ndim - 1)]</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.sin.html%23chainer.functions.sin&amp;sa=D&amp;ust=1578461385441000">F.sin</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.sin&amp;sa=D&amp;ust=1578461385442000">torch.sin</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.sinh.html%23chainer.functions.sinh&amp;sa=D&amp;ust=1578461385442000">F.sinh</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.sinh&amp;sa=D&amp;ust=1578461385443000">torch.sinh</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.sign.html%23chainer.functions.sign&amp;sa=D&amp;ust=1578461385444000">F.sign</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.sign&amp;sa=D&amp;ust=1578461385444000">torch.sign</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.sparse_matmul.html%23chainer.functions.sparse_matmul&amp;sa=D&amp;ust=1578461385445000">F.sparse_matmul</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/sparse.html%23torch.sparse.mm&amp;sa=D&amp;ust=1578461385446000">torch.sparse.mm</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Only support dense-sparse product. For sparse-dense product, transpose the operands and the output.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.sqrt.html%23chainer.functions.sqrt&amp;sa=D&amp;ust=1578461385447000">F.sqrt</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.sqrt&amp;sa=D&amp;ust=1578461385447000">torch.sqrt</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.square.html%23chainer.functions.square&amp;sa=D&amp;ust=1578461385448000">F.square</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Rewrite as:</span></p><p class="c4 c10"><span class="c53 c35 c15">x * x</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.squared_difference.html%23chainer.functions.squared_difference&amp;sa=D&amp;ust=1578461385450000">F.squared_difference</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.sum.html%23chainer.functions.sum&amp;sa=D&amp;ust=1578461385451000">F.sum</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.sum&amp;sa=D&amp;ust=1578461385451000">torch.sum</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.sum_to.html%23chainer.functions.sum_to&amp;sa=D&amp;ust=1578461385452000">F.sum_to</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.tanh.html%23chainer.functions.tanh&amp;sa=D&amp;ust=1578461385454000">F.tanh</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.tanh&amp;sa=D&amp;ust=1578461385454000">torch.tanh</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.tan.html%23chainer.functions.tan&amp;sa=D&amp;ust=1578461385455000">F.tan</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.tan&amp;sa=D&amp;ust=1578461385456000">torch.tan</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.tensordot.html%23chainer.functions.tensordot&amp;sa=D&amp;ust=1578461385456000">F.tensordot</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.tensordot&amp;sa=D&amp;ust=1578461385457000">torch.tensordot</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c19" colspan="3" rowspan="1"><p class="c4 c10"><span class="c36 c15">Noise injections</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.dropout.html%23chainer.functions.dropout&amp;sa=D&amp;ust=1578461385460000">F.dropout</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23dropout&amp;sa=D&amp;ust=1578461385461000">F.dropout</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">No mask support, elements are randomly zeroed.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.gaussian.html%23chainer.functions.gaussian&amp;sa=D&amp;ust=1578461385462000">F.gaussian</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.distributions.normal.Normal&amp;sa=D&amp;ust=1578461385463000">torch.distributions.normal.Normal</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.gumbel_softmax.html%23chainer.functions.gumbel_softmax&amp;sa=D&amp;ust=1578461385464000">F.gumbel_softmax</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.gumbel_softmax&amp;sa=D&amp;ust=1578461385465000">F.gumbel_softmax</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">The default value of tau is 1, while the Chainer&#39;s function takes 0.1.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.simplified_dropconnect.html%23chainer.functions.simplified_dropconnect&amp;sa=D&amp;ust=1578461385466000">F.simplified_dropconnect</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Not available. Use F.dropout on the weight, or try torchnlp.nn.WeightDrop.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.zoneout.html%23chainer.functions.zoneout&amp;sa=D&amp;ust=1578461385467000">F.zoneout</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c19" colspan="3" rowspan="1"><p class="c4 c10"><span class="c36 c15">Normalization functions</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.batch_normalization.html%23chainer.functions.batch_normalization&amp;sa=D&amp;ust=1578461385469000">F.batch_normalization</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.batch_norm&amp;sa=D&amp;ust=1578461385470000">F.batch_norm</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.batch_renormalization.html%23chainer.functions.batch_renormalization&amp;sa=D&amp;ust=1578461385471000">F.batch_renormalization</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.decorrelated_batch_normalization.html%23chainer.functions.decorrelated_batch_normalization&amp;sa=D&amp;ust=1578461385472000">F.decorrelated_batch_normalization</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.fixed_batch_normalization.html%23chainer.functions.fixed_batch_normalization&amp;sa=D&amp;ust=1578461385473000">F.fixed_batch_normalization</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.batch_norm&amp;sa=D&amp;ust=1578461385473000">F.batch_norm</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">training=False?</span></p></td></tr><tr class="c69"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.fixed_batch_renormalization.html%23chainer.functions.fixed_batch_renormalization&amp;sa=D&amp;ust=1578461385474000">F.fixed_batch_renormalization</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">Batch Renormalization not implemented: </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/support-for-batch-renormalization/29653&amp;sa=D&amp;ust=1578461385475000">https://discuss.pytorch.org/t/support-for-batch-renormalization/2965</a></span><span class="c15">, </span><span class="c15">&nbsp;</span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/batch-renormalization-implementation-in-thcunn/5144&amp;sa=D&amp;ust=1578461385476000">https://discuss.pytorch.org/t/batch-renormalization-implementation-in-thcunn/5144</a></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.fixed_decorrelated_batch_normalization.html%23chainer.functions.fixed_decorrelated_batch_normalization&amp;sa=D&amp;ust=1578461385476000">F.fixed_decorrelated_batch_normalization</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.group_normalization.html%23chainer.functions.group_normalization&amp;sa=D&amp;ust=1578461385478000">F.group_normalization</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.group_norm&amp;sa=D&amp;ust=1578461385478000">F.group_norm</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Currently undocumented.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.layer_normalization.html%23chainer.functions.layer_normalization&amp;sa=D&amp;ust=1578461385479000">F.layer_normalization</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.layer_norm&amp;sa=D&amp;ust=1578461385480000">layer_norm</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">`gamma = weight` &amp; `beta= bias`</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.local_response_normalization.html%23chainer.functions.local_response_normalization&amp;sa=D&amp;ust=1578461385481000">F.local_response_normalization</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.local_response_norm&amp;sa=D&amp;ust=1578461385481000">F.local_response_norm</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.normalize.html%23chainer.functions.normalize&amp;sa=D&amp;ust=1578461385482000">F.normalize</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.normalize&amp;sa=D&amp;ust=1578461385482000">F.normalize</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">The PyTorch&#39;s `F.normalize` is not only for L2 normalization. But the default behavior is for L2 normalization, i.e., the default value of the second argument `p` is set to 2.</span></p></td></tr><tr class="c20"><td class="c19" colspan="3" rowspan="1"><p class="c4 c10"><span class="c15 c36">Spatial pooling</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.average_pooling_1d.html%23chainer.functions.average_pooling_1d&amp;sa=D&amp;ust=1578461385484000">F.average_pooling_1d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.avg_pool1d&amp;sa=D&amp;ust=1578461385485000">F.avg_pool1d</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.average_pooling_2d.html%23chainer.functions.average_pooling_2d&amp;sa=D&amp;ust=1578461385486000">F.average_pooling_2d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.avg_pool2d&amp;sa=D&amp;ust=1578461385486000">F.avg_pool2d</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Superset of Chainer&#39;s counterpart.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.average_pooling_3d.html%23chainer.functions.average_pooling_3d&amp;sa=D&amp;ust=1578461385487000">F.average_pooling_3d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.avg_pool3d&amp;sa=D&amp;ust=1578461385488000">F.avg_pool3d</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.average_pooling_nd.html%23chainer.functions.average_pooling_nd&amp;sa=D&amp;ust=1578461385488000">F.average_pooling_nd</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">N/A</span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.max_pooling_1d.html%23chainer.functions.max_pooling_1d&amp;sa=D&amp;ust=1578461385490000">F.max_pooling_1d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.max_pool1d&amp;sa=D&amp;ust=1578461385490000">F.max_pool1d</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">In addition to arguments documented in `nn.MaxPool1D`, `return_indices` argument is available to obtain index for unpooling.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.max_pooling_2d.html%23chainer.functions.max_pooling_2d&amp;sa=D&amp;ust=1578461385491000">F.max_pooling_2d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.max_pool2d&amp;sa=D&amp;ust=1578461385492000">F.max_pool2d</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">ditto.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.max_pooling_3d.html%23chainer.functions.max_pooling_3d&amp;sa=D&amp;ust=1578461385493000">F.max_pooling_3d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.max_pool3d&amp;sa=D&amp;ust=1578461385493000">F.max_pool3d</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">ditto.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.max_pooling_nd.html%23chainer.functions.max_pooling_nd&amp;sa=D&amp;ust=1578461385494000">F.max_pooling_nd</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">N/A</span></p></td></tr><tr class="c51"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.roi_average_align_2d.html%23chainer.functions.roi_average_align_2d&amp;sa=D&amp;ust=1578461385495000">F.roi_average_align_2d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torchvision/ops.html%23torchvision.ops.roi_align&amp;sa=D&amp;ust=1578461385496000">torchvision.ops.roi_align</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Requires Torchvision, torchvision has only 2 roi functions, roi_align uses the average of the pixels while roi_pool uses the max value</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.roi_average_pooling_2d.html%23chainer.functions.roi_average_pooling_2d&amp;sa=D&amp;ust=1578461385497000">F.roi_average_pooling_2d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.roi_max_align_2d.html%23chainer.functions.roi_max_align_2d&amp;sa=D&amp;ust=1578461385498000">F.roi_max_align_2d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">N/A</span></p></td></tr><tr class="c68"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.roi_max_pooling_2d.html%23chainer.functions.roi_max_pooling_2d&amp;sa=D&amp;ust=1578461385499000">F.roi_max_pooling_2d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torchvision.ops.roi_pool&amp;sa=D&amp;ust=1578461385500000">torchvision.ops.roi_pool</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">The `roi_pool` function of Torchvision is meant to be roi max pooling according to the source: </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/vision/blob/ccd1b27d2b7312ebddb4d51b3a4f8ade1ba8fa8b/torchvision/csrc/cpu/ROIPool_cpu.cpp%23L65&amp;sa=D&amp;ust=1578461385500000">https://github.com/pytorch/vision/blob/ccd1b27d2b7312ebddb4d51b3a4f8ade1ba8fa8b/torchvision/csrc/cpu/ROIPool_cpu.cpp#L65</a></span></p><p class="c4 c10"><span class="c0">Regarding the API, the way to pass the batch indices of each set of RoI coordinates is different.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.roi_pooling_2d.html%23chainer.functions.roi_pooling_2d&amp;sa=D&amp;ust=1578461385501000">F.roi_pooling_2d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torchvision/ops.html%23torchvision.ops.roi_pool&amp;sa=D&amp;ust=1578461385502000">torchvision.ops.roi_pool</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Requires torchvision.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.spatial_pyramid_pooling_2d.html%23chainer.functions.spatial_pyramid_pooling_2d&amp;sa=D&amp;ust=1578461385503000">F.spatial_pyramid_pooling_2d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Not available. Not too difficult to implement? It&#39;s a combination of existing functions in Chainer.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.unpooling_1d.html%23chainer.functions.unpooling_1d&amp;sa=D&amp;ust=1578461385504000">F.unpooling_1d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.max_unpool1d&amp;sa=D&amp;ust=1578461385504000">F.max_unpool1d</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">Pass `indices` returned from F.max_pool1d.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.unpooling_2d.html%23chainer.functions.unpooling_2d&amp;sa=D&amp;ust=1578461385505000">F.unpooling_2d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.max_unpool2d&amp;sa=D&amp;ust=1578461385506000">F.max_unpool2d</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">ditto.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.unpooling_3d.html%23chainer.functions.unpooling_3d&amp;sa=D&amp;ust=1578461385507000">F.unpooling_3d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.max_unpool3d&amp;sa=D&amp;ust=1578461385507000">F.max_unpool3d</a></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">ditto.</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.unpooling_nd.html%23chainer.functions.unpooling_nd&amp;sa=D&amp;ust=1578461385508000">F.unpooling_nd</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.upsampling_2d.html%23chainer.functions.upsampling_2d&amp;sa=D&amp;ust=1578461385509000">F.upsampling_2d</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c19" colspan="3" rowspan="1"><p class="c4 c10"><span class="c36 c15">Utility functions</span></p></td></tr><tr class="c20"><td class="c8" colspan="1" rowspan="1"><p class="c4 c10"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.functions.forget.html%23chainer.functions.forget&amp;sa=D&amp;ust=1578461385511000">F.forget</a></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c4 c10 c29"><span class="c0"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c4 c10"><span class="c15">See </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/checkpoint.html&amp;sa=D&amp;ust=1578461385512000">https://pytorch.org/docs/stable/checkpoint.html</a></span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><h3 class="c23 c10" id="h.ryz2089jygqa"><span class="c36 c42">Links</span></h3><p class="c4 c10"><span class="c35">L</span><span>&nbsp;refers to </span><span class="c35">chainer.links</span><span>&nbsp;(Chainer), and </span><span class="c35">nn</span><span>&nbsp;refers to </span><span class="c35">torch.nn</span><span class="c6">&nbsp;(PyTorch).</span></p><p class="c4 c10 c29"><span class="c6"></span></p><a id="t.3b37620fdb6ced6923d1d3cbb3cd34113c1d0cb4"></a><a id="t.20"></a><table class="c30"><tbody><tr class="c51"><td class="c88 c105" colspan="1" rowspan="1"><p class="c64"><span class="c36 c15">Chainer</span></p></td><td class="c82" colspan="1" rowspan="1"><p class="c64"><span class="c36 c15">PyTorch</span></p></td><td class="c88 c108" colspan="1" rowspan="1"><p class="c64"><span class="c36 c15">Notes</span></p></td></tr><tr class="c20"><td class="c106" colspan="3" rowspan="1"><p class="c4"><span class="c33 c15">Learnable connections</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Bias.html%23chainer.links.Bias&amp;sa=D&amp;ust=1578461385518000">L.Bias</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Bilinear.html%23chainer.links.Bilinear&amp;sa=D&amp;ust=1578461385519000">L.Bilinear</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Bilinear&amp;sa=D&amp;ust=1578461385519000">nn.Bilinear</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c51"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.ChildSumTreeLSTM.html%23chainer.links.ChildSumTreeLSTM&amp;sa=D&amp;ust=1578461385520000">L.ChildSumTreeLSTM</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c15">N/A. Reference user implementation at: </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/ttpro1995/TreeLSTMSentiment&amp;sa=D&amp;ust=1578461385521000">https://github.com/ttpro1995/TreeLSTMSentiment</a></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Convolution1D.html%23chainer.links.Convolution1D&amp;sa=D&amp;ust=1578461385521000">L.Convolution1D</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Conv1d&amp;sa=D&amp;ust=1578461385522000">nn.Conv1d</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Convolution2D.html%23chainer.links.Convolution2D&amp;sa=D&amp;ust=1578461385523000">L.Convolution2D</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Conv2d&amp;sa=D&amp;ust=1578461385523000">nn.Conv2d</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Convolution3D.html%23chainer.links.Convolution3D&amp;sa=D&amp;ust=1578461385524000">L.Convolution3D</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Conv3d&amp;sa=D&amp;ust=1578461385525000">nn.Conv3d</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.ConvolutionND.html%23chainer.links.ConvolutionND&amp;sa=D&amp;ust=1578461385526000">L.ConvolutionND</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Deconvolution1D.html%23chainer.links.Deconvolution1D&amp;sa=D&amp;ust=1578461385527000">L.Deconvolution1D</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.ConvTranspose1d&amp;sa=D&amp;ust=1578461385528000">nn.ConvTranspose1d</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Deconvolution2D.html%23chainer.links.Deconvolution2D&amp;sa=D&amp;ust=1578461385529000">L.Deconvolution2D</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.ConvTranspose2d&amp;sa=D&amp;ust=1578461385529000">nn.ConvTranspose2d</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Deconvolution3D.html%23chainer.links.Deconvolution3D&amp;sa=D&amp;ust=1578461385530000">L.Deconvolution3D</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.ConvTranspose3d&amp;sa=D&amp;ust=1578461385531000">nn.ConvTranspose3d</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.DeconvolutionND.html%23chainer.links.DeconvolutionND&amp;sa=D&amp;ust=1578461385532000">L.DeconvolutionND</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.DeformableConvolution2D.html%23chainer.links.DeformableConvolution2D&amp;sa=D&amp;ust=1578461385533000">L.DeformableConvolution2D</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c15">N/A: </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/issues/2260&amp;sa=D&amp;ust=1578461385533000">https://github.com/pytorch/pytorch/issues/2260</a></span></p></td></tr><tr class="c69"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.DepthwiseConvolution2D.html%23chainer.links.DepthwiseConvolution2D&amp;sa=D&amp;ust=1578461385534000">L.DepthwiseConvolution2D</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Conv2d&amp;sa=D&amp;ust=1578461385535000">nn.Conv2d</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c15">Use `groups` argument; see </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://discuss.pytorch.org/t/depthwise-and-separable-convolutions-in-pytorch/7315/2&amp;sa=D&amp;ust=1578461385535000">https://discuss.pytorch.org/t/depthwise-and-separable-convolutions-in-pytorch/7315/2</a></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.DilatedConvolution2D.html%23chainer.links.DilatedConvolution2D&amp;sa=D&amp;ust=1578461385536000">L.DilatedConvolution2D</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Conv2d&amp;sa=D&amp;ust=1578461385536000">nn.Conv2d</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">Use `dilation` argument.</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.EmbedID.html%23chainer.links.EmbedID&amp;sa=D&amp;ust=1578461385537000">L.EmbedID</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Embedding&amp;sa=D&amp;ust=1578461385538000">nn.Embedding</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.GRU.html%23chainer.links.GRU&amp;sa=D&amp;ust=1578461385539000">L.GRU</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.GRU&amp;sa=D&amp;ust=1578461385539000">nn.GRU</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Highway.html%23chainer.links.Highway&amp;sa=D&amp;ust=1578461385540000">L.Highway</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">N/A</span></p></td></tr><tr class="c69"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Inception.html%23chainer.links.Inception&amp;sa=D&amp;ust=1578461385542000">L.Inception</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">`torchvision.models.inception.InceptionA` seems to be the corresponding module for Chainer&#39;s `L.Inception`, but is not documented.</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.InceptionBN.html%23chainer.links.InceptionBN&amp;sa=D&amp;ust=1578461385543000">L.InceptionBN</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">See torchvision.models.inception for Inception v3</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Linear.html%23chainer.links.Linear&amp;sa=D&amp;ust=1578461385544000">L.Linear</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Linear&amp;sa=D&amp;ust=1578461385544000">nn.Linear</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.LocalConvolution2D.html%23chainer.links.LocalConvolution2D&amp;sa=D&amp;ust=1578461385545000">L.LocalConvolution2D</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.LSTM.html%23chainer.links.LSTM&amp;sa=D&amp;ust=1578461385546000">L.LSTM</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.LSTM&amp;sa=D&amp;ust=1578461385547000">nn.LSTM</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.MLPConvolution2D.html%23chainer.links.MLPConvolution2D&amp;sa=D&amp;ust=1578461385548000">L.MLPConvolution2D</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.NaryTreeLSTM.html%23chainer.links.NaryTreeLSTM&amp;sa=D&amp;ust=1578461385549000">L.NaryTreeLSTM</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.NStepBiGRU.html%23chainer.links.NStepBiGRU&amp;sa=D&amp;ust=1578461385550000">L.NStepBiGRU</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.GRU&amp;sa=D&amp;ust=1578461385551000">nn.GRU</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">bidirectional=True, no explicit activation, no stacking</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.NStepBiLSTM.html%23chainer.links.NStepBiLSTM&amp;sa=D&amp;ust=1578461385552000">L.NStepBiLSTM</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.LSTM&amp;sa=D&amp;ust=1578461385552000">nn.LSTM</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">bidirectional=True, no explicit activation, no stacking</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.NStepBiRNNReLU.html%23chainer.links.NStepBiRNNReLU&amp;sa=D&amp;ust=1578461385553000">L.NStepBiRNNReLU</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.RNN&amp;sa=D&amp;ust=1578461385554000">nn.RNN</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">bidirectional=True, no explicit activation, no stacking</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.NStepBiRNNTanh.html%23chainer.links.NStepBiRNNTanh&amp;sa=D&amp;ust=1578461385555000">L.NStepBiRNNTanh</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.RNN&amp;sa=D&amp;ust=1578461385555000">nn.RNN</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">bidirectional=True, no explicit activation, no stacking</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.NStepGRU.html%23chainer.links.NStepGRU&amp;sa=D&amp;ust=1578461385556000">L.NStepGRU</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.torch.nn.GRU&amp;sa=D&amp;ust=1578461385557000">nn.GRU</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.NStepLSTM.html%23chainer.links.NStepLSTM&amp;sa=D&amp;ust=1578461385557000">L.NStepLSTM</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.LSTM&amp;sa=D&amp;ust=1578461385558000">nn.LSTM</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.NStepRNNReLU.html%23chainer.links.NStepRNNReLU&amp;sa=D&amp;ust=1578461385559000">L.NStepRNNReLU</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.RNN&amp;sa=D&amp;ust=1578461385559000">nn.RNN</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.NStepRNNTanh.html%23chainer.links.NStepRNNTanh&amp;sa=D&amp;ust=1578461385560000">L.NStepRNNTanh</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.RNN&amp;sa=D&amp;ust=1578461385561000">nn.RNN</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Parameter.html%23chainer.links.Parameter&amp;sa=D&amp;ust=1578461385562000">L.Parameter</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">You could use torch.nn.modules.ParameterList with 1 element</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Scale.html%23chainer.links.Scale&amp;sa=D&amp;ust=1578461385563000">L.Scale</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.StatefulGRU.html%23chainer.links.StatefulGRU&amp;sa=D&amp;ust=1578461385564000">L.StatefulGRU</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.GRU&amp;sa=D&amp;ust=1578461385564000">nn.GRU</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.StatelessGRU.html%23chainer.links.StatelessGRU&amp;sa=D&amp;ust=1578461385565000">L.StatelessGRU</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.StatefulMGU.html%23chainer.links.StatefulMGU&amp;sa=D&amp;ust=1578461385567000">L.StatefulMGU</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c15">See </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/jpeg729/pytorch_bits&amp;sa=D&amp;ust=1578461385567000">https://github.com/jpeg729/pytorch_bits</a></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.StatelessMGU.html%23chainer.links.StatelessMGU&amp;sa=D&amp;ust=1578461385568000">L.StatelessMGU</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.StatefulPeepholeLSTM.html%23chainer.links.StatefulPeepholeLSTM&amp;sa=D&amp;ust=1578461385569000">L.StatefulPeepholeLSTM</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c15">See </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/issues/630&amp;sa=D&amp;ust=1578461385570000">https://github.com/pytorch/pytorch/issues/630</a></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.StatefulZoneoutLSTM.html%23chainer.links.StatefulZoneoutLSTM&amp;sa=D&amp;ust=1578461385571000">L.StatefulZoneoutLSTM</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c15">N/A: </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/pull/4838&amp;sa=D&amp;ust=1578461385571000">https://github.com/pytorch/pytorch/pull/4838</a></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.StatelessLSTM.html%23chainer.links.StatelessLSTM&amp;sa=D&amp;ust=1578461385572000">L.StatelessLSTM</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c51"><td class="c106" colspan="3" rowspan="1"><p class="c4"><span class="c15 c33">Activation/loss/normalization functions with parameters</span></p></td></tr><tr class="c80"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.BatchNormalization.html%23chainer.links.BatchNormalization&amp;sa=D&amp;ust=1578461385574000">L.BatchNormalization</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3 c50"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23batchnorm1d&amp;sa=D&amp;ust=1578461385575000">nn.BatchNorm1d</a></span></p><p class="c4"><span class="c3 c50"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23batchnorm1d&amp;sa=D&amp;ust=1578461385575000">nn.BatchNorm2d</a></span></p><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23batchnorm1d&amp;sa=D&amp;ust=1578461385575000">nn.BatchNorm3d</a></span></p></td><td class="c95" colspan="1" rowspan="1"><p class="c4"><span class="c0">The argument `momentum` in the PyTorch implementation seems to be equivalent to `1 - decay` in the Chainer&#39;s link.</span></p><p class="c4"><span class="c0">The default value for the argument `eps` (1e-5) is different from Chainer&#39;s default value (2e-5).</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.BatchRenormalization.html%23chainer.links.BatchRenormalization&amp;sa=D&amp;ust=1578461385576000">L.BatchRenormalization</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">N/A</span></p></td></tr><tr class="c68"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.DecorrelatedBatchNormalization.html%23chainer.links.DecorrelatedBatchNormalization&amp;sa=D&amp;ust=1578461385578000">L.DecorrelatedBatchNormalization</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c15">Not available. A reference implementation (not that well implemented?) </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/huangleiBuaa/IterNorm-pytorch/blob/master/extension/normailzation/dbn.py&amp;sa=D&amp;ust=1578461385578000">https://github.com/huangleiBuaa/IterNorm-pytorch/blob/master/extension/normailzation/dbn.py</a></span><span class="c15">. Otherwise look at the Torch lua official implementation </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/princeton-vl/DecorrelatedBN&amp;sa=D&amp;ust=1578461385579000">https://github.com/princeton-vl/DecorrelatedBN</a></span><span class="c0">.</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.GroupNormalization.html%23chainer.links.GroupNormalization&amp;sa=D&amp;ust=1578461385579000">L.GroupNormalization</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.GroupNorm&amp;sa=D&amp;ust=1578461385580000">nn.GroupNorm</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">affine=True</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.LayerNormalization.html%23chainer.links.LayerNormalization&amp;sa=D&amp;ust=1578461385581000">L.LayerNormalization</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.LayerNorm&amp;sa=D&amp;ust=1578461385581000">nn.LayerNorm</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">elementwise_affine=True</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.BinaryHierarchicalSoftmax.html%23chainer.links.BinaryHierarchicalSoftmax&amp;sa=D&amp;ust=1578461385582000">L.BinaryHierarchicalSoftmax</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.BlackOut.html%23chainer.links.BlackOut&amp;sa=D&amp;ust=1578461385583000">L.BlackOut</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.CRF1d.html%23chainer.links.CRF1d&amp;sa=D&amp;ust=1578461385585000">L.CRF1d</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.SimplifiedDropconnect.html%23chainer.links.SimplifiedDropconnect&amp;sa=D&amp;ust=1578461385586000">L.SimplifiedDropconnect</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.PReLU.html%23chainer.links.PReLU&amp;sa=D&amp;ust=1578461385588000">L.PReLU</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.PReLU&amp;sa=D&amp;ust=1578461385589000">nn.PReLU</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Swish.html%23chainer.links.Swish&amp;sa=D&amp;ust=1578461385590000">L.Swish</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c15">See </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://blog.ceshine.net/post/pytorch-memory-swish/&amp;sa=D&amp;ust=1578461385591000">https://blog.ceshine.net/post/pytorch-memory-swish/</a></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Maxout.html%23chainer.links.Maxout&amp;sa=D&amp;ust=1578461385591000">L.Maxout</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.NegativeSampling.html%23chainer.links.NegativeSampling&amp;sa=D&amp;ust=1578461385593000">L.NegativeSampling</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c106" colspan="3" rowspan="1"><p class="c4"><span class="c33 c15">Machine learning models</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.Classifier.html%23chainer.links.Classifier&amp;sa=D&amp;ust=1578461385595000">L.Classifier</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c106" colspan="3" rowspan="1"><p class="c4"><span class="c33 c15">Pre-trained models</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.VGG16Layers.html%23chainer.links.VGG16Layers&amp;sa=D&amp;ust=1578461385598000">L.VGG16Layers</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torchvision/models.html%23id2&amp;sa=D&amp;ust=1578461385598000">torchvision.models.vgg*</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">Superset of Chainer&#39;s VGG variations in torchvision.</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.VGG19Layers.html%23chainer.links.VGG19Layers&amp;sa=D&amp;ust=1578461385599000">L.VGG19Layers</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torchvision/models.html%23torchvision.models.vgg19&amp;sa=D&amp;ust=1578461385600000">torchvision.models.vgg19*</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">ditto</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.model.vision.vgg.prepare.html%23chainer.links.model.vision.vgg.prepare&amp;sa=D&amp;ust=1578461385601000">L.model.vision.vgg.prepare</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.GoogLeNet.html%23chainer.links.GoogLeNet&amp;sa=D&amp;ust=1578461385602000">L.GoogLeNet</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torchvision/models.html%23torchvision.models.googlenet&amp;sa=D&amp;ust=1578461385602000">torchvision.models.googlenet</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.model.vision.googlenet.prepare.html%23chainer.links.model.vision.googlenet.prepare&amp;sa=D&amp;ust=1578461385603000">L.model.vision.googlenet.prepare</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">transform_input=True in torchvision.models.googlenet</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.model.vision.resnet.ResNetLayers.html%23chainer.links.model.vision.resnet.ResNetLayers&amp;sa=D&amp;ust=1578461385604000">L.model.vision.resnet.ResNetLayers</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.ResNet50Layers.html%23chainer.links.ResNet50Layers&amp;sa=D&amp;ust=1578461385606000">L.ResNet50Layers</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torchvision/models.html%23torchvision.models.resnet50&amp;sa=D&amp;ust=1578461385606000">torchvision.models.resnet101</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">torchvision only, pretrained=True</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.ResNet101Layers.html%23chainer.links.ResNet101Layers&amp;sa=D&amp;ust=1578461385607000">L.ResNet101Layers</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torchvision/models.html%23torchvision.models.resnet101&amp;sa=D&amp;ust=1578461385608000">torchvision.models.resnet101</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">torchvision only, pretrained=True</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.ResNet152Layers.html%23chainer.links.ResNet152Layers&amp;sa=D&amp;ust=1578461385609000">L.ResNet152Layers</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torchvision/models.html%23torchvision.models.resnet152&amp;sa=D&amp;ust=1578461385609000">torchvision.models.resnet152</a></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">torchvision only, pretrained=True</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.model.vision.resnet.prepare.html%23chainer.links.model.vision.resnet.prepare&amp;sa=D&amp;ust=1578461385610000">L.model.vision.resnet.prepare</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">N/A</span></p></td></tr><tr class="c20"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.TheanoFunction.html%23chainer.links.TheanoFunction&amp;sa=D&amp;ust=1578461385612000">L.TheanoFunction</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c0">N/A</span></p></td></tr><tr class="c51"><td class="c17" colspan="1" rowspan="1"><p class="c4"><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/generated/chainer.links.caffe.CaffeFunction.html%23chainer.links.caffe.CaffeFunction&amp;sa=D&amp;ust=1578461385613000">L.caffe.CaffeFunction</a></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c4 c29"><span class="c0"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c4"><span class="c15">See </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/marvis/pytorch-caffe&amp;sa=D&amp;ust=1578461385614000">https://github.com/marvis/pytorch-caffe</a></span><span class="c15">&nbsp;or </span><span class="c3"><a class="c2" href="https://www.google.com/url?q=https://github.com/Microsoft/MMdnn&amp;sa=D&amp;ust=1578461385614000">https://github.com/Microsoft/MMdnn</a></span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><h2 class="c10 c31" id="h.hb9kqa7i3enr"><span class="c67 c36">Configuration</span></h2><p class="c4 c10"><span>Here is the mapping of configurations in Chainer (</span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://docs.chainer.org/en/latest/reference/configuration.html&amp;sa=D&amp;ust=1578461385616000">chainer.config.*</a></span><span class="c6">) and PyTorch:</span></p><p class="c4 c10 c29"><span class="c6"></span></p><a id="t.f3301a8a5c40dafd6342027539056b8cf48e653c"></a><a id="t.21"></a><table class="c111"><tbody><tr class="c5"><td class="c88 c115" colspan="1" rowspan="1"><p class="c34"><span class="c7">Chainer</span></p></td><td class="c88 c93" colspan="1" rowspan="1"><p class="c34"><span class="c7">PyTorch</span></p></td><td class="c88 c92" colspan="1" rowspan="1"><p class="c34"><span class="c7">Notes</span></p></td></tr><tr class="c5"><td class="c54" colspan="1" rowspan="1"><p class="c16"><span class="c22">autotune</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c16"><span class="c22">torch.backends.cudnn.benchmark</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c16"><span class="c6">Not thread-local.</span></p></td></tr><tr class="c5"><td class="c54" colspan="1" rowspan="1"><p class="c16"><span class="c22">cudnn_deterministic</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c16"><span class="c22">torch.backends.cudnn.deterministic</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c16"><span class="c6">Not thread-local.</span></p></td></tr><tr class="c5"><td class="c54" colspan="1" rowspan="1"><p class="c16"><span class="c22">cudnn_fast_batch_normalization</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c16"><span class="c6">N/A</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c16"><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/blob/v1.2.0/aten/src/ATen/native/cudnn/BatchNorm.cpp%23L90-L94&amp;sa=D&amp;ust=1578461385620000">Intentionally unsupported</a></span><span class="c6">&nbsp;as the precision is low in some models.</span></p></td></tr><tr class="c5"><td class="c54" colspan="1" rowspan="1"><p class="c16"><span class="c22">debug</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c16"><span class="c6">N/A</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c16"><span>Use </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/autograd.html%23torch.autograd.detect_anomaly&amp;sa=D&amp;ust=1578461385622000">torch.autograd.detect_anomaly()</a></span><span class="c6">&nbsp;context-manager to check NaN during backward, display the corresponding forward stack trace when error occurred in backward.</span></p></td></tr><tr class="c5"><td class="c54" colspan="1" rowspan="1"><p class="c16"><span class="c22">dtype</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c16"><span class="c43 c35"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/torch.html%23torch.set_default_dtype&amp;sa=D&amp;ust=1578461385622000">torch.set_default_dtype(dtype)</a></span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c16"><span class="c6">Mixed precision support is done via Apex. Not thread-local.</span></p></td></tr><tr class="c5"><td class="c54" colspan="1" rowspan="1"><p class="c16"><span class="c22">enable_backprop</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c16"><span class="c22">torch.no_grad()</span></p><p class="c16"><span class="c22">torch.enable_grad()</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c16"><span>You can use them as context-manager or decorator. See also </span><span class="c43"><a class="c2" href="#h.mc69ie7hbl6j">Backprop modes</a></span><span class="c6">.</span></p></td></tr><tr class="c5"><td class="c54" colspan="1" rowspan="1"><p class="c16"><span class="c22">is_recomputing</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c16"><span class="c6">N/A</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c16"><span>See </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/checkpoint.html&amp;sa=D&amp;ust=1578461385625000">torch.utils.checkpoint.checkpoint</a></span><span class="c6">&nbsp;for F.forget equivalent (it also supports RNG).</span></p></td></tr><tr class="c5"><td class="c54" colspan="1" rowspan="1"><p class="c16"><span class="c22">keep_graph_on_report</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c16"><span class="c6">N/A</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c16 c29"><span class="c6"></span></p></td></tr><tr class="c5"><td class="c54" colspan="1" rowspan="1"><p class="c16"><span class="c22">lazy_grad_sum</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c16"><span class="c6">N/A</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c16 c29"><span class="c6"></span></p></td></tr><tr class="c5"><td class="c54" colspan="1" rowspan="1"><p class="c16"><span class="c22">train</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c16"><span class="c6">N/A</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c16"><span>The mode is configured per Module (using Module.train() and Module.eval()). See also </span><span class="c43"><a class="c2" href="#h.bka3yqtw2rpy">Train/Test modes</a></span><span class="c6">.</span></p></td></tr><tr class="c5"><td class="c54" colspan="1" rowspan="1"><p class="c16"><span class="c22">type_check</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c16"><span class="c6">N/A</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c16 c29"><span class="c6"></span></p></td></tr><tr class="c5"><td class="c54" colspan="1" rowspan="1"><p class="c16"><span class="c22">use_cudnn</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c16"><span class="c22">torch.backends.cudnn.enabled</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c16"><span class="c6">Enabled by default. Not thread-local.</span></p></td></tr><tr class="c5"><td class="c54" colspan="1" rowspan="1"><p class="c16"><span class="c22">use_cudnn_tensor_core</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c16"><span class="c6">N/A</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c16"><span class="c6">Tensor Cores cannot be disabled.</span></p></td></tr><tr class="c5"><td class="c54" colspan="1" rowspan="1"><p class="c16"><span class="c22">use_ideep</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c16"><span class="c6">N/A</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c16"><span class="c6">PyTorch itself supports MKL-DNN. You can check availability using torch.backends.mkldnn.is_available().</span></p></td></tr><tr class="c89"><td class="c54" colspan="1" rowspan="1"><p class="c16"><span class="c22">use_static_graph</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c16"><span class="c6">N/A</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c16 c29"><span class="c6"></span></p></td></tr><tr class="c5"><td class="c54" colspan="1" rowspan="1"><p class="c16"><span class="c22">warn_nondeterministic</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c16"><span class="c6">N/A</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c16 c29"><span class="c6"></span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span>See </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/notes/randomness.html&amp;sa=D&amp;ust=1578461385633000">Reproducibility</a></span><span>&nbsp;for the reproducibility (including steps to fix seeds).</span></p><h2 class="c31 c10" id="h.rxt9pteccajv"><span class="c67 c36">Hooks</span></h2><h3 class="c23 c10" id="h.gsgtoxixjcm4"><span class="c42 c36">Function Hooks</span></h3><p class="c4 c10"><span class="c6">There is no equivalent feature in PyTorch.</span></p><p class="c4 c10"><span class="c6">Replacements for Chainer built-in hooks:</span></p><ul class="c18 lst-kix_owgllipbp8j5-0 start"><li class="c1"><span>CUDAProfileHook: </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/master/autograd.html%23torch.autograd.profiler.profile&amp;sa=D&amp;ust=1578461385634000">torch.autograd.profiler.profile</a></span><span>&nbsp;+ </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/master/autograd.html%23torch.autograd.profiler.emit_nvtx&amp;sa=D&amp;ust=1578461385635000">torch.autograd.profiler.emit_nvtx</a></span></li><li class="c1"><span>CupyMemoryProfileHook: N/A (</span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/notes/cuda.html%23memory-management&amp;sa=D&amp;ust=1578461385635000">allocator status can be retrieved</a></span><span class="c6">)</span></li><li class="c1"><span class="c6">PrintHook: N/A</span></li><li class="c1"><span>TimerHook: </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/master/autograd.html%23torch.autograd.profiler.profile&amp;sa=D&amp;ust=1578461385636000">torch.autograd.profiler.profile</a></span></li></ul><h3 class="c23 c10" id="h.rvlhszhkp1bw"><span class="c42 c36">Link Hooks</span></h3><p class="c4 c10"><span>You can register </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/tutorials/beginner/former_torchies/nnft_tutorial.html%23forward-and-backward-function-hooks&amp;sa=D&amp;ust=1578461385636000">Module Hooks</a></span><span class="c6">&nbsp;per module. There&#39;s no way to inject a hook for every link called under the specific scope.</span></p><p class="c4 c10"><span class="c6">Replacements for Chainer built-in hooks:</span></p><ul class="c18 lst-kix_9reixuath9e3-0 start"><li class="c1"><span>SpectralNormalization: </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.utils.spectral_norm&amp;sa=D&amp;ust=1578461385637000">torch.nn.utils.spectral_norm</a></span><span>&nbsp;/ </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.utils.remove_spectral_norm&amp;sa=D&amp;ust=1578461385637000">torch.nn.utils.remove_spectral_norm</a></span></li><li class="c1"><span class="c6">TimerHook: N/A</span></li></ul><h3 class="c10 c23" id="h.5a204an0cllk"><span class="c42 c36">Optimizer Hooks</span></h3><p class="c4 c10"><span>There is no direct equivalent in PyTorch, but you can </span><span>register backward hooks</span><span>&nbsp;per </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/autograd.html%23torch.Tensor.register_hook&amp;sa=D&amp;ust=1578461385638000">Tensor</a></span><span>&nbsp;/ </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Module.register_backward_hook&amp;sa=D&amp;ust=1578461385638000">Module</a></span><span>&nbsp;to modify gradients.</span></p><p class="c4 c10"><span class="c6">Replacements for Chainer built-in hooks:</span></p><ul class="c18 lst-kix_jbicnccaji3d-0 start"><li class="c1"><span>WeightDecay: specify as </span><span class="c35">weight_decay</span><span>&nbsp;argument to each Optimizer (e.g., </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/optim.html%23torch.optim.Adam&amp;sa=D&amp;ust=1578461385638000">Adam</a></span><span class="c6">)</span></li><li class="c1"><span class="c6">Lasso: N/A</span></li><li class="c1"><span>GradientClipping: </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.utils.clip_grad_norm_&amp;sa=D&amp;ust=1578461385639000">torch.nn.utils.clip_grad_norm_</a></span></li><li class="c1"><span>GradientHardClipping: </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.utils.clip_grad_value_&amp;sa=D&amp;ust=1578461385639000">torch.nn.utils.clip_grad_value_</a></span></li><li class="c1"><span class="c6">GradientNoise: N/A</span></li><li class="c1"><span>GradientLARS: N/A (see </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch/issues/18414&amp;sa=D&amp;ust=1578461385640000">pytorch #18414</a></span><span>&nbsp;and </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://github.com/noahgolmant/pytorch-lars&amp;sa=D&amp;ust=1578461385640000">pytorch-lars</a></span><span>)</span></li></ul><h2 class="c31 c10" id="h.79n4spowwnun"><span class="c67 c36">Training PyTorch model using Chainer</span></h2><p class="c4 c10"><span>To quickly try a PyTorch model in a training script using Chainer, </span><span class="c43 c13"><a class="c2" href="#h.jgakn54a8peo">cpm.TorchModule</a></span><span class="c6">&nbsp;is the tool to use. Assuming you have a training script using Chainer, you have to try the following steps:</span></p><p class="c4 c10 c29"><span class="c6"></span></p><ul class="c18 lst-kix_38adif7m6rbx-0 start"><li class="c1"><span>Replace the model to train with </span><span class="c13">cpm.TorchModule(module_you_want_to_use)</span><span>. Use </span><span class="c13">to_gpu</span><span class="c6">&nbsp;to transfer the variables to a GPU device.</span></li><li class="c1"><span class="c6">Rewrite the loss computation and backprop call with PyTorch.</span></li></ul><ul class="c18 lst-kix_38adif7m6rbx-1 start"><li class="c4 c10 c71"><span>If you are using StandardUpdater, make its subclass and override </span><span class="c13">update_core</span><span class="c6">. Write loss calculation and backprop call in PyTorch.</span></li></ul><ul class="c18 lst-kix_38adif7m6rbx-2 start"><li class="c4 c10 c81"><span class="c101">NOTE</span><span>: Once you compute the gradient in PyTorch, it is automatically reflected to Chainer parameters, so it is valid to just call </span><span class="c13">optimizer.update()</span><span class="c6">&nbsp;after that.</span></li></ul><ul class="c18 lst-kix_38adif7m6rbx-1"><li class="c4 c10 c71"><span>If you are using a custom training loop, rewrite the gradient computation part in PyTorch. See the above NOTE, too.</span></li></ul><h2 class="c31 c10" id="h.33jrfcvcf9zh"><span class="c67 c36">Distributed training </span></h2><p class="c4 c10"><span>As of writing, there are two major ways to run distributed deep learning applications:</span><span class="c13">&nbsp;torch.distributed</span><span>&nbsp;and Horovod. We recommend</span><span class="c13">&nbsp;torch.distributed</span><span class="c6">&nbsp;as a first option because of the following reasons.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><ol class="c18 lst-kix_8dw3ycrgt362-0 start" start="1"><li class="c1"><span class="c13">torch.distributed</span><span class="c6">&nbsp;is a part of standard modules of PyTorch.</span></li><li class="c1"><span class="c6">It supports some advanced features that Horovod doesn&rsquo;t, such as multi-node batch normalization (e.g. inter-process batch normalization)</span></li></ol><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span class="c6">In this document, we describe both approaches to migrate ChainerMN programs to PyTorch.</span></p><h3 class="c23 c10 c61" id="h.91x1ehh487en"><span class="c42 c36"></span></h3><h3 class="c23 c10" id="h.iyhfmfndl13j"><span class="c42 c36">Pytorch model using torch.distributed&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></h3><p class="c4 c10"><span class="c6">Torch.distributed is the standard module for distributed deep learning of PyTorch. </span></p><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span class="c6">Torch.distributed supports three backends: &ldquo;nccl&rdquo;, &ldquo;mpi&rdquo; and &ldquo;gloo&rdquo;. For users who are migrating from Chainer and ChainerMN and have been using NCCL with MPI, using &ldquo;nccl&rdquo; backend is the most straightforward way. In this section, we assume that you use NCCL and MPI to run your distributed deep learning programs. In particular we assume Open MPI as the MPI implementation used here because it is the recommended option in ChainerMN, but other MPI implementations are mentioned as well.</span></p><h4 class="c23 c10" id="h.moliknyk6ru3"><span class="c48">Invocation</span></h4><p class="c4 c10"><span>In ChainerMN, process invocation is totally coordinated by the MPI runtime. However, in PyTorch and torch.distributed, you may need a few more steps to invoke distributed deep learning processes. The simplest initialization method might be </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/distributed.html%23environment-variable-initialization&amp;sa=D&amp;ust=1578461385643000">environment variable initialization</a></span><span class="c6">. </span></p><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span>The following environmental variables are necessary (whatever system you use to invoke your script, including MPI). Other variables, </span><span class="c13">WORLD_SIZE</span><span>&nbsp;and</span><span class="c13">&nbsp;RANK,</span><span class="c6">&nbsp;are set from inside the following snippet.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span class="c13">MASTER_ADDR : </span><span class="c6">Address of the computing node where the rank 0 process runs.</span></p><p class="c4 c10"><span class="c13">MASTER_PORT : </span><span class="c6">A free port of the MASTER_ADDR machine. The port will be used by &nbsp;the rank 0 process.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span>Note that process invocation is highly system-dependent issue. PyTorch supports other options such as </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/distributed.html%23tcp-initialization&amp;sa=D&amp;ust=1578461385644000">TCP initialization</a></span><span>&nbsp;and </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/distributed.html%23shared-file-system-initialization&amp;sa=D&amp;ust=1578461385644000">shared file-system initialization</a></span><span class="c6">. Please refer to the official documents for more details.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><h4 class="c23 c10" id="h.7r5y5xoqrywb"><span class="c48">Initialization</span></h4><p class="c4 c10"><span class="c6">The following code snippets shows how to initialize torch.distributed module.</span></p><p class="c4 c10 c29"><span class="c9"></span></p><a id="t.bca77ae00997d02300bdcc0347eb376ffd57872b"></a><a id="t.22"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c4 c10"><span class="c9"># setup env for torch.distributed</span></p><p class="c4 c10"><span class="c9">comm_world_size = int(os.environ[&quot;OMPI_COMM_WORLD_SIZE&quot;])</span></p><p class="c4 c10"><span class="c9">comm_rank = int(os.environ[&quot;OMPI_COMM_WORLD_RANK&quot;])</span></p><p class="c4 c10"><span class="c9">comm_local_rank = int(os.environ[&#39;OMPI_COMM_WORLD_LOCAL_RANK&#39;])</span></p><p class="c4 c10 c29"><span class="c9"></span></p><p class="c4 c10"><span class="c9">os.environ[&quot;WORLD_SIZE&quot;] = str(comm_world_size)</span></p><p class="c4 c10"><span class="c9">os.environ[&quot;RANK&quot;] = str(comm_rank)</span></p><p class="c4 c10"><span class="c9">torch.cuda.set_device(comm_local_rank)</span></p><p class="c4 c10"><span class="c9">torch.distributed.init_process_group(backend=&#39;nccl&#39;, init_method=&#39;env://&#39;)</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span class="c6">Environmental variables set by MPI runtime are here, instead of communicator.intra_rank in ChainerMN because torch.distributed does not provide corresponding rank information. If you use MVAPICH2, use MV2_COMM_WORLD_SIZE, MV2_COMM_WORLD_RANK, MV2_COMM_WORLD_LOCAL_RANK respectively. </span></p><p class="c4 c10 c29"><span class="c6"></span></p><h4 class="c23 c10" id="h.nzh1eoy3bny9"><span class="c48">Dataset scattering</span></h4><p class="c4 c10"><span>Each node can get a slice of a globally shared dataset using a </span><span class="c13">DistributedSampler</span><span>.</span></p><a id="t.89ef2d99828a1b22383a2ae56fba3bdc817aa41c"></a><a id="t.23"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c38 c10"><span class="c12">sampler = torch.utils.data.distributed.DistributedSampler(dataset, </span></p><p class="c38 c10"><span class="c12">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; num_replicas=comm_world_size,</span></p><p class="c38 c10"><span class="c12">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; rank=comm_rank)</span></p><p class="c38 c10 c29"><span class="c12"></span></p><p class="c38 c10"><span class="c12">loader_kwargs = {&#39;num_workers&#39;: 1, &#39;pin_memory&#39;: True} &nbsp;# Assuming we use GPUs</span></p><p class="c38 c10"><span class="c12">loader = torch.utils.data.DataLoader(train_dataset,</span></p><p class="c38 c10"><span class="c12">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;batch_size=args.batch_size, </span></p><p class="c38 c10"><span class="c12">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;sampler=sampler, **loader_kwargs)</span></p></td></tr></tbody></table><p class="c38 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span>This will make every worker to only load a slice of the dataset, this sampler can be normally fed to the </span><span class="c13">DataLoader</span><span class="c6">.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span>Also, you need to call</span><span class="c13">&nbsp;DistributedSampler.set_epoch()</span><span class="c6">&nbsp;to adjust epoch numbers. &nbsp;Thus typical training loop looks like:</span></p><p class="c4 c10 c29"><span class="c12"></span></p><a id="t.bbd36d8e629516ffbb814279727dc47778519869"></a><a id="t.24"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c38 c10"><span class="c12">for epoch in range(1, args.epochs + 1):</span></p><p class="c38 c10"><span class="c12">&nbsp; &nbsp; train_sampler.set_epoch(epoch)</span></p><p class="c38 c10"><span class="c12">&nbsp; &nbsp; train(args, model, device, train_loader, optimizer, epoch)</span></p><p class="c38 c10"><span class="c12">&nbsp; &nbsp; test(args, model, device, test_loader, len(test_dataset))</span></p><p class="c38 c10"><span class="c12">&nbsp; &nbsp; scheduler.step()</span></p></td></tr></tbody></table><p class="c38 c10 c29"><span class="c6"></span></p><p class="c4 c10 c29"><span class="c9"></span></p><h4 class="c23 c10" id="h.kyzvorr2x2ij"><span class="c48">Data transfer to devices</span></h4><p class="c4 c10"><span>We need to specify the device to which the data is transferred using</span><span class="c13">&nbsp;comm_local_rank</span><span class="c6">. </span></p><p class="c4 c10 c29"><span class="c12"></span></p><a id="t.febd87097d6acdc6ac335c2829150af17406f2f5"></a><a id="t.25"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c38 c10"><span class="c12">class MyNN(nn.module):</span></p><p class="c38 c10"><span class="c12">&nbsp; &nbsp; ...</span></p><p class="c38 c10 c29"><span class="c12"></span></p><p class="c38 c10"><span class="c12">device = torch.device(&quot;cuda:{}&quot;.format(comm_local_rank) if use_cuda else &quot;cpu&quot;)</span></p><p class="c38 c10"><span class="c12">model = MyNN().to(device)</span></p><p class="c38 c10"><span class="c12">model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[comm_local_rank])</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><h4 class="c23 c10" id="h.s0hd5ycxwpdh"><span class="c48">Optimizer wrapping</span></h4><p class="c4 c10"><span>In contrast to </span><span class="c43"><a class="c2" href="#h.z7g1nmbbb3uh">Horovod</a></span><span class="c6">, We can use the same optimizer as in non-distributed execution. </span></p><p class="c4 c10 c29"><span class="c6"></span></p><h4 class="c23 c10" id="h.d1nulkakooh"><span class="c48">Initial values broadcast</span></h4><p class="c4 c10"><span>Parameter values are synchronized (i.e. initial broadcast and allreduce in every iteration) automatically by</span><span class="c13">&nbsp;DistributedDataParallel</span><span class="c6">&nbsp;class and thus no further modification is necessary.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><h4 class="c23 c10" id="h.x5dny5mqq9px"><span class="c48">Metrics average and reductions</span></h4><h4 class="c23 c10" id="h.5t9pfndndqnr"><span class="c62"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/distributed.html%23multi-gpu-collective-functions&amp;sa=D&amp;ust=1578461385655000">https://pytorch.org/docs/stable/distributed.html#multi-gpu-collective-functions</a></span></h4><p class="c4 c10 c29"><span class="c6"></span></p><h4 class="c23 c10" id="h.3lb7ncfjheoo"><span class="c48">Synchronization</span></h4><p class="c4 c10"><span class="c6">To avoid potential data races other kinds of bugs, you may need to use torch.distributed.barrier() to synchronize processes before or after data loading, and finishing the application. </span></p><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10 c29"><span class="c6"></span></p><h3 class="c23 c10 c61" id="h.fm07a8ui8sm1"><span class="c42 c36"></span></h3><h3 class="c23 c10" id="h.dis62849w9cz"><span class="c42 c36">PyTorch model using Horovod</span></h3><p class="c4 c10"><span>PyTorch can use </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://github.com/horovod/horovod&amp;sa=D&amp;ust=1578461385656000">Horovod</a></span><span>&nbsp;to do Data Parallel training in a similar way to ChainerMN.<br>Data is distributed across the nodes and the optimizer is wrapped in with </span><span>Horovod</span><span class="c6">&nbsp;to automatically average the gradients of several MPI processes.</span></p><h4 class="c23 c10 c96" id="h.o3x9ygfly4q"><span class="c48"></span></h4><h4 class="c23 c10" id="h.tje6mmfdx3pf"><span class="c48">Horovod initialization</span></h4><p class="c4 c10"><span>The following snippet shows how to import horovod and retrieve the current worker id and the total number of workers.</span></p><a id="t.1f187a1cc2a0f3f05314bb5efd0eca754b829707"></a><a id="t.26"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c4 c10"><span class="c9">import horovod.torch as hvd</span></p><p class="c4 c10"><span class="c9">hvd.init()</span></p><p class="c4 c10"><span class="c9">print(&lsquo;My rank is {} of {} workers&lsquo;.format(hvd.rank(), hvd.size()))</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span class="c13">hvd.local_rank() </span><span>is used to get the rank inside a single node, this is useful to assign GPUs, similar to ChainerMN&rsquo;s</span><span class="c13">&nbsp;intra_rank()</span><span>.</span></p><a id="t.2947184f677b00b78c938df5ebaf8a3de12018f5"></a><a id="t.27"></a><table class="c30"><tbody><tr class="c87"><td class="c28" colspan="1" rowspan="1"><p class="c4 c10"><span class="c12 c58">torch.cuda.set_device(hvd.local_rank())</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><h4 class="c23 c10" id="h.37g288q2db5i"><span class="c48">Dataset scattering</span></h4><p class="c4 c10"><span>Each node can get a slice of a globally shared dataset using a </span><span class="c13">DistributedSampler</span><span>.</span></p><a id="t.49bd94ec55cd43d4b62152a8a3740c05dbfb8bf1"></a><a id="t.28"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c38 c10"><span class="c13 c77">torch.utils.data.distributed.DistributedSampler(dataset, </span><span class="c13">num_replicas=</span><span class="c12">hvd.size(), </span></p><p class="c38 c10"><span class="c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; rank=</span><span class="c12">hvd.rank())</span></p></td></tr></tbody></table><p class="c38 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span>This will make every worker to only load a slice of the dataset, this sampler can be normally fed to the </span><span class="c13">DataLoader</span><span class="c6"><br></span></p><h4 class="c23 c10" id="h.z7g1nmbbb3uh"><span class="c48">Optimizer wrapping</span></h4><p class="c4 c10"><span>The optimizer is wrapped in a </span><span class="c13">hvd.DistributedOptimizer</span><span>&nbsp;object with the following configuration parameters.<br><br></span><span class="c13">compression </span><span>: value in</span><span class="c9">&nbsp;{hvd.Compression.fp16, hvd.Compression.none}<br></span></p><p class="c4 c10"><span>compression is used to reduce the size of the allreduce operations performed by the optimizer.<br><br></span><span class="c13">backward_passes_per_step : int </span><span class="c6">default value usually 1</span></p><p class="c4 c10 c29"><span class="c9"></span></p><p class="c4 c10"><span>Number of batches that are performed locally before performing the gradients exchange.</span></p><a id="t.e7c44ee3b69544418ca97691b43afb5b46f1e908"></a><a id="t.29"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c4 c10"><span class="c9">optimizer = hvd.DistributedOptimizer(</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; optimizer, named_parameters=model.named_parameters(),</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; compression=compression,</span></p><p class="c4 c10"><span class="c9">&nbsp; &nbsp; backward_passes_per_step=args.batches_per_allreduce)</span></p></td></tr></tbody></table><p class="c4 c10"><span><br>From the documentation:<br><br></span><span class="c52 c45">DistributedOptimizer exposes the </span><span class="c76 c45">synchronize()</span><span class="c52 c45">&nbsp;method, which forces allreduce operations to finish before continuing the execution. It&rsquo;s useful in conjunction with gradient clipping, or other operations that modify gradients in place before </span><span class="c45 c76">step()</span><span class="c52 c45">is executed. Make sure to use </span><span class="c76 c45">optimizer.skip_synchronize()</span><span class="c52 c45">&nbsp;if you&rsquo;re calling </span><span class="c76 c45">synchronize()</span><span class="c45 c52">&nbsp;in your code.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><h4 class="c23 c10" id="h.gq621f9b16zf"><span class="c48">Initial values broadcast</span></h4><p class="c4 c10"><span>Before starting the training loop, initial model parameters and the optimizer state must be broadcasted to all the workers:</span></p><a id="t.d9c5fa6d0a478715e92abcf59d1d7d36e3acde5b"></a><a id="t.30"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c4 c10"><span class="c9">hvd.broadcast_parameters(model.state_dict(), root_rank=0)</span></p><p class="c4 c10"><span class="c9">hvd.broadcast_optimizer_state(optimizer, root_rank=0)</span></p></td></tr></tbody></table><h4 class="c23 c10 c96" id="h.7hiogyr5jasg"><span class="c48"></span></h4><h4 class="c23 c10" id="h.9t9k4lfat6t2"><span class="c48">Metrics average and reductions</span></h4><p class="c4 c10"><span class="c6">When computing the loss and other metrics such as accuracy, the values of multiple workers can be explicitly exchanged to compute averages:</span></p><a id="t.7b00fd4181f942caf888937294ff90e6381ac1d0"></a><a id="t.31"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c16"><span class="c13 c58">self.sum += hvd.allreduce(val.detach().cpu(), name=metric_name)</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span class="c6">Horovod has support to exchange data using other MPI collectives:</span></p><ul class="c18 lst-kix_rsr7bmzen4a7-0 start"><li class="c1"><span class="c9">horovod.torch.allgather</span></li><li class="c1"><span class="c9">horovod.torch.broadcast</span></li></ul><p class="c4 c10"><span>There are _async versions of the three functions that can be queried using </span><span class="c13">poll()</span><span>&nbsp;on the returned handler or </span><span class="c13">synchronize()</span><span class="c6">&nbsp;to wait till completion.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><h4 class="c23 c10" id="h.bfpbumwh7xzs"><span class="c48">Horovod code structure</span></h4><a id="t.e2ebc92c8c2223cbc3ddccd433f6d952be2ae85c"></a><a id="t.32"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c16"><span class="c53 c13 c45">import torch</span></p><p class="c16"><span class="c53 c13 c45">import horovod.torch as hvd</span></p><p class="c16"><span class="c53 c13 c45">&hellip;</span></p><p class="c16"><span class="c53 c13 c45">&hellip;</span></p><p class="c16"><span class="c53 c13 c45">def main():</span></p><p class="c16"><span class="c13 c45">&nbsp; &nbsp; </span><span class="c40 c13"># Initialize horovod</span></p><p class="c4 c10"><span class="c53 c13 c45">&nbsp; &nbsp; hvd.init()</span></p><p class="c4 c10"><span class="c13 c45">&nbsp; &nbsp; </span><span class="c53 c13 c58 c45">torch.cuda.set_device(hvd.local_rank())</span></p><p class="c4 c10"><span class="c13 c58 c45">&nbsp; &nbsp; </span><span class="c13 c26"># Read the dataset and create the iterators</span></p><p class="c4 c10"><span class="c53 c13 c58 c45">&nbsp; &nbsp; dataset = datasets.ImageFolder(&hellip;)</span></p><p class="c4 c10"><span class="c13 c58 c45">&nbsp; &nbsp; train_sampler = </span><span class="c53 c13 c45">torch.utils.data.distributed.DistributedSampler(dataset, num_replicas=hvd.size(), </span></p><p class="c38 c10"><span class="c53 c13 c45">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; rank=hvd.rank())</span></p><p class="c38 c10"><span class="c13 c45">&nbsp; &nbsp; loader = torch.utils.data.DataLoader(dataset, sampler=train_sampler, &hellip;)<br> &nbsp; &nbsp;</span><span class="c40 c13"># Set up the model, checkpoints, &hellip;</span></p><p class="c38 c10"><span class="c53 c13 c45">&nbsp; &nbsp; &hellip;</span></p><p class="c38 c10"><span class="c13 c45">&nbsp; &nbsp; </span><span class="c40 c13"># Create the optimizer</span></p><p class="c38 c10"><span class="c53 c13 c45">&nbsp; &nbsp; optimizer = optim.SGD(model.parameters(), &hellip;)</span></p><p class="c38 c10"><span class="c53 c13 c45">&nbsp; &nbsp; optimizer = hvd.DistributedOptimizer(</span></p><p class="c38 c10"><span class="c53 c13 c45">&nbsp; &nbsp; &nbsp; &nbsp; optimizer, named_parameters=model.named_parameters(),</span></p><p class="c38 c10"><span class="c53 c13 c45">&nbsp; &nbsp; &nbsp; &nbsp; compression= hvd.Compression.none,</span></p><p class="c38 c10"><span class="c53 c13 c45">&nbsp; &nbsp; &nbsp; &nbsp; backward_passes_per_step=args.batches_per_allreduce)<br></span></p><p class="c38 c10"><span class="c13 c45">&nbsp; &nbsp; </span><span class="c40 c13"># Broadcast initial state</span></p><p class="c38 c10"><span class="c32 c13">&nbsp; &nbsp; broadcast parameters &amp; optimizer state.</span></p><p class="c38 c10"><span class="c32 c13">&nbsp; &nbsp; hvd.broadcast_parameters(model.state_dict(), root_rank=0)</span></p><p class="c38 c10"><span class="c32 c13">&nbsp; &nbsp; hvd.broadcast_optimizer_state(optimizer, root_rank=0)</span></p><p class="c10 c38"><span class="c39 c13">&nbsp; &nbsp; </span><span class="c40 c13"># Start training</span></p><p class="c38 c10"><span class="c32 c13">&nbsp; &nbsp; for epoch in range(epochs):</span></p><p class="c38 c10"><span class="c32 c13">&nbsp; &nbsp; &nbsp; &nbsp; train_sampler.set_epoch(epoch)</span></p><p class="c38 c10"><span class="c13 c32">&nbsp; &nbsp; &nbsp; &nbsp; &hellip; </span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c9"></span></p><h4 class="c23 c10" id="h.apxtaciyccdc"><span class="c48">Obtaining Horovod traces to measure performance</span></h4><p class="c4 c10"><span>Communication traces showing Horovod communications can be obtained by setting the </span><span class="c13">HOROVOD_TIMELINE</span><span class="c6">&nbsp;environment variable.</span></p><a id="t.64ecae9ad815cf624f1b9ed5b6a24476d88e0a59"></a><a id="t.33"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c16"><span class="c9">mpirun -bind-to-none -np 8 -x HOROVOD_TIMELINE=timeline.json ...</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span class="c6">The resultant trace can be visualized in Chrome by using the browser built-in chrome://tracing feature.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><h4 class="c23 c10" id="h.9jn0jqinrgx3"><span class="c48">Tuning Horovod performance</span></h4><p class="c4 c10"><span class="c6">Horovod has several knobs to improve its performance</span></p><p class="c4 c10 c29"><span class="c6"></span></p><ul class="c18 lst-kix_9i19e8txouig-0 start"><li class="c1"><span>TensorFusion improves network utilization when there are many operations to be done on small tensors. Instead of eagerly starting multiple small reductions, horovod combines the small tensors on a buffer and then batch operations in order to perform a more efficient communication/computation overlap. </span><span class="c13 c39">HOROVOD_FUSION_THRESHOLD</span><span class="c39 c56">&nbsp;</span><span class="c39">controls the size of the buffer in bytes (default is 64MB). </span><span class="c39 c13">HOROVOD_CYCLE_TIME </span><span class="c32 c66">specifies the amount of time in ms to wait for tensors to be batched before reducing them.</span></li><li class="c1"><span class="c39">Hierarchical Reduce: </span><span class="c39 c13">HOROVOD_HIERARCHICAL_ALLREDUCE</span><span class="c32 c66">&nbsp;does a hybrid approach where allreduce in-node is done by NCCL, and allreduce across nodes is done by MPI.</span></li><li class="c1"><span class="c39 c13">HOROVOD_AUTOTUNE </span><span class="c39">can be used for horovod to perform a Bayesian optimization on all the configurable parameters at the first epochs of training. More info </span><span class="c43 c45"><a class="c2" href="https://www.google.com/url?q=https://github.com/horovod/horovod/blob/83eaa163b395ae8866a404f94facf82cc8127642/docs/autotune.rst&amp;sa=D&amp;ust=1578461385673000">here</a></span></li></ul><h4 class="c23 c10 c96" id="h.81xyyty2r9qq"><span class="c48"></span></h4><h4 class="c23 c10" id="h.wuax6jpon8sy"><span class="c48">Using Horovod with apex</span></h4><p class="c4 c10"><span>Horovod launches all-reduce in parallel with backward computation, and </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://github.com/NVIDIA/apex&amp;sa=D&amp;ust=1578461385674000">apex</a></span><span class="c6">&nbsp;unscales gradient after backward computation.</span></p><p class="c4 c10"><span class="c6">To avoid race conditions, we have to wait for all-reduce completion before unscaling:</span></p><a id="t.6f2636f4210fb90c92d9a363f1d87ad8d31bcaab"></a><a id="t.34"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c16"><span class="c9">from apex import amp</span></p><p class="c16"><span class="c9">...</span></p><p class="c16"><span class="c9">with amp.scale_loss(loss, optimizer) as scaled_loss:</span></p><p class="c16"><span class="c9">&nbsp; &nbsp; scaled_loss.backward()</span></p><p class="c16"><span class="c9">&nbsp; &nbsp; optimizer.synchronize() &nbsp;# Wait for all-reduce completion</span></p><p class="c16"><span class="c9">with optimizer.skip_synchronize():</span></p><p class="c16"><span class="c9">&nbsp; &nbsp; optimizer.step()</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><p class="c4 c10"><span>Also, </span><span class="c13">backward_passes_per_step </span><span>should be 1 when using Horovod and apex. The current implementation of Horovoda and apex do not work as expected when </span><span class="c13">backward_passes_per_step</span><span class="c6">&nbsp;is not 1.</span></p><p class="c4 c10 c29"><span class="c6"></span></p><h4 class="c23 c10" id="h.pdah33gpi4li"><span class="c48">Multi-Node Batch Normalization in Horovod</span></h4><p class="c4 c10"><span>Horovod does not yet officially support MNBN (</span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://github.com/horovod/horovod/issues/1384&amp;sa=D&amp;ust=1578461385676000">https://github.com/horovod/horovod/issues/1384</a></span><span>), but there exists an unofficial implementation: </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://github.com/atranitell/Synchronized-BatchNorm-PyTorch-Horovod/blob/master/sync_bn.py&amp;sa=D&amp;ust=1578461385676000">https://github.com/atranitell/Synchronized-BatchNorm-PyTorch-Horovod/blob/master/sync_bn.py</a></span><span>. </span><span>Apex also has an implementation: </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://nvidia.github.io/apex/parallel.html%23apex.parallel.SyncBatchNorm&amp;sa=D&amp;ust=1578461385676000">https://nvidia.github.io/apex/parallel.html#apex.parallel.SyncBatchNorm</a></span></p><p class="c4 c10 c29"><span class="c6"></span></p><h4 class="c23 c10" id="h.eqj7dzgbr9y7"><span class="c48">Gathering arbitrary objects using Horovod and mpi4py</span></h4><p class="c4 c10"><span>Horovod supports simultaneous usage with mpi4py (</span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://github.com/horovod/horovod%23mpi4py&amp;sa=D&amp;ust=1578461385677000">https://github.com/horovod/horovod#mpi4py</a></span><span>). You can directly work with mpi4py to e.g. rewrite ChainerMN&#39;s </span><span class="c35">comm.gather_obj</span><span>:</span></p><a id="t.18c04d1a8953c91d68759f73f1d8c923e9d7fc66"></a><a id="t.35"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c16"><span class="c55 c56 c15">import horovod.torch as hvd</span></p><p class="c16 c29"><span class="c55 c56 c15"></span></p><p class="c16"><span class="c55 c15 c56"># Initialize Horovod</span></p><p class="c16"><span class="c55 c56 c15">hvd.init()</span></p><p class="c16 c29"><span class="c55 c56 c15"></span></p><p class="c16"><span class="c55 c56 c15"># Verify that MPI multi-threading is supported.</span></p><p class="c16"><span class="c55 c56 c15">assert hvd.mpi_threads_supported()</span></p><p class="c16 c29"><span class="c55 c56 c15"></span></p><p class="c16"><span class="c55 c56 c15">from mpi4py import MPI<br>mpi_comm = MPI.COMM_WORLD</span></p><p class="c16"><span class="c55 c56 c15">assert hvd.size() == mpi_comm.Get_size()</span></p><p class="c16"><span class="c56 c77 c15">mpi_comm.gather(obj, root=0) &nbsp;# This is equal to ChainerMN&rsquo;s comm.gather_obj</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><h4 class="c23 c10" id="h.y8eom3uzrv56"><span class="c48">Alternatives to Horovod</span></h4><p class="c4 c10"><span class="c6">Horovod is introduced here because it greatly resembles ChainerMN and can be used in our computing infrastructure right away. Alternatives are:<br></span></p><ul class="c18 lst-kix_dnm4ke3nhj1e-0 start"><li class="c1"><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/tutorials/intermediate/dist_tuto.html&amp;sa=D&amp;ust=1578461385680000">Pytorch distributed API</a></span></li><li class="c1"><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://williamfalcon.github.io/pytorch-lightning/Trainer/Distributed%2520training/%23Multi-node&amp;sa=D&amp;ust=1578461385680000">Lightning</a></span></li></ul><p class="c4 c10 c29"><span class="c6"></span></p><h3 class="c23 c10" id="h.qfxp9de828j4"><span class="c42 c36">Chainer model using Horovod</span></h3><p class="c4 c10"><span>To train chainer models in distributed environments using Horovod, the chainer link should be wrapped using </span><span class="c43 c13"><a class="c2" href="#h.46et3pwf65s">cpm.LinkAsTorchModel</a></span><span class="c13">. </span><span class="c6">The use of a PyTorch optimizer is required.</span></p><a id="t.a248f011d1b3a5976ee0a1b79acb09d221b6c0f7"></a><a id="t.36"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c16"><span class="c9">model = ChainerModel()</span></p><p class="c16"><span class="c9">model.to_device(ch_device)</span></p><p class="c16 c29"><span class="c9"></span></p><p class="c16"><span class="c13 c72"># Initialize parameters before converting to `ChainerParameter`s.</span></p><p class="c16"><span class="c9">model(ch_device.xp.zeros((1, 784)).astype(&#39;f&#39;))</span></p><p class="c16 c29"><span class="c9"></span></p><p class="c16"><span class="c72 c13"># Convert parameters to `ChainerParameter`s to share memory with PyTorch.</span></p><p class="c16"><span class="c9">torched_model = cpm.LinkAsTorchModel(model)</span></p><p class="c16 c29"><span class="c9"></span></p><p class="c16"><span class="c9">optimizer = optim.SGD(torched_model.parameters(), lr=args.lr)</span></p><p class="c16 c29"><span class="c9"></span></p><p class="c16"><span class="c9">optimizer = hvd.DistributedOptimizer(</span></p><p class="c16"><span class="c9">&nbsp; &nbsp; optimizer, named_parameters=torched_model.named_parameters())</span></p><p class="c16"><span class="c9">hvd.broadcast_parameters(torched_model.state_dict(), root_rank=0)</span></p><p class="c16"><span class="c13">hvd.broadcast_optimizer_state(optimizer, root_rank=0)</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><h3 class="c23 c10" id="h.vlwpxcx5nw9c"><span>Py</span><span class="c42 c36">Torch model using ChainerMN</span></h3><p class="c4 c10"><span class="c6">Using the cpm tool it is also possible to train a PyTorch model using ChainerMN.</span></p><p class="c4 c10"><span class="c6">The current support is limited only to data parallel training.</span></p><a id="t.0eeb743abfa107ec882dd18dcbb467ec22d093d1"></a><a id="t.37"></a><table class="c30"><tbody><tr class="c5"><td class="c28" colspan="1" rowspan="1"><p class="c16"><span class="c13 c58 c45">from</span><span class="c13 c45 c58">&nbsp;chainer_pytorch_migration </span><span class="c13 c58 c45">import</span><span class="c53 c13 c58 c45">&nbsp;chainermn</span></p><p class="c16 c29"><span class="c55 c35 c15"></span></p><p class="c16"><span class="c55 c35 c15">&hellip;</span></p><p class="c16"><span class="c35 c58 c77 c15">comm </span><span class="c35 c58 c15 c90">=</span><span class="c35 c58 c15 c77">&nbsp;chainermn.create_communicator(</span><span class="c35 c58 c15 c99">&#39;pure_nccl&#39;</span><span class="c55 c35 c15">)<br></span></p><p class="c16"><span class="c55 c35 c15"># Set up standard ResNet-50 model.</span></p><p class="c16"><span class="c55 c35 c15">model = models.resnet50()</span></p><p class="c16"><span class="c55 c35 c15">model.cuda()</span></p><p class="c16"><span class="c55 c35 c15">w_model = links.TorchModule(model)</span></p><p class="c16"><span class="c55 c35 c15">w_model.to_gpu(device)</span></p><p class="c16 c29"><span class="c35 c15 c55"></span></p><p class="c16 c29"><span class="c55 c35 c15"></span></p><p class="c16"><span class="c55 c35 c15">optimizer = optim.SGD(model.parameters(), lr=lr)</span></p><p class="c16 c29"><span class="c55 c35 c15"></span></p><p class="c16"><span class="c55 c35 c15">optimizer = chainermn.create_multi_node_optimizer(optimizer, comm)</span></p><p class="c16"><span class="c55 c35 c15">optimizer.setup(w_model)</span></p></td></tr></tbody></table><p class="c4 c10 c29"><span class="c6"></span></p><h2 class="c31 c10" id="h.2jl4lfh90jqb"><span class="c36 c67">Porting code that edits the computational graph</span></h2><h3 class="c23 c10" id="h.gbqjtjbzzzno"><span class="c42 c36">Unchaining nodes </span></h3><p class="c4 c10"><span class="c6">Explains differences of how variables can be unchained from the computational graph.</span></p><ul class="c18 lst-kix_5s83gilt2o7g-0 start"><li class="c1"><span>Chainer: </span><span class="c13">Variable.{data,array}</span><span>&nbsp;or </span><span class="c13">Variable.unchain()</span><span class="c6">. </span></li><li class="c1"><span>PyTorch: </span><span class="c43 c13"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/autograd.html%23torch.Tensor.detach&amp;sa=D&amp;ust=1578461385687000">Tensor.detach()</a></span><span>. This method returns a new </span><span class="c13">Tensor</span><span>&nbsp;unchained from the computational graph with </span><span class="c13">requires_grad</span><span>&nbsp;set to </span><span class="c13">False</span><span>. This is not an in-place operation in contrast to </span><span class="c13">Variable.unchain()</span><span>&nbsp;and does not incur any side effects (although the new </span><span class="c13">Tensor</span><span>&nbsp;will share the same memory). An in-place variant is however provided as well </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/autograd.html%23torch.Tensor.detach_&amp;sa=D&amp;ust=1578461385688000">Tensor.detach_()</a></span><span class="c6">.</span></li><li class="c1"><span>PyTorch: </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch.github.io/pull/31&amp;sa=D&amp;ust=1578461385688000">Tensor.data is discouraged</a></span><span class="c6">&nbsp;and it seems like it might even get deprecated in the future (based on comments in forums and on GitHub).</span></li><li class="c1"><span>Chainer&rsquo;s </span><span class="c13">Variable.unchain_backward()</span><span>&nbsp;counterpart in PyTorch is not available?</span></li></ul><h3 class="c23 c10" id="h.mc69ie7hbl6j"><span class="c42 c36">Backprop modes</span></h3><p class="c4 c10"><span class="c6">Explains differences of how backprop modes are switched.</span></p><ul class="c18 lst-kix_g3mw20emt8ab-0 start"><li class="c1"><span>Chainer: </span><span class="c13">no_backprop_mode</span><span>, </span><span class="c13">force_backprop_mode </span><span class="c6">correspond to the following in PyTorch.</span></li><li class="c1"><span>PyTorch: </span><span class="c43 c13"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/autograd.html%23torch.autograd.no_grad&amp;sa=D&amp;ust=1578461385689000">torch.autograd.no_grad()</a></span><span>, </span><span class="c43 c13"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/autograd.html%23torch.autograd.enable_grad&amp;sa=D&amp;ust=1578461385689000">torch.autograd.enable_grad()</a></span><span class="c6">. </span></li><li class="c1"><span class="c13">no_grad()</span><span>&nbsp;can also be used to allow writing data directly to an already allocated </span><span class="c13">Tensor</span><span class="c6">&nbsp;using [...].</span></li><li class="c1"><span>In Chainer, this is also a configuration (</span><span class="c13">configuration.config.enable_backprop</span><span>), it is however not in PyTorch.</span></li><li class="c1"><span class="c6">Both Chainer and PyTorch default to backprop mode being enabled.</span></li></ul><h3 class="c23 c10" id="h.bka3yqtw2rpy"><span class="c42 c36">Train/Test modes</span></h3><p class="c4 c10"><span class="c6">Explains differences of how train/test modes are switched. </span></p><ul class="c18 lst-kix_3sh9r2c1w16g-0 start"><li class="c1"><span>Chainer: This mode is controlled via a configuration (</span><span class="c13">configuration.config.train</span><span class="c6">).</span></li><li class="c1"><span>PyTorch: This mode is a module state and should be changed using </span><span class="c43 c13"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Module.train&amp;sa=D&amp;ust=1578461385691000">torch.nn.Module.train(mode)</a></span><span>, </span><span class="c43 c13"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Module.eval&amp;sa=D&amp;ust=1578461385691000">torch.nn.Module.eval()</a></span><span>. This also means that you must pass the &ldquo;train&rdquo; argument to functions calls such as </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23torch.nn.functional.dropout&amp;sa=D&amp;ust=1578461385691000">torch.nn.functional.dropout</a></span><span>&nbsp;otherwise use the </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23torch.nn.Dropout&amp;sa=D&amp;ust=1578461385691000">torch.nn.Dropout module</a></span><span>&nbsp;which is stateful.</span></li><li class="c1"><span class="c6">In both Chainer and PyTorch, train/test mode affects the behavior of certain functions/links/modules such as dropout and batch normalization. </span></li><li class="c1"><span>Both Chainer and PyTorch default to train mode.</span></li></ul><h1 class="c10 c49 c59" id="h.r8th8e47f02c"><span class="c94 c36 c62">Ecosystem</span></h1><p class="c4 c10"><span class="c6">This section introduces some of the larger repositories under the PyTorch GitHub organization. It also refers to the official list of other ecosystem-libraries acknowledged by PyTorch.</span></p><h3 class="c23 c10" id="h.d863gr6235hf"><span class="c42 c36">PyTorch</span></h3><p class="c4 c10"><span class="c36">Summary:</span><span>&nbsp;</span><span class="c58 c77 c112">Tensors and Dynamic neural networks in Python with strong GPU acceleration</span></p><p class="c4 c10"><span class="c36">GitHub:</span><span>&nbsp;</span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/pytorch&amp;sa=D&amp;ust=1578461385693000">https://github.com/pytorch/pytorch</a></span></p><ul class="c18 lst-kix_47504ojh0ba1-0 start"><li class="c1"><span class="c36">Installation:</span><span>&nbsp;See </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/get-started/locally/&amp;sa=D&amp;ust=1578461385693000">Start Locally</a></span><span>&nbsp;for the instructions. Note that not all variants are hosted on PyPI; as of PyTorch 1.2.0, </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pypi.org/project/torch/&amp;sa=D&amp;ust=1578461385693000">torch</a></span><span>/</span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pypi.org/project/torchvision/&amp;sa=D&amp;ust=1578461385693000">torchvision</a></span><span class="c6">&nbsp;packages hosted on PyPI are for CUDA 10.0.</span></li><li class="c1"><span class="c36">Nightly builds</span><span>: Nightly build is provided so you can try the pre-built binary with new merged feature next day. Each nightly build is tagged per each day so you can download nightly version locked pip wheel and prebuilt </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/cppdocs/installing.html&amp;sa=D&amp;ust=1578461385694000">libtorch</a></span><span>&nbsp;of specific build date. For pip wheel refer </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/get-started/locally/&amp;sa=D&amp;ust=1578461385694000">Start Locally</a></span><span>&nbsp;(</span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html&amp;sa=D&amp;ust=1578461385694000">CPU page</a></span><span>, </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html&amp;sa=D&amp;ust=1578461385694000">CUDA 9.2 page</a></span><span>, </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://download.pytorch.org/whl/nightly/cu100/torch_nightly.html&amp;sa=D&amp;ust=1578461385695000">CUDA 10.0 page</a></span><span>) to get optimal version.</span></li></ul><h3 class="c23 c10" id="h.w69092dw2rtl"><span class="c42 c36">Ignite</span></h3><p class="c4 c10"><span class="c36">Summary:</span><span class="c6">&nbsp;High level utilities such as training loop abstraction.</span></p><p class="c4 c10"><span class="c36">GitHub:</span><span>&nbsp;</span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/ignite&amp;sa=D&amp;ust=1578461385695000">https://github.com/pytorch/ignite</a></span></p><h3 class="c23 c10" id="h.b2r58wgcvv09"><span class="c42 c36">torchvision</span></h3><p class="c4 c10"><span class="c36">Summary:</span><span class="c6">&nbsp;PyTorch for CV.</span></p><p class="c4 c10"><span class="c36">GitHub: </span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/vision&amp;sa=D&amp;ust=1578461385696000">https://github.com/pytorch/vision</a></span></p><p class="c4 c10"><span>Recommended by the official installation guide to install along with </span><span class="c13">pytorch</span><span class="c6">.</span></p><p class="c4 c10"><span class="c6">Provides domain-agnostic (not limited to CV) data augmentation functionality.</span></p><p class="c4 c10"><span>Provides loaders for video data. Slow due to ffmpeg but this might be improved in the future?</span></p><h3 class="c23 c10" id="h.ctcyjos25n6z"><span class="c42 c36">torchtext</span></h3><p class="c4 c10"><span class="c36">Summary:</span><span class="c6">&nbsp;PyTorch for NLP.</span></p><p class="c4 c10"><span class="c36">GitHub:</span><span>&nbsp;</span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/text&amp;sa=D&amp;ust=1578461385697000">https://github.com/pytorch/text</a></span></p><h3 class="c23 c10" id="h.l9nxjlcurusl"><span class="c42 c36">torchaudio </span></h3><p class="c4 c10"><span class="c36">Summary:</span><span>&nbsp;PyTorch for audio data.</span></p><p class="c4 c10"><span class="c36">GitHub:</span><span>&nbsp;</span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/audio&amp;sa=D&amp;ust=1578461385697000">https://github.com/pytorch/audio</a></span></p><h3 class="c23 c10" id="h.p90hj6w1ucn0"><span class="c42 c36">Fairseq</span></h3><p class="c4 c10"><span class="c36">Summary:</span><span class="c6">&nbsp;Seq2seq models.</span></p><p class="c4 c10"><span class="c36">GitHub:</span><span>&nbsp;</span><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://github.com/pytorch/fairseq&amp;sa=D&amp;ust=1578461385698000">https://github.com/pytorch/fairseq</a></span></p><p class="c4 c10"><span>Seq2seq models such as translation. Includes the Transformer and BERT-like models.</span></p><h3 class="c23 c10" id="h.eaofa6s7sf0k"><span class="c42 c36">Other</span></h3><p class="c4 c10"><span class="c6">There is an official list of libraries included in the PyTorch ecosystem (besides the domain specific libraries above), including e.g. Ignite.</span></p><p class="c4 c10"><span class="c43"><a class="c2" href="https://www.google.com/url?q=https://pytorch.org/ecosystem&amp;sa=D&amp;ust=1578461385699000">https://pytorch.org/ecosystem</a></span></p></body></html>